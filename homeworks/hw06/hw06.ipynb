{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb45b9e7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw06.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a768e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "\n",
    "#### Homework 6\n",
    "\n",
    "# SQL, Regular Expressions, and GPTEECS\n",
    "\n",
    "### EECS 398-003: Practical Data Science, Fall 2024\n",
    "\n",
    "#### Due Thursday, October 17th at 11:59PM (due in **two** weeks)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008d33c",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to Homework 6! In this homework, you will practice writing SQL queries, use regular expressions to extract meaning out of messy text data, and apply your knowledge of cosine similarity and TF-IDF to implement a supercharged ChatGPT-like bot. See the [Readings section of the Resources tab on the course website](https://practicaldsc.org/resources/#readings) for supplemental resources.\n",
    "\n",
    "You are given six slip days throughout the semester to extend deadlines. See the [Syllabus](https://practicaldsc.org/syllabus) for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "To access this notebook, you'll need to clone our [public GitHub repository](https://github.com/practicaldsc/fa24/). The [‚öôÔ∏è Environment Setup](https://practicaldsc.org/env-setup) page on the course website walks you through the necessary steps. Once you're done, you'll submit your completed notebook to Gradescope.\n",
    "\n",
    "Please start early and submit often. You can submit as many times as you'd like to Gradescope, and we'll grade your **most recent** submission.\n",
    "\n",
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "Unlike other homeworks, Homework 6 <b>has no hidden tests</b>, because of its proximity to the Midterm Exam. This means the tests you see in your notebook are the exact same as the ones that will be used to grade your work on Gradescope. When you submit on Gradescope, you'll see your score shortly after you submit, once the autograder finishes running.\n",
    "<br><br>\n",
    "<b>Even though Homework 6 is due after the Midterm Exam, you should work on it before, since everything in the homework is in scope for the exam!</b> In particular, we recommend working on Questions 1-3 before the exam, because they provide core practice with SQL and regular expressions, both of which will appear on the exam. Question 4 is more \"applied\", and while cosine similarity, bag of words, and TF-IDF will appear on the exam, the best way to practice with those ideas is by working on relevant old exam problems at the <a href=\"https://study.practicaldsc.org\"><b>study site</b></a>.\n",
    "</div>\n",
    "\n",
    "If you do fail a test in your notebook, look for a brief failure message that describes the error.\n",
    "\n",
    "This homework is worth a total of **56 points**, all of which come from the autograder. The number of points each question is worth is listed at the start of each question. **The four questions in the assignment are independent, so feel free to move around if you get stuck**. Tip: if you're using Jupyter Lab, you can see a Table of Contents for the notebook by going to View > Table of Contents.\n",
    "\n",
    "<!-- <a name='like-dataframe'>\n",
    "\n",
    "</a>\n",
    "\n",
    "<div class=\"alert alert-warning\" markdown=\"1\">\n",
    "    \n",
    "**Note**: Throughout this homework, you'll see statements like this frequently:\n",
    "\n",
    "<blockquote>Complete the implementation of the function ____, which takes in a DataFrame <code>df</code> like <code>other_df</code> and _____.</blockquote>\n",
    "\n",
    "What this means is that you should assume that `df` has the same number of columns as `other_df`, with the same column titles and data types, but potentially a different number of rows in a different order, with a potentially different index. You should always also assume that `df` has at least one row.\n",
    "\n",
    "We have you implement functions like this to prevent you from hard-coding your answers to one specific dataset.\n",
    "\n",
    "</div>\n",
    " -->\n",
    " \n",
    "<div class=\"alert alert-danger\" markdown=\"1\">\n",
    "<tt>for</tt>-loops are <strong>allowed</strong> throughout this entire homework.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77719143",
   "metadata": {},
   "source": [
    "To get started, run the **two** cells below, plus the cell at the top of the notebook that imports and initializes `otter`. The cell below installs a few new packages that weren't included in the `pds` conda environment that we'll need throughout the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85994216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: duckdb in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: groq in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from groq) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from groq) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n",
      "Requirement already satisfied: certifi in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/macbook/anaconda3/envs/pds/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install duckdb\n",
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17e5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import groq\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25786e43",
   "metadata": {},
   "source": [
    "## Question 1: LoansQL üíµ\n",
    "\n",
    "---\n",
    "\n",
    "In this question, you'll practice writing SQL queries involving the LendingClub loans dataset from [Lecture 7](https://practicaldsc.org/resources/lectures/lec07/lec07-filled.html) and Homework 4. Run the cell below to load in our dataset as the DataFrame `loans` and clean it using the same steps from lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24fb367c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>desc</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17965023</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>16.99</td>\n",
       "      <td>D</td>\n",
       "      <td>D3</td>\n",
       "      <td>sales</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>RENT</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MN</td>\n",
       "      <td>23.22</td>\n",
       "      <td>700.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>N</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2014-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111414087</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.02</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>mechanic</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>OWN</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL</td>\n",
       "      <td>6.14</td>\n",
       "      <td>680.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>N</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95219557</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>36</td>\n",
       "      <td>7.99</td>\n",
       "      <td>A</td>\n",
       "      <td>A5</td>\n",
       "      <td>general manager</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>47500.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MO</td>\n",
       "      <td>12.89</td>\n",
       "      <td>705.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>N</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2016-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142831837</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>23.40</td>\n",
       "      <td>E</td>\n",
       "      <td>E1</td>\n",
       "      <td>nurse</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FL</td>\n",
       "      <td>5.66</td>\n",
       "      <td>670.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140113255</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>7.84</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>staff pharmacist</td>\n",
       "      <td>Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MN</td>\n",
       "      <td>12.24</td>\n",
       "      <td>735.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295</th>\n",
       "      <td>16121830</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>6.03</td>\n",
       "      <td>A</td>\n",
       "      <td>A1</td>\n",
       "      <td>senior buyer</td>\n",
       "      <td>Verified</td>\n",
       "      <td>RENT</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.91</td>\n",
       "      <td>720.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>N</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2014-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>105091208</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>7.99</td>\n",
       "      <td>A</td>\n",
       "      <td>A5</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>OWN</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>5.66</td>\n",
       "      <td>695.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>63990101</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>60</td>\n",
       "      <td>18.49</td>\n",
       "      <td>E</td>\n",
       "      <td>E2</td>\n",
       "      <td>technician</td>\n",
       "      <td>Verified</td>\n",
       "      <td>OWN</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>25.39</td>\n",
       "      <td>675.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>N</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2015-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>37641672</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>14.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>software engineer</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>RENT</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>10.63</td>\n",
       "      <td>660.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>N</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2014-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>50587446</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>9.99</td>\n",
       "      <td>B</td>\n",
       "      <td>B3</td>\n",
       "      <td>teacher</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>44868.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>9.25</td>\n",
       "      <td>685.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6300 rows √ó 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  loan_amnt  term  int_rate grade sub_grade          emp_title  \\\n",
       "0      17965023    18000.0    60     16.99     D        D3              sales   \n",
       "1     111414087    10000.0    36     16.02     C        C5           mechanic   \n",
       "2      95219557    12800.0    36      7.99     A        A5    general manager   \n",
       "3     142831837    16000.0    60     23.40     E        E1              nurse   \n",
       "4     140113255    40000.0    60      7.84     A        A4   staff pharmacist   \n",
       "...         ...        ...   ...       ...   ...       ...                ...   \n",
       "6295   16121830    20000.0    36      6.03     A        A1       senior buyer   \n",
       "6296  105091208    20000.0    36      7.99     A        A5   registered nurse   \n",
       "6297   63990101    10800.0    60     18.49     E        E2         technician   \n",
       "6298   37641672    15000.0    60     14.31     C        C4  software engineer   \n",
       "6299   50587446    14000.0    60      9.99     B        B3            teacher   \n",
       "\n",
       "     verification_status home_ownership  annual_inc  loan_status  \\\n",
       "0        Source Verified           RENT     60000.0  Charged Off   \n",
       "1        Source Verified            OWN     50000.0      Current   \n",
       "2           Not Verified       MORTGAGE     47500.0   Fully Paid   \n",
       "3        Source Verified       MORTGAGE    120000.0      Current   \n",
       "4               Verified       MORTGAGE    150000.0      Current   \n",
       "...                  ...            ...         ...          ...   \n",
       "6295            Verified           RENT    124000.0   Fully Paid   \n",
       "6296     Source Verified            OWN    220000.0   Fully Paid   \n",
       "6297            Verified            OWN     35000.0  Charged Off   \n",
       "6298     Source Verified           RENT    150000.0   Fully Paid   \n",
       "6299        Not Verified       MORTGAGE     44868.0      Current   \n",
       "\n",
       "                 purpose desc addr_state    dti  fico_range_low  \\\n",
       "0     debt_consolidation  NaN         MN  23.22           700.0   \n",
       "1       home_improvement  NaN         IL   6.14           680.0   \n",
       "2     debt_consolidation  NaN         MO  12.89           705.0   \n",
       "3       home_improvement  NaN         FL   5.66           670.0   \n",
       "4     debt_consolidation  NaN         MN  12.24           735.0   \n",
       "...                  ...  ...        ...    ...             ...   \n",
       "6295  debt_consolidation  NaN         CA   6.91           720.0   \n",
       "6296  debt_consolidation  NaN         CA   5.66           695.0   \n",
       "6297  debt_consolidation  NaN         NY  25.39           675.0   \n",
       "6298         credit_card  NaN         CA  10.63           660.0   \n",
       "6299    home_improvement  NaN         TX   9.25           685.0   \n",
       "\n",
       "      fico_range_high hardship_flag  mths_since_last_delinq       date  \n",
       "0               704.0             N                    72.0 2014-06-01  \n",
       "1               684.0             N                     6.0 2017-06-01  \n",
       "2               709.0             N                    66.0 2016-12-01  \n",
       "3               674.0             N                     NaN 2018-10-01  \n",
       "4               739.0             N                     NaN 2018-09-01  \n",
       "...               ...           ...                     ...        ...  \n",
       "6295            724.0             N                    54.0 2014-05-01  \n",
       "6296            699.0             N                     NaN 2017-04-01  \n",
       "6297            679.0             N                    39.0 2015-11-01  \n",
       "6298            664.0             N                    22.0 2014-12-01  \n",
       "6299            689.0             N                     NaN 2015-06-01  \n",
       "\n",
       "[6300 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_term_column(df):\n",
    "    return df.assign(\n",
    "        term=df['term'].str.split().str[0].astype(int)\n",
    "    )\n",
    "\n",
    "def clean_date_column(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(date=pd.to_datetime(df['issue_d'], format='%b-%Y'))\n",
    "        .drop(columns=['issue_d'])\n",
    "    )\n",
    "\n",
    "loans = (\n",
    "    pd.read_csv('data/loans.csv')\n",
    "    .pipe(clean_term_column)\n",
    "    .pipe(clean_date_column)\n",
    ")\n",
    "\n",
    "loans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f6403",
   "metadata": {},
   "source": [
    "As we did in [Lecture 10](https://practicaldsc.org/resources/lectures/lec10/lec10-filled.html#SQL), we will use the Python module `duckdb` to execute SQL queries within our Jupyter Notebook. We've included code to install and import `duckdb` at the top of this notebook.\n",
    "\n",
    "Specifically, we will use the `run_sql` function we defined in lecture.\n",
    "- `run_sql` takes in a string containing a SQL query.\n",
    "- `run_sql` outputs the result of running the query, treating all DataFrames mentioned in the query as if they were SQL tables. The result it outputs (here) is a **DataFrame**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328ef5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql(query_str):\n",
    "    if query_str == ... or query_str.strip() == '':\n",
    "        raise NotImplementedError('The input passed to run_sql is empty. Update it to include your query.')\n",
    "    out = duckdb.query(query_str)\n",
    "    return out.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896cd265",
   "metadata": {},
   "source": [
    "For example, the following call to `run_sql` references `loans`, a DataFrame already defined in our notebook. It returns a new DataFrame (and doesn't modify the original `loans` DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5668617d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>desc</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140113255</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>7.84</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>staff pharmacist</td>\n",
       "      <td>Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>None</td>\n",
       "      <td>MN</td>\n",
       "      <td>12.24</td>\n",
       "      <td>735.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143365202</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>20.89</td>\n",
       "      <td>D</td>\n",
       "      <td>D4</td>\n",
       "      <td>graphics designer/ ui developer</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>None</td>\n",
       "      <td>CA</td>\n",
       "      <td>29.34</td>\n",
       "      <td>700.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2018-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94378468</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>21.49</td>\n",
       "      <td>D</td>\n",
       "      <td>D5</td>\n",
       "      <td>producer</td>\n",
       "      <td>Verified</td>\n",
       "      <td>RENT</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>None</td>\n",
       "      <td>CA</td>\n",
       "      <td>15.92</td>\n",
       "      <td>660.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>N</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2016-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99330538</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>23.99</td>\n",
       "      <td>E</td>\n",
       "      <td>E2</td>\n",
       "      <td>courier</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>None</td>\n",
       "      <td>GA</td>\n",
       "      <td>4.29</td>\n",
       "      <td>660.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59411554</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>18.55</td>\n",
       "      <td>E</td>\n",
       "      <td>E2</td>\n",
       "      <td>patients care tech</td>\n",
       "      <td>Verified</td>\n",
       "      <td>OWN</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>None</td>\n",
       "      <td>CA</td>\n",
       "      <td>38.50</td>\n",
       "      <td>670.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>N</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2015-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>16341922</td>\n",
       "      <td>20400.0</td>\n",
       "      <td>60</td>\n",
       "      <td>14.49</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>information security engineer</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>OWN</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>None</td>\n",
       "      <td>GA</td>\n",
       "      <td>14.02</td>\n",
       "      <td>710.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>N</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2014-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>137876020</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>11.55</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>police sergeant</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>None</td>\n",
       "      <td>IL</td>\n",
       "      <td>17.14</td>\n",
       "      <td>705.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>78659466</td>\n",
       "      <td>30300.0</td>\n",
       "      <td>60</td>\n",
       "      <td>29.96</td>\n",
       "      <td>G</td>\n",
       "      <td>G4</td>\n",
       "      <td>rn</td>\n",
       "      <td>Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>None</td>\n",
       "      <td>IN</td>\n",
       "      <td>21.93</td>\n",
       "      <td>680.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>56109274</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>20.99</td>\n",
       "      <td>E</td>\n",
       "      <td>E5</td>\n",
       "      <td>mailhandler</td>\n",
       "      <td>Verified</td>\n",
       "      <td>RENT</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>None</td>\n",
       "      <td>NY</td>\n",
       "      <td>28.53</td>\n",
       "      <td>665.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>N</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2015-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>132541772</td>\n",
       "      <td>23900.0</td>\n",
       "      <td>60</td>\n",
       "      <td>12.61</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>svp &amp; internal audit director</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>232785.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>None</td>\n",
       "      <td>TX</td>\n",
       "      <td>16.60</td>\n",
       "      <td>685.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>N</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2018-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows √ó 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  loan_amnt  term  int_rate grade sub_grade  \\\n",
       "0    140113255    40000.0    60      7.84     A        A4   \n",
       "1    143365202    30000.0    60     20.89     D        D4   \n",
       "2     94378468    24000.0    60     21.49     D        D5   \n",
       "3     99330538    24000.0    60     23.99     E        E2   \n",
       "4     59411554    32000.0    60     18.55     E        E2   \n",
       "..         ...        ...   ...       ...   ...       ...   \n",
       "489   16341922    20400.0    60     14.49     C        C4   \n",
       "490  137876020    40000.0    60     11.55     B        B4   \n",
       "491   78659466    30300.0    60     29.96     G        G4   \n",
       "492   56109274    21000.0    60     20.99     E        E5   \n",
       "493  132541772    23900.0    60     12.61     C        C1   \n",
       "\n",
       "                           emp_title verification_status home_ownership  \\\n",
       "0                   staff pharmacist            Verified       MORTGAGE   \n",
       "1    graphics designer/ ui developer     Source Verified           RENT   \n",
       "2                           producer            Verified           RENT   \n",
       "3                            courier     Source Verified       MORTGAGE   \n",
       "4                 patients care tech            Verified            OWN   \n",
       "..                               ...                 ...            ...   \n",
       "489    information security engineer     Source Verified            OWN   \n",
       "490                  police sergeant     Source Verified       MORTGAGE   \n",
       "491                               rn            Verified       MORTGAGE   \n",
       "492                      mailhandler            Verified           RENT   \n",
       "493    svp & internal audit director     Source Verified       MORTGAGE   \n",
       "\n",
       "     annual_inc  loan_status             purpose  desc addr_state    dti  \\\n",
       "0      150000.0      Current  debt_consolidation  None         MN  12.24   \n",
       "1       80000.0      Current         credit_card  None         CA  29.34   \n",
       "2       85000.0  Charged Off  debt_consolidation  None         CA  15.92   \n",
       "3       80000.0   Fully Paid  debt_consolidation  None         GA   4.29   \n",
       "4       75000.0   Fully Paid  debt_consolidation  None         CA  38.50   \n",
       "..          ...          ...                 ...   ...        ...    ...   \n",
       "489    133000.0   Fully Paid    home_improvement  None         GA  14.02   \n",
       "490    150000.0      Current  debt_consolidation  None         IL  17.14   \n",
       "491     70000.0  Charged Off  debt_consolidation  None         IN  21.93   \n",
       "492     54000.0   Fully Paid  debt_consolidation  None         NY  28.53   \n",
       "493    232785.0      Current         credit_card  None         TX  16.60   \n",
       "\n",
       "     fico_range_low  fico_range_high hardship_flag  mths_since_last_delinq  \\\n",
       "0             735.0            739.0             N                     NaN   \n",
       "1             700.0            704.0             N                    17.0   \n",
       "2             660.0            664.0             N                    29.0   \n",
       "3             660.0            664.0             N                     NaN   \n",
       "4             670.0            674.0             N                    80.0   \n",
       "..              ...              ...           ...                     ...   \n",
       "489           710.0            714.0             N                    82.0   \n",
       "490           705.0            709.0             N                     NaN   \n",
       "491           680.0            684.0             N                     NaN   \n",
       "492           665.0            669.0             N                    19.0   \n",
       "493           685.0            689.0             N                    65.0   \n",
       "\n",
       "          date  \n",
       "0   2018-09-01  \n",
       "1   2018-11-01  \n",
       "2   2016-12-01  \n",
       "3   2017-02-01  \n",
       "4   2015-09-01  \n",
       "..         ...  \n",
       "489 2014-05-01  \n",
       "490 2018-08-01  \n",
       "491 2016-05-01  \n",
       "492 2015-08-01  \n",
       "493 2018-05-01  \n",
       "\n",
       "[494 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_sql('''\n",
    "SELECT * FROM loans\n",
    "WHERE term = 60 AND loan_amnt > 20000\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b8f4a",
   "metadata": {},
   "source": [
    "The above query happens to be equivalent to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45723a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>desc</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140113255</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>7.84</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>staff pharmacist</td>\n",
       "      <td>Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MN</td>\n",
       "      <td>12.24</td>\n",
       "      <td>735.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>143365202</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>20.89</td>\n",
       "      <td>D</td>\n",
       "      <td>D4</td>\n",
       "      <td>graphics designer/ ui developer</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>29.34</td>\n",
       "      <td>700.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2018-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>94378468</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>21.49</td>\n",
       "      <td>D</td>\n",
       "      <td>D5</td>\n",
       "      <td>producer</td>\n",
       "      <td>Verified</td>\n",
       "      <td>RENT</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>15.92</td>\n",
       "      <td>660.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>N</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2016-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>99330538</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>23.99</td>\n",
       "      <td>E</td>\n",
       "      <td>E2</td>\n",
       "      <td>courier</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GA</td>\n",
       "      <td>4.29</td>\n",
       "      <td>660.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>59411554</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>18.55</td>\n",
       "      <td>E</td>\n",
       "      <td>E2</td>\n",
       "      <td>patients care tech</td>\n",
       "      <td>Verified</td>\n",
       "      <td>OWN</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>38.50</td>\n",
       "      <td>670.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>N</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2015-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>16341922</td>\n",
       "      <td>20400.0</td>\n",
       "      <td>60</td>\n",
       "      <td>14.49</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>information security engineer</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>OWN</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GA</td>\n",
       "      <td>14.02</td>\n",
       "      <td>710.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>N</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2014-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>137876020</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>11.55</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>police sergeant</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL</td>\n",
       "      <td>17.14</td>\n",
       "      <td>705.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>78659466</td>\n",
       "      <td>30300.0</td>\n",
       "      <td>60</td>\n",
       "      <td>29.96</td>\n",
       "      <td>G</td>\n",
       "      <td>G4</td>\n",
       "      <td>rn</td>\n",
       "      <td>Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>21.93</td>\n",
       "      <td>680.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>56109274</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>20.99</td>\n",
       "      <td>E</td>\n",
       "      <td>E5</td>\n",
       "      <td>mailhandler</td>\n",
       "      <td>Verified</td>\n",
       "      <td>RENT</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>28.53</td>\n",
       "      <td>665.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>N</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2015-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>132541772</td>\n",
       "      <td>23900.0</td>\n",
       "      <td>60</td>\n",
       "      <td>12.61</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>svp &amp; internal audit director</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>232785.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>16.60</td>\n",
       "      <td>685.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>N</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2018-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows √ó 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  loan_amnt  term  int_rate grade sub_grade  \\\n",
       "4     140113255    40000.0    60      7.84     A        A4   \n",
       "35    143365202    30000.0    60     20.89     D        D4   \n",
       "48     94378468    24000.0    60     21.49     D        D5   \n",
       "52     99330538    24000.0    60     23.99     E        E2   \n",
       "54     59411554    32000.0    60     18.55     E        E2   \n",
       "...         ...        ...   ...       ...   ...       ...   \n",
       "6219   16341922    20400.0    60     14.49     C        C4   \n",
       "6224  137876020    40000.0    60     11.55     B        B4   \n",
       "6234   78659466    30300.0    60     29.96     G        G4   \n",
       "6275   56109274    21000.0    60     20.99     E        E5   \n",
       "6290  132541772    23900.0    60     12.61     C        C1   \n",
       "\n",
       "                            emp_title verification_status home_ownership  \\\n",
       "4                    staff pharmacist            Verified       MORTGAGE   \n",
       "35    graphics designer/ ui developer     Source Verified           RENT   \n",
       "48                           producer            Verified           RENT   \n",
       "52                            courier     Source Verified       MORTGAGE   \n",
       "54                 patients care tech            Verified            OWN   \n",
       "...                               ...                 ...            ...   \n",
       "6219    information security engineer     Source Verified            OWN   \n",
       "6224                  police sergeant     Source Verified       MORTGAGE   \n",
       "6234                               rn            Verified       MORTGAGE   \n",
       "6275                      mailhandler            Verified           RENT   \n",
       "6290    svp & internal audit director     Source Verified       MORTGAGE   \n",
       "\n",
       "      annual_inc  loan_status             purpose desc addr_state    dti  \\\n",
       "4       150000.0      Current  debt_consolidation  NaN         MN  12.24   \n",
       "35       80000.0      Current         credit_card  NaN         CA  29.34   \n",
       "48       85000.0  Charged Off  debt_consolidation  NaN         CA  15.92   \n",
       "52       80000.0   Fully Paid  debt_consolidation  NaN         GA   4.29   \n",
       "54       75000.0   Fully Paid  debt_consolidation  NaN         CA  38.50   \n",
       "...          ...          ...                 ...  ...        ...    ...   \n",
       "6219    133000.0   Fully Paid    home_improvement  NaN         GA  14.02   \n",
       "6224    150000.0      Current  debt_consolidation  NaN         IL  17.14   \n",
       "6234     70000.0  Charged Off  debt_consolidation  NaN         IN  21.93   \n",
       "6275     54000.0   Fully Paid  debt_consolidation  NaN         NY  28.53   \n",
       "6290    232785.0      Current         credit_card  NaN         TX  16.60   \n",
       "\n",
       "      fico_range_low  fico_range_high hardship_flag  mths_since_last_delinq  \\\n",
       "4              735.0            739.0             N                     NaN   \n",
       "35             700.0            704.0             N                    17.0   \n",
       "48             660.0            664.0             N                    29.0   \n",
       "52             660.0            664.0             N                     NaN   \n",
       "54             670.0            674.0             N                    80.0   \n",
       "...              ...              ...           ...                     ...   \n",
       "6219           710.0            714.0             N                    82.0   \n",
       "6224           705.0            709.0             N                     NaN   \n",
       "6234           680.0            684.0             N                     NaN   \n",
       "6275           665.0            669.0             N                    19.0   \n",
       "6290           685.0            689.0             N                    65.0   \n",
       "\n",
       "           date  \n",
       "4    2018-09-01  \n",
       "35   2018-11-01  \n",
       "48   2016-12-01  \n",
       "52   2017-02-01  \n",
       "54   2015-09-01  \n",
       "...         ...  \n",
       "6219 2014-05-01  \n",
       "6224 2018-08-01  \n",
       "6234 2016-05-01  \n",
       "6275 2015-08-01  \n",
       "6290 2018-05-01  \n",
       "\n",
       "[494 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans[(loans['term'] == 60) & (loans['loan_amnt'] > 20000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db673b1",
   "metadata": {},
   "source": [
    "All of the questions below will ask you to assign your answer to a **string**. To test your code, we will call `run_sql` on the string that you define, and make sure the resulting DataFrame has the right properties. We suggest you use multi-line strings (defined by `'''` triple quotes `'''`) like in the example call to `run_sql` above.\n",
    "\n",
    "Most of the syntax you need to answer the queries here was covered in Lecture 10. The chart at the start of the [SQL section of Lecture 10](https://practicaldsc.org/resources/lectures/lec10/lec10-filled.html#SQL) contains a nice summary of the necessary keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fab172",
   "metadata": {},
   "source": [
    "### Question 1.1 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Assign `query_1` to a string containing a SQL query that finds **the total (sum) of all loan amounts for each loan purpose, only among loans given in Michigan (`'MI'`)**. The DataFrame that results from calling `run_sql(query_1)` should have two columns, **`'purpose'`** and **`'total_loans'`**, and should be sorted in **descending order** of `'total_loans'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2119228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purpose</th>\n",
       "      <th>total_loans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>1541525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>582675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>home_improvement</td>\n",
       "      <td>113375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>110275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>house</td>\n",
       "      <td>68600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>major_purchase</td>\n",
       "      <td>45800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>small_business</td>\n",
       "      <td>25900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>moving</td>\n",
       "      <td>6400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              purpose  total_loans\n",
       "0  debt_consolidation    1541525.0\n",
       "1         credit_card     582675.0\n",
       "2    home_improvement     113375.0\n",
       "3               other     110275.0\n",
       "4               house      68600.0\n",
       "5      major_purchase      45800.0\n",
       "6      small_business      25900.0\n",
       "7              moving       6400.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_1 = '''\n",
    "    SELECT purpose, SUM(loan_amnt) AS total_loans\n",
    "    FROM loans \n",
    "    WHERE addr_state = 'MI'\n",
    "    GROUP BY purpose\n",
    "    ORDER BY total_loans DESC\n",
    "'''\n",
    "run_sql(query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908df34c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q01_01</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q01_01 results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q01_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dfca59",
   "metadata": {},
   "source": [
    "### Question 1.2 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Assign `query_2` to a string containing a SQL query that finds **the average credit score per state, among states _having_ at least 150 loans**. The DataFrame that results from calling `run_sql(query_2)` should have two columns, **`'state'`** and **`'average_credit'`**, and should be sorted in **increasing order** of `'average_credit'`.\n",
    "\n",
    "Some guidance:\n",
    "- Extract credit scores from the `'fico_range_low'` column in `loans`.\n",
    "- One of the SQL keywords you need to use was _italicized_ in the first sentence above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94087ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>average_credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FL</td>\n",
       "      <td>695.130952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VA</td>\n",
       "      <td>696.338798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>696.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>697.401961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MI</td>\n",
       "      <td>697.672414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CA</td>\n",
       "      <td>698.154696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MD</td>\n",
       "      <td>698.245033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IL</td>\n",
       "      <td>698.582375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GA</td>\n",
       "      <td>698.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PA</td>\n",
       "      <td>698.731707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TX</td>\n",
       "      <td>699.312839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NY</td>\n",
       "      <td>700.200803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NC</td>\n",
       "      <td>700.452128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MA</td>\n",
       "      <td>702.235294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  average_credit\n",
       "0     FL      695.130952\n",
       "1     VA      696.338798\n",
       "2     NJ      696.710526\n",
       "3     OH      697.401961\n",
       "4     MI      697.672414\n",
       "5     CA      698.154696\n",
       "6     MD      698.245033\n",
       "7     IL      698.582375\n",
       "8     GA      698.712121\n",
       "9     PA      698.731707\n",
       "10    TX      699.312839\n",
       "11    NY      700.200803\n",
       "12    NC      700.452128\n",
       "13    MA      702.235294"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2 = '''\n",
    "    SELECT addr_state AS state , AVG(fico_range_low) AS average_credit\n",
    "    FROM loans\n",
    "    GROUP BY addr_state\n",
    "    HAVING COUNT(loan_amnt) > 150\n",
    "    ORDER BY average_credit ASC\n",
    "'''\n",
    "run_sql(query_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e342202f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q01_02</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q01_02 results: All test cases passed!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q01_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32230a",
   "metadata": {},
   "source": [
    "### Question 1.3 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "The LendingClub uses **simple interest** to calculate loan payments. Using simple interest, the total amount due for a loan is:\n",
    "\n",
    "$$\\text{Total Amount Due} = \\text{Loan Amount} \\cdot \\left(1 + (\\text{Interest Rate} \\cdot \\text{Loan Length in Years}) \\right)$$\n",
    "\n",
    "For example, a loan for \\\\$10,000 at an interest rate of 15% for 5 years would pay a total amount of \\\\$17,500:\n",
    "\n",
    "$$10000 \\cdot (1 + 0.15 \\cdot 5) = 17500$$\n",
    "\n",
    "Since there are 60 months in 5 years, this lendee would pay $\\frac{\\$17,500}{60} = \\$291.67$ per month for 60 months. **Note that the percentage 15% is equivalent to the decimal 0.15.**\n",
    "\n",
    "More generally:\n",
    "\n",
    "$$\\text{Monthly Payments} = \\frac{\\text{Total Amount Due}}{\\text{Loan Length in Months}} = \\frac{\\text{Loan Amount} \\cdot \\left(1 + (\\text{Interest Rate} \\cdot \\text{Loan Length in Years}) \\right)}{\\text{Loan Length in Months}}$$\n",
    "\n",
    "Assign `query_3` to a string containing a SQL query that finds **loan amount, term, interest rate, and monthly payment amount of the single loanholder with the highest monthly payments**. The DataFrame that results from calling `run_sql(query_3)` should have four columns, `'amount'`, `'term'`, `'interest'`, and `'monthly'`, and should only have a **single row**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df307092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>term</th>\n",
       "      <th>interest</th>\n",
       "      <th>monthly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39475.0</td>\n",
       "      <td>36</td>\n",
       "      <td>23.88</td>\n",
       "      <td>1882.080278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amount  term  interest      monthly\n",
       "0  39475.0    36     23.88  1882.080278"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_3 = '''\n",
    "SELECT loan_amnt AS amount, term, int_rate AS interest, (loan_amnt * ((1+(interest/100)*(term/12)))/term) AS monthly \n",
    "FROM loans\n",
    "ORDER BY monthly DESC\n",
    "LIMIT 1;\n",
    "'''\n",
    "run_sql(query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a82806af",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q01_03</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q01_03 results: All test cases passed!"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q01_03\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c20d2bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2: Practice with Regular Expressions üìï\n",
    "\n",
    "---\n",
    "\n",
    "Regular expressions can be tricky, and the best way to gain familiarity with them is through lots of practice.\n",
    "\n",
    "In this question, you will work through 10 parts, **each of which requires you to write a regular expression that matches strings that satisfy certain criteria**. You will do this by ‚Äì as usual ‚Äì completing the implementation of a function. In Questions 2.1 through 2.9, your function will take in a string and return `True` if the string follows the pattern and `False` otherwise.\n",
    "\n",
    "- Make sure to take a close look at the examples for each function, as they provide useful guidance for the types of strings you should and shouldn't match.\n",
    "- Make sure to refer to the [Regular Expression Resources](https://practicaldsc.org/resources/#regular-expressions) on the course website. In particular, we recommend having [regex101.com](https://regex101.com/) open while working, along with the [cheat sheet](https://practicaldsc.org/resources/other/berkeley-regex-reference.pdf).\n",
    "- The number of points each part is worth tells you its relative difficulty level ‚Äì some are worth <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div> and some are worth <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>. If you're spending lots of time on exercises worth <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>, take a close look at the syntax from [Lecture 9](https://practicaldsc.org/resources/lectures/lec09/lec09-filled.html), as there is probably an easier way of writing the necessary pattern!\n",
    "- The 10 parts are all independent, and are **not** sorted by difficulty ‚Äì some of the easiest parts are in the middle or towards the end!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c71b3",
   "metadata": {},
   "source": [
    "### Question 2.1  <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Write a regular expression that matches strings that have `'['` as the third character and `']'` as the sixth character. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> match_1(\"abcde]\")\n",
    "False\n",
    "\n",
    ">>> match_1(\"ab[cde\")\n",
    "False\n",
    "\n",
    ">>> match_1(\"ab[cd]ef\")\n",
    "True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97bccd6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_1(string):\n",
    "    pattern = r'^..\\[..\\].*$'\n",
    "\n",
    "    # Do not edit the following code.\n",
    "    return re.findall(pattern, string) != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2951570a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q02_01</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q02_01 results: All test cases passed!"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q02_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a2344",
   "metadata": {},
   "source": [
    "### Question 2.2 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Write a regular expression that matches strings that are phone numbers that start with `'(734)'` and follow the format `'(xxx) xxx-xxxx'` (`'x'` represents a digit). Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> match_2(\"(734) 456-7890\")\n",
    "True\n",
    "\n",
    ">>> match_2(\"(123) 456-7890\")\n",
    "False\n",
    "\n",
    ">>> match_2(\"(734) 456-7890b\")\n",
    "False\n",
    "```\n",
    "\n",
    "Note that there is a space between `'(xxx)'` and `'xxx-xxxx'`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "764039e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_2(string):\n",
    "    pattern = r'^\\(734\\) \\d{3}-\\d{4}$'\n",
    "\n",
    "    # Do not edit the following code.\n",
    "    return re.findall(pattern, string) != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fad35c53",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q02_02</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q02_02 results: All test cases passed!"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q02_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271f53e6",
   "metadata": {},
   "source": [
    "### Question 2.3 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Write a regular expression that matches strings that:\n",
    "- are between 6 and 10 characters long (inclusive),\n",
    "- contain only alphanumeric characters, whitespace and `'?'`, and\n",
    "- end with `'?'`.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> match_3('qw?ertsd?')\n",
    "True\n",
    "\n",
    ">>> match_3(\"ab   c ?\")\n",
    "True\n",
    "\n",
    ">>> match_3(\" adf!qes ?\")\n",
    "False\n",
    "\n",
    ">>> match_3('wwwWW .? ')\n",
    "False\n",
    "```\n",
    "\n",
    "Note that `'?'` is a special character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a844ca9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_3(string):\n",
    "    pattern = r\"^[A-Za-z \\?]{5,9}\\?$\"\n",
    "\n",
    "    # Do not edit the following code.\n",
    "    return re.findall(pattern, string) != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8091d14",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q02_03</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q02_03 results: All test cases passed!"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q02_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ab37af",
   "metadata": {},
   "source": [
    "### Question 2.4 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Write a regular expression that matches strings with exactly two `'$'`, one of which is at the start of the string, such that:\n",
    "- the characters between the two `'$'` can be anything (including nothing) except the lowercase letters `'a'`, `'b'`, and `'c'`, (and `'$'`), and\n",
    "- the characters after the second `'$'` can only be the **lowercase or uppercase** letters `'a'`/`'A'`, `'b'`/`'B'`, and `'c'`/`'C'`, with every `'a'`/`'A'` before every `'b'`/`'B'`, and every `'b'`/`'B'` before every `'c'`/`'C'`. There **must be** at least one `'a'` or `'A'`, at least one `'b'` or `'B'`, and at least one `'c'` or `'C'`.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> match_4(\"$!@#$aABc\")\n",
    "True\n",
    "\n",
    ">>> match_4('$qw!!  $aaBC')\n",
    "True\n",
    "\n",
    ">>> match_4('$a$aABc')\n",
    "False\n",
    "\n",
    ">>> match_4('$!@$')\n",
    "False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6719436c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_4(string):\n",
    "    pattern = r\"^\\$([^abc]*)\\$[aA]+[bB]+[cC]+\"\n",
    "\n",
    "    # Do not edit the following code.\n",
    "    return re.findall(pattern, string) != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a846719",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q02_04</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q02_04 results: All test cases passed!"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q02_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f341ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 2.5 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Write a regular expression that matches strings that represent valid Python file names, including the extension. For simplicity, assume that file names only contain letters, numbers, and underscores. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> match_5(\"eecs398.py\")\n",
    "True\n",
    "\n",
    ">>> match_5('eecs398_.py')\n",
    "True\n",
    "\n",
    ">>> match_5(\"here is a Python file eecs398.py\")\n",
    "False\n",
    "\n",
    ">>> match_5(\"eecs398+.py\")\n",
    "False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4bb640f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_5(string):\n",
    "    pattern = r\"^[\\w]+\\.py$\"\n",
    "\n",
    "    # Do not edit the following code.\n",
    "    return re.findall(pattern, string) != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe4e3cda",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q02_05</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q02_05 results: All test cases passed!"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q02_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37362564",
   "metadata": {},
   "source": [
    "### Question 2.6 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Write a regular expression that matches strings that:\n",
    "- are made up of only lowercase letters and exactly one underscore (`'_'`), and\n",
    "- have at least one lowercase letter on both sides of the underscore.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> match_6(\"aab_cbbbc\")\n",
    "True\n",
    "\n",
    ">>> match_6(\"zebra_d\")\n",
    "True\n",
    "\n",
    ">>> match_6(\"aab_Abbbc\")\n",
    "False\n",
    "\n",
    ">>> match_6(\"zebra_\")\n",
    "False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e17cb09c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_6(string):\n",
    "    pattern = r\"^[a-z]+_[a-z]+$\"\n",
    "\n",
    "    # Do not edit the following code.\n",
    "    return re.findall(pattern, string) != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07765cca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q02_06</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q02_06 results: All test cases passed!"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q02_06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45bb3cd",
   "metadata": {},
   "source": [
    "### Question 2.7 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Write a regular expression that matches strings that start with and end with an underscore (`'_'`). Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> match_7(\"_abc_\")\n",
    "True\n",
    "\n",
    ">>> match_7(\"_ZeBr@45Din000!!!\\b_\")\n",
    "True\n",
    "\n",
    ">>> match_7(\"abc\")\n",
    "False\n",
    "\n",
    ">>> match_7(\"_ncde\")\n",
    "False\n",
    "\n",
    ">>> match_7(\"_\") # Need at least two underscores!\n",
    "False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de481ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_7(string):\n",
    "    pattern = r\"^_.+_$\"\n",
    "\n",
    "    # Do not edit the following code.\n",
    "    return re.findall(pattern, string) != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbb2c220",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q02_07</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q02_07 results: All test cases passed!"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q02_07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb76fc2",
   "metadata": {},
   "source": [
    "### Question 2.8 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Apple serial numbers are strings of length 1 or more that are made up of any characters, other than\n",
    "- the uppercase letter `'O'`, \n",
    "- the lowercase letter `'i`', and \n",
    "- the number `'1'`.\n",
    "\n",
    "Write a regular expression that matches strings that are valid Apple serial numbers. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> match_8('ASDJKL9380JKAL')\n",
    "True\n",
    "\n",
    ">>> match_8(\"ASJDKLFK0ASDo!!!!!!! !!!!!!!!!\")\n",
    "True\n",
    "\n",
    ">>> match_8('iPhone 10')\n",
    "False\n",
    "\n",
    ">>> match_8(\"hi ASDJKL9380JKAL\")\n",
    "False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b873e01a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_8(string):\n",
    "    pattern = r'^[^Oi1]+$'\n",
    "\n",
    "    # Do not edit the following code.\n",
    "    return re.findall(pattern, string) != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eed5fec6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q02_08</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q02_08 results: All test cases passed!"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q02_08\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c726f5",
   "metadata": {},
   "source": [
    "### Question 2.9 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Suppose DataID numbers are formatted as `'SC-NN-CCC-NNNN'`, where \n",
    "- SC represents state code in uppercase (e.g. `'MI'`),\n",
    "- NN represents a number with 2 digits (e.g. `'98'`),\n",
    "- CCC represents a three letter city code in uppercase (e.g. `'DTW'`), and\n",
    "- NNNN represents a number with 4 digits (e.g. `'1998'`).\n",
    "\n",
    "Write a regular expression that matches strings that are DataID numbers corresponding to the cities of `'DTW'` (Detroit) or `'LAN'` (Lansing), or the state of `'TX'` (Texas). Assume that there is only one city named `'DTW'` and only one city named `'LAN'`.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> match_9('MI-32-LAN-1232')\n",
    "True\n",
    "\n",
    ">>> match_9('TX-32-DTW-1232')\n",
    "True\n",
    "\n",
    "# Lansing is not in California!\n",
    ">>> match_9('CA-32-LAN-1232')\n",
    "False\n",
    "\n",
    ">>> match_9('mI-32-LAN-1232')\n",
    "False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83e139a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_9(string):\n",
    "    pattern = r\"^[MITX]{2}-\\d{2}-[A-Z]{3}-\\d{4}$\"\n",
    "\n",
    "    # Do not edit the following code.\n",
    "    return re.findall(pattern, string) != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83f92ca3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q02_09</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q02_09 results: All test cases passed!"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q02_09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cba24f",
   "metadata": {},
   "source": [
    "### Question 2.10 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "In this final part, your task involves more than writing a single regular expression.\n",
    "\n",
    "Complete the implementation of the function `match_10`, which takes in a string (`string`) and:\n",
    "- converts the string to lowercase,\n",
    "- removes all non-alphanumeric characters (i.e. removes everything that is not in the `\\w` character class), and the letter `'a'`, and\n",
    "- returns a list of every **non-overlapping** three-character substring in the remaining string, starting from the beginning of the string.\n",
    "   \n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> match_10('Ab..DEF')\n",
    "['bde']\n",
    "\n",
    ">>> match_10('FINALS are COMING A')\n",
    "['fin', 'lsr', 'eco', 'min']\n",
    "\n",
    ">>> match_10('h9i9hOWW44areY@')\n",
    "['h9i', '9ho', 'ww4', '4re']\n",
    "```\n",
    "\n",
    "Here's how `match_10` should process `'Ab..DEF'`:\n",
    "\n",
    "1. Convert to lowercase: `'ab..def'`.\n",
    "2. Remove non-alphanumeric characters and the letter `'a'`: `'bdef'`.\n",
    "3. Starting from the beginning of the string, there is only a single non-overlapping three character substring: `'bde'`. Hence, we return `['bde']`.\n",
    "\n",
    "Some guidance: \n",
    "- Perform your operations in the exact order described above, otherwise your code may not pass all the tests.\n",
    "- Don't use a `for`-loop. You'll need to use `re.sub` in addition to `re.findall`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d5ea941",
   "metadata": {
    "tags": [
     "to-py"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fin', 'lsr', 'eco', 'min']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def match_10(string):\n",
    "    string = string.lower()\n",
    "    clean_string = re.sub(r'[^a-zA-Z0-9]|a| ', '', string)\n",
    "    clean_string\n",
    "    out = []\n",
    "    for i in range(0,(len(clean_string)-2),3):\n",
    "        out.append(clean_string[i:i+3])\n",
    "    return out\n",
    "    \n",
    "    \n",
    "\n",
    "# Feel free to change the input below to test out your implementation of match_10.\n",
    "#match_10('FINALS are COMING A')\n",
    "match_10('FINALS are COMING A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c3cc1d9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q02_10</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q02_10 results: All test cases passed!"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q02_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48857db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 3: Capture Groups üì°\n",
    "\n",
    "---\n",
    "\n",
    "The dataset stored in `data/messy.txt` contains personal information from a fictional website that a user scraped from web server logs. Within this dataset, there are four fields that are of interest to you:\n",
    "1. Social Security Numbers\n",
    "1. Bitcoin Addresses\n",
    "1. Email Addresses \n",
    "1. Street Addresses\n",
    "\n",
    "Your job is to use `re.findall` to extract out the relevant pieces of information from `messy.txt`. **Since this data is very messy, your function will be allowed to miss ~5% of the records in each list. Good spot checking using certain useful substrings (e.g. `'@'` for emails) should help assure correctness!** As usual, your functions will be tested on a sample of the file `messy.txt`.\n",
    "\n",
    "Note that there are multiple \"delimiters\" (separators) in use in the file; there are few enough of them that you can safely determine what they are. **Before attempting any of the parts here, open `data/messy.txt` in your favorite text editor and explore!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944f2d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 3.1 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Complete the implementation of the function `extract_ssns`, which takes in a string (`string`) containing the contents of a server log file and returns the Social Security Numbers in the file as a list. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> extract_ssns('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n",
    "['423-01-9575']\n",
    "\n",
    ">>> out = extract_ssns(open('data/messy.txt', encoding='utf8').read())\n",
    ">>> out[0]\n",
    "'380-09-9403'\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- For our purposes, an SSN is a string of the form 3 digits-2 digits-4 digits.\n",
    "- The returned list should not contain any empty strings or the string `'null'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "875381e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['423-01-9575']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_ssns(string):\n",
    "    pattern = r'\\d{3}-\\d{2}-\\d{4}'\n",
    "    return re.findall(pattern, string)\n",
    "    \n",
    "# To test your work, first run:\n",
    "extract_ssns('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n",
    "# Then, once that works, uncomment:\n",
    "# extract_ssns(open('data/messy.txt', encoding='utf8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24c42309",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q03_01</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q03_01 results: All test cases passed!"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q03_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93786fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 3.2  <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Complete the implementation of the function `extract_bitcoin_addresses`, which takes in a string (`string`) containing the contents of a server log file and returns the Bitcoin addresses in the file as a list. Example behavior is given below. \n",
    "\n",
    "```python\n",
    ">>> extract_bitcoin_addresses('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n",
    "['1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2']\n",
    "\n",
    ">>> out = extract_bitcoin_addresses(open('data/messy.txt', encoding='utf8').read())\n",
    ">>> out[0]\n",
    "'18A8rBU3wvbLTSxMjqrPNc9mvonpA4XMiv'\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- Assume Bitcoin addresses are alphanumeric strings.\n",
    "- The returned list should not contain any empty strings or the string `'null'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e18bda3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18A8rBU3wvbLTSxMjqrPNc9mvonpA4XMiv',\n",
       " '1EB7kYpnfJSqS7kUFpinsmPF3uiH9sfRf1',\n",
       " '1E5fev4boabWZmXvHGVkHcNJZ2tLnpM6Zv',\n",
       " '1DqG3WcmGw74PjptjzcAmxGFuQdvWL7RCC',\n",
       " '1LfacbqCA7NZVq2u5CTTZsoEtncYuBWvNX',\n",
       " '1DoWjNx6PGwPvMQ5P7zeLWg6hnbGC184td',\n",
       " '1FLuKwdTrCiMrdS4wmRKCJfTRDZsq5f2q2',\n",
       " '1DY46TrozvX1SLvGH39Nc2kfx236gaAoLA',\n",
       " '17fo1ZbViKPFGiPXhNsAU8NUyw5bynRxDX',\n",
       " '17ZrXccNfAdyVt7DTqWDXKgdhmYtYKnmNN',\n",
       " '18SWMUwCnwHxoFAr2czJRsSBQgF8oCWDTu',\n",
       " '1PrAha8iCktRM2J67VXivQucjzvsTRwsd8',\n",
       " '1BovwmzX7oLyNZX76LqVy5SJKQLBYA4d7c',\n",
       " '1DAb3G5vbWAotDZrdQaFu1NYCTsEEgxWpM',\n",
       " '1L7UMt4HmedHLeowz7TAmTtgPKGzTHM7H3',\n",
       " '1CaBYBD2Hz21NHpQ266iVxZ2ZKjS29XvCp',\n",
       " '1NsK6BVxEPwxXLMjLkVkVLQzbjqLLEyT1i',\n",
       " '1AyiBohjtgByzouVbpCp2LqV2qATy5Nvgt',\n",
       " '1WtiMLn5TYheBkLQ6D3Vr4TjmkyR8aNLY',\n",
       " '17LwuggjFmVWYwDLKJ2zrxKrs6d21FMvij',\n",
       " '1FTXfdD4ZDsBu1ht3KvkPEd5GKFhTj9Pri',\n",
       " '13WNKycmFaQvbyARgMrvn434kmDRQQWzr2',\n",
       " '1LMRBCHL4Hi4aQR8nMNAYErrBVGLjXX5dv',\n",
       " '1KVfRPSwDTbAu9feKFSqFBap5swajp56kn',\n",
       " '13HcgY6Vn7oFPAzYnARVtZQS4GDbb7sfqg',\n",
       " '1GyFrbAJwcGQugdPBs7ecdf12BUqhpXZpD',\n",
       " '1HgSpAK6yXKyRjSwMEpMMWwtBVeGVZeV8s',\n",
       " '1Lo9c3f7GAFT5sEPTsrvVJZU5dAeVCspKA',\n",
       " '1Nb6dSCX741ecD9LLeGFdw95CSKSt4cgJV',\n",
       " '19gH4EUZr1BZGLfyH5KaPSvRtoJpvMW1G8',\n",
       " '1N7DnvqnsqiPYfscMNpXguPCbrXxwJzzgg',\n",
       " '1GKiUdMny3Sk5iVaPHSLmStJEe4W1r5QtY',\n",
       " '1LWCN9PwgaiQJNHoYfcWyrdWNt3xAy67fR',\n",
       " '19UFMjbBFoSqfXgB3fyTiT6vUFUJQ5XPuh',\n",
       " '1Pw98qLnNpnrVspwHfKb4AjcXgfSfWBCMo',\n",
       " '13dqHNVq1uBTsYnxYw1gM3vScuRLFidSip',\n",
       " '1M1RkE85MqsL56ii62QZaPMhvsGgAxBv3h',\n",
       " '1E8aL9jQGSuHE5PcttnH6k953ze8uaxYmh',\n",
       " '14hSyjBDQpHu4UPVT2MZK7R9gRX4J9QnDz',\n",
       " '1MSCbxCEdXPtgfLjMzyySShdHoCB6yvbRH',\n",
       " '1QDDSf2sWb9VdYuiWMerpmyuqg4rK8yup2',\n",
       " '1PzFgCsHMxZX2XTQBZ79Cx2tsieyNrc6UQ',\n",
       " '14s1Fwew7vZzB62UhCL6pjvNaBuurETnsu',\n",
       " '14rwN7qDtCnxjXzWdvLyXH1EM3CA2aZXUa',\n",
       " '18UTRBbN8vnQiFqNkD132A6SXLCJ7XxKnY',\n",
       " '1Kt6eSEanamDGUhBCKdnvqpkF5dkST7Mzs',\n",
       " '16t3ujSmkT26ZXLAwqxKSRAmBkF69ab6QR',\n",
       " '1BW9U1AnBPM1184G768t4MPGLGnGGy5rzP',\n",
       " '1CE68afBMCwbX75qcKUutw2xHfunNGk8ga',\n",
       " '13yMK1GrAvxpqteCSU1SmMDcaMR8xZdJUe',\n",
       " '16CX5HG6qNkL2m7JjCQLyg8Q1yFkBbEPJR',\n",
       " '1KHprX6Wgek9ALG8aUEjPS9rN7bPbenfdG',\n",
       " '15KpUWSZFK6bpMsrK7AbLkHApCFqwSVaqj',\n",
       " '1PpkaEGVik1NWBnSyCiVzxv6p6Xbmfngq7',\n",
       " '1ExC1BwcKZqNdSwRKBUSGrPBcfCpf9gVA2',\n",
       " '1CChqa4MiWM1VqbbGNLnTpDUvwv4vrNEFt',\n",
       " '1PRESqp9tKgGn9Yf8myTxXfdCtTPDJc3cc',\n",
       " '133RWCHnjCxVA6Mhh2yM6PPkEH2YJVwmVP',\n",
       " '1DHk11LfkWAYBhXYRK7G7xqqAovBsEmbuZ',\n",
       " '18dEvLQ7AMEF4BTSKJm19WeRf6K31r7voi',\n",
       " '1GVoQ4nNNbvzh5LVxQnbZn61eWWZF4mdty',\n",
       " '19D5xTA5PLyVRmRcnH2jC8kWpcCuMXJwqL',\n",
       " '13XLSN1kmnFygGnhzLghJyZufFewbMvVc6',\n",
       " '1oofLrxdJaUBjzvsAMinTQ3ru42gCDA1T',\n",
       " '1EHN2QdHu1BQQVKTSKX8w1CzwewzLuxJev',\n",
       " '1Jyy9HusMQXiWiDkJpcdEKCghVAnfyiLU2',\n",
       " '1NSXUxrKvHidUcdUF37Swyqwpq81LxA4EP',\n",
       " '1JPmFTow8ZU3WLkRpQvhJzFR1v1qfhWvcs',\n",
       " '',\n",
       " '',\n",
       " '168G3iCELcLYgAm8GJ8VJiZTBLr3i11rFi',\n",
       " '1NxNjNdXV2qCVVLDx9Ghze15saQ4aCxU6x',\n",
       " '1Fx9uuoTaLgBUGsfm67VjUaAkaTDHttKv7',\n",
       " '1KD5BtUxSZYdPqTwR5eXZmm7DpiwqdSXuD',\n",
       " '',\n",
       " '19NDSisceX97gQK6s1YUexQ74axA8moYhG',\n",
       " '',\n",
       " '1KwVvYaSZAPfu6AtuemYeHJ7aWf8L6t34A',\n",
       " '1MssPfuM5wZDiDDotiBVsjGf5ZqSkZ5Pap',\n",
       " '1NtyUwWFonUdr3XDZqVHSrJKwLTFcCN9GU',\n",
       " '18gzHpogHpkHLeUt51vqgbuhmJ16EbeymF',\n",
       " '1NhfdcpHPk9RXAjEbhRpNJrwoQ2Mcd8Xjn',\n",
       " '1EwLTQqjFWEAuhZv82fL46zT1PqeHTKKH6',\n",
       " '1LWR9jLWXNRj8DTzHdxFStdyuPphew5Hi2',\n",
       " '1H5z8mCtMiFeSYfmg5SGDPne1rY3mCjKmn',\n",
       " '1D3phxg3tgG3QnDT8tjCihY5rSjg7afNUE',\n",
       " '12J9DVR2sPp7j1t8pwLRZrZrMWZD2pEY9o',\n",
       " '141E3T7NQXRaJa6BLmBy5GiRP6u7SQx9vi',\n",
       " '1NjZ6HktRS11spA6a86DbPUpcNUjgCx96Q',\n",
       " '15bTH85bYUKq2AEBPc8Voe5uwyEn8rbmgB',\n",
       " '19X1bic5RDdDTtdSwjij3UPVkodDqDdcNb',\n",
       " '1MB86LgUsHDRfkNW3kvmSFiZhm5S1bxo7K',\n",
       " '1vQaF7A7KefhDbNQpnfRq7EGj84AfkhEc',\n",
       " '19KvHEa7uAv1BBtomxf8PPjRoQc9AR43Sq',\n",
       " '1PHRUEPsftcmuNFUsjUqenJHVwZcKpJ7up',\n",
       " '',\n",
       " '13qE2XoF8TVVjDPtqZkdEBCsDgz34abmTd',\n",
       " '1HQqQrxSmwooSA1udMK6cKZXPxx4TVUk3a',\n",
       " '1AgVZ2vyKzCSSo6Pa62by2ML6sVyGWNb2s',\n",
       " '1FMcyxaxURvhNJLnYrV7vXRsUn1ER3sju9',\n",
       " '1DayvpftupRnTEXFfXWv37JwoZ9to7qhQ2',\n",
       " '1BjEvUFPFfgK39a6oyQpxSrSLRwPaZHZRe',\n",
       " '1Gu7jLd4PSqWKzNzVNkmKeymRvkPsoX5Jg',\n",
       " '1BiV8Q2CDY8byTwYAp65YKiN2E5jMUDu9E',\n",
       " '1EAFtX31jYtgdGzjo92V3Lzpwa8Jy1QHye',\n",
       " '17nsAeyKSmfrWcXD4tWatk2Pzve73xhR8t',\n",
       " '1KpyPx5UmtZ6ASygwGgUoSLu4A44x23Ab7',\n",
       " '14i5JTGRsV46rUDrY9mXcmvYRLakNk9e2x',\n",
       " '1PjdRYMJZjvRPazCeaKo6e4TyQG9467dpi',\n",
       " '1MDmtphms249A85EuSY8DCuiunW6bqvqoX',\n",
       " '13NejjR7duDR9rzSfDS5BUqj4MCyzsNDv6',\n",
       " '12NMKYcpJzc9YQig6pN4hz1WZhRpuFhKfD',\n",
       " '1H7DXs64AUuovxSDpPr5TrKZxz87PUDrGx',\n",
       " '1L9YfAK1mKUaT5kpXrfaEM2EBsM8KWWBpi',\n",
       " '1LeCo7vpJWjHWMJPwf1uNw8YLeCtdRFzat',\n",
       " '15CcF7qmgPMKNtvZWMtUgzvg4ZMBfrGqXS',\n",
       " '1MbJburZb5Y7QpJccGSnMu3ybAoA69gLKh',\n",
       " '1GmBh83YBzLRJVcKWzYV9BZZ1DAy14Fk1Q',\n",
       " '1AjcVZ436LxLrKDJzWVe6movHigykqN7it',\n",
       " '1NwaKeZQRytbdZZRbpoxpmLmKwVBjiwqUg',\n",
       " '16Trc2w8Dno3Rwdv1GeEdTeZGAyZexUoSH',\n",
       " '175rnxjDAtV9rjeQLWPKaVTz3u5Hnofuei',\n",
       " '1DzKQvoJRZUMf1DynKCDACmR9ypYzDswVr',\n",
       " '1CbWvjNEtP2DWpLVh5tbfWbiLvj5mah3vf',\n",
       " '1HqedmV2LFdufFpdRhp4FKM1eLy5ZXFche',\n",
       " '1LiHqg7oktxZ89REgAPQ7RY9MpkSvMCUwt',\n",
       " '19GCF6Xb6wBSxs6on3AhwLKpHoSEySPPiQ',\n",
       " '16jU7CH3CY8f16tAfMGN35XUjEYRy8bF7e',\n",
       " '1HPjpAfx6DLcPVWZZtw2u6BLqbpDus5hZw',\n",
       " '1LoFpgNhozMqWdo8vLKWNwCWhzEGWVHzJM',\n",
       " '13n5xfbL7E5rhf7Zm7n1s7s9y7Yhk9nDBV',\n",
       " '1FgdP4crEuuaeBSdvf68dBBtai3rLq6UQ6',\n",
       " '17yFk2qvYyX4Msg5fv4TyGnyhoJqvh4W2o',\n",
       " '1GieJGbv2mbLKqmUiwnnpuiRMVdHviWe8a',\n",
       " '19pdmsR1UJ4YhX9APEhcfoMDjZoxnHeHM5',\n",
       " '1CQXatREkRMn6C6ojmSUy3jmX1jPnRSjGs',\n",
       " '1FCWpNrEKDtVvoxKPk1J5BnQ1eyLJRrSX1',\n",
       " '1qted4dQLbmpjZsaUX7NXSL3Uz1hunX1k',\n",
       " '1DsniM8PTW7mrxqUZgFWYoqQRJTXFMrKEc',\n",
       " '1Mot8DoZxNJATwCZNY5vEiz59QrY4pZQSL',\n",
       " '1MGLAtBizahrEoAXyjBoR54fTHH5pacUgM',\n",
       " '1Ac1eRocj4HgdDjuXB1EM2aauETCz66rEF',\n",
       " '1BpSfZcj4wEXCvKp4SFH7SqpVoYH3Y1y1U',\n",
       " '1FHbPRsv711J5kwWxUY5A5f4yktQ2ZbnvM',\n",
       " '',\n",
       " '17tpFLBW9ETfWMVWQXiJcZs3vhUhyeKWCm',\n",
       " '1GhTWVFvudNZY6eJv6zWMKDodPz2fJ26w5',\n",
       " '16JiX3x6WzZHjS6a4Y47cfTbiA8bKvXnpF',\n",
       " '13QJnhdMMrBpjh5TaLhCFA9U1yoznqoL93',\n",
       " '',\n",
       " '14gkYT47Dke2nEZwynEVyQRBpaz24uQE8v',\n",
       " '18G2h7iW2hPovzqdc1PCxmtnUUN6NF31JU',\n",
       " '19JpTCWqDfgQotxsJ5ecw4uGWdf7NnUBRD',\n",
       " '13CYidS7DWtWFNkZE53hGJ8Eg3msaEeGcM',\n",
       " '1FBa56BzRDRrc2NgcBZpMAzPXRnGL6sh91',\n",
       " '17a9WVbLsXpa6cXHaScoGb34dMqnobNPFC',\n",
       " '165K3R9W7p3qW7uK5uTTPDMYczcx5HBXsC',\n",
       " '133ZgE8Do59p5LhhjLr3RYmZYCvXaM5BBi',\n",
       " '1CdjxQhafPaoiq94BnDzjzVT286T6RCGoi',\n",
       " '1Jkkm5aBx6FhLKvndSZZrYoawvUtDgbMjP',\n",
       " '14G8Nxv56G2Z1usNMGzLqScVZL44U4jM6E',\n",
       " '13PQfYQ5vF3LhkG2jqsmLyK2GDbV8a8mee',\n",
       " '1EPLNihPGN1BKk4K9ewmQAnD9yLYNXFozQ',\n",
       " '1PVCdH6TkzLZk3pdMjYQsSbtXv87zwd1ZQ',\n",
       " '12TcbtNrmctX31xeZHvcBLEZUgmpGXNFAa',\n",
       " '1CNpMJwgDtr63CGW6LFz3pGB2nEcd5Ap4v',\n",
       " '1UKHcFatn4pYsLi21GMe5GRKUoJGAkF8F',\n",
       " '143Ms1Jk4TjVCnVYrqKzPh6xWWob9uLdVX',\n",
       " '18KbtwtsDYNCv19p35ZEkz1e5juNK9S6L1',\n",
       " '15EiAkP5sTrJox4Dr6Jhx3cpYL5mDmwcJX',\n",
       " '1Auej33Si1DcpjefNyNnSoLCr6RM1KN8S7',\n",
       " '16HDr1mdyqogqwKi1Ynb9u6qMMNEMVExxY',\n",
       " '1CgtdH12sQgHRZ7tStQygoLGwzDgJ2CFPu',\n",
       " '1DJqBHFPfxS8yzu4s79w8DSpvt9ixsXmFy',\n",
       " '1E1NFE178bbcWcF5gskSBmh77YmGhjeyDz',\n",
       " '144AU55R1CHs7pQLC8Rd1nh3jjkfqD53Vs',\n",
       " '1A38Wh3omNzrjU7L2ymHvvSsLT1ZijwtN2',\n",
       " '1A3aR4FvDEuvTiyGP1Sd8J2YeLnxr4Yaeh',\n",
       " '18Mue5GAicxLPYk9R9wxJcDcNkoe7vrGK9',\n",
       " '1HE9qSpNNunoyNF1AY2NChofNaQGHMh12Z',\n",
       " '15DHQXr35CUprAhS2FoQE7QU1k7X7wh9AQ',\n",
       " '12fYJn99k7mNhDFzCTpD2THFoYyjF1NyGA',\n",
       " '1ri9zBQFW517gSZorBs6TipftSzGuBMqF',\n",
       " '1Es3fC4QDxTagFzANJo6fnX7WMmsarPEdZ',\n",
       " '1K9KuF1CovHqQ8FPwqmN7QgXSVkQzAo2E3',\n",
       " '1EwJhs7naxvqjMWn746HJTSTkkqncASgmF',\n",
       " '1NoseMAwSzEbDz7p2CjwdVPpybUmXzR3xC',\n",
       " '1A6MZ1ep9LCzQYFpBX2uavjndX8LHPpE2K',\n",
       " '1LhuPWT7n53Q1ABKwAWsxknsm8hKhJM7Ku',\n",
       " '14SDkN6pkyq1U71BAXZ2bQCvez9VyZAyvF',\n",
       " '113KWAr4FEjjTABa24gVNyqCg4iAVhhgtr',\n",
       " '18VXWMyf55MLXAmDgwQvxEznqoMP1USR9r',\n",
       " '1VoTdqUaGT8heJdtkWVi1Rqj4UnDjzbBe',\n",
       " '',\n",
       " '16D9sWQkQUckxEcqjdjSFTnKJx5uyvdapy',\n",
       " '1DK8bei6TCgnGZkdci42UCpoWnd82h8cvy',\n",
       " '16SXuhvaEGSx8qHEfDJjAucZevUSgH3f5Z',\n",
       " '1FSMzJWEpwy68MhkottofK9TWTypAcvphu',\n",
       " '1A3z59Z4vYswJnvME7PyYQE9jURBFvQ36M',\n",
       " '1H82n4hTgAUGnHm6GNHmFXc8pWuLctFGEa',\n",
       " '18uXP8xfFEpBjVR9TaZCF3U55D7h7ty46A',\n",
       " '1J9CbDYCNAkm6nYQ3zfCd2QkmSdfqjqFn8',\n",
       " '155iJKdVBwB8ZeoNSq9GG8qXPrqUuNsKKA',\n",
       " '1NZoMfpo6MNNSXKNAF5zgBPgDbFbJZRsPD',\n",
       " '1A3VnpyE9tbU18dmZK8iZetNcsWujBqpys',\n",
       " '15hdFs9VvEpYWK8JMDHDTzmBGpQFQeZ9P9',\n",
       " '1XusnuRet9Vg48nyGmz9kxckDQGwCgqxN',\n",
       " '13ePGVL596a5xtiFuJ3fJmA7Fe9rB7yBM3',\n",
       " '1JAJdPvUeUKd6UUhoCCjGvbzM4TcDfsBjN',\n",
       " '1MmSLtx3stnA1TMmNyx9itecozQza9Ah1e',\n",
       " '1BzmdhwCwjz7ixugZSknj41TdZjaWNVni5',\n",
       " '154g2Z9uBAkFKG7kZRdmeZoLtP5vfYLysj',\n",
       " '1F2pcokXggsTHoq8Vt5sJy3cmyMkNSguqv',\n",
       " '1CeuCdZ1NV8t8a5qZg6Xib1ksVKWNMSs2k',\n",
       " '1BAfgMeJQ4f275YDyKF8JcmfWaAg5Z6wtS',\n",
       " '1ABqjseC1G4qzCiLWsgKVRmwjKNhkuwMaC',\n",
       " '17AsobycVRGuU5HrSP3aMxYnCfLimP9ynw',\n",
       " '1ByudqPmxnsYABLvNuTqqj5SMbU8PMPtvD',\n",
       " '1GNWoP36VNuNVQU1iLwxqH9X3RBz4wyLy7',\n",
       " '1eADAyWqD64fqxzeCtrXBBaQCTvm2kg2E',\n",
       " '163DWjcwGsrN1Kzgx8XpzeryBs53u9krnG',\n",
       " '155uAAgYojmUNxN9mtVLTcKChgPn3aZ2Ye',\n",
       " '1AD7nGfJ5tkFss2848TzoXBqCBhv6fBQcS',\n",
       " '1GBC92kd1uMAURGzNkMLcVfzfNj4jGaVB3',\n",
       " '',\n",
       " '12cwtr2cRQf14TZtQA6jiuZwKbokxm9HVB',\n",
       " '14Rbs7tRDnq62fA3Z9P1mHVPt5Rz22xWD2',\n",
       " '1NpjKLG1BGdmQzMrm4RVoAKUbeHH7VeuH6',\n",
       " '1NVQs7SCFYXAyPtJrtZBxFn7giZbV1ckx9',\n",
       " '16YpWsGBChp3YYZxWJp68DW5YB5YdygnZu',\n",
       " '1Da918RurpfgTnDYAuiXvkgfwwMnEESMBC',\n",
       " '19iDDzMJy7ycm4fnKgaBz6kpMftUaU4vmi',\n",
       " '1AdS5KYXnwTQhMwmJ3t6DZfWxuouiX9tUw',\n",
       " '1jW9x26GsCtpXb9eRc8A8sMwtPh6b5cVE',\n",
       " '1Ac5r8wr54tCFG2GnWUjVVHYqjxgCKfbrp',\n",
       " '18SeRFLJwj2SWGm3pueCjzu1gzcT4Ztm4C',\n",
       " '13zPrZ4bgV7LJ2EXLYqtoUKUBTHwJnQL3N',\n",
       " '1LZc4LkQF9SxXs9d5p2SApAbMUV3dMtGEc',\n",
       " '1HLtFaAQaxG4AyKohwM45C4UgmCZ3Jxn4z',\n",
       " '1L7ae1fkjz7FNMhgX9CScfNe5LY9mqqt9J',\n",
       " '12QoJEaW5V1i4Bwp81ueYuBaLqySSdaEVa',\n",
       " '14qi5pR7bT8jJTmTvLzaE56kZRoFHFyupf',\n",
       " '1HvQhxPDjZHXVAcpSX6L5KH8ycTCUpiQfi',\n",
       " '1CRXBnn3XvQFPh5QRxr8tGBxCvdXdEmxxh',\n",
       " '1A59sD6mTdXsLFFQKjFFECGFCGUgP3EASp',\n",
       " '1FmYLdzFNxp3915aaQakUjQu1BPAKU9bbj',\n",
       " '14BoRpSweXjEXs2rLsFSink5zCwANg6fEn',\n",
       " '1MhhCos2oEWWtda6dXpkkKB19NmQHfPLpf',\n",
       " '1Amh6MY4VQjqgrbNsnHj4yixcTuWqBHfxJ',\n",
       " '1L8QDBkW2NR46b89PkYqsxWkxuc2Qg7K3n',\n",
       " '1JcUKerN8pUfGhPa5ir5LSeUALSoK7KxcV',\n",
       " '1938Dyihd5iMKPLF9qGbkhRroFtYTKBnva',\n",
       " '146bJZ674dzucLnuaXbyECoJf6gYfzKBzf',\n",
       " '1N1xv5SjdUAb36DSgzYnHrqGNjq4PsrZqq',\n",
       " '1EVeQ3KNXDsDbfhk6Yut4rmUdAhBB9FjpH',\n",
       " '1Mz2C9ZjaZqwXtbjqUx5r4Qh4fnXzSS8ag',\n",
       " '1DfvnumCDFLk8LSacPHk1fCm39seFW37mn',\n",
       " '1HFb4Qz9s6PUYBvAuaKPxtgLXTiW76yyBm',\n",
       " '1EGcJrGMszTpAetFA5C9VkDwKjafKAf8TU',\n",
       " '19jyLy5B7BnPKDqaRGTzaCKCCsTgfWcfff',\n",
       " '1DxrztWMCAaZzUGLvYx9BAmKZjmpGTRXS2',\n",
       " '1CKs8joHw6xoob15qBNi1oJMBSKbdxWWHp',\n",
       " '1EJRbmNJg3ZkVSw8tdjQAhMBTeeK6hCBcT',\n",
       " '1MR8b12JuM8MWYFi6yeu25mcf9Tsq2Uo4w',\n",
       " '1Dtk2qQuoEme8xjf9pP1gHYNoQUHFLyGAQ',\n",
       " '1aneZjr4BvATBD6VP7dq1gyryfB3mwxK8',\n",
       " '1CVThYLcVgxTGTNd3r2U18YyRzticAYZYB',\n",
       " '1PKMNnw4b1mcpBUcFRH5PJbhjcCA5UmrEd',\n",
       " '1DnJT9imUoVVqiiqW9kYmnuxdkEQJC3w7K',\n",
       " '',\n",
       " '1LRQTQKfRLgfa9QKb67qdmPSdx3RKqjdGm',\n",
       " '1sfJBHxNPUwxCaeBkTj4xVFEnBygYoSj8',\n",
       " '1EZ1vPb2qSE4zLSZhVxpvLPFFNweM46PV5',\n",
       " '19XAJckNZ2gxjoomECajBBt2Pi4ENCEVvX',\n",
       " '1AWwWj9syLmqYdipN9hnM9a5vDNbcVFNrC',\n",
       " '1GkPgXoupbfLqW25qtrDwdax5ytDKNMNfF',\n",
       " '157A4chZktDVTjcohi87hSkK58tT2PmcvR',\n",
       " '1GYTygPXmM29xWnQbpHyi8UoodWWAG45UE',\n",
       " '1BFAYktoSDeSeJkAzacYtnYw8b1gPESspr',\n",
       " '14REtF16rnJcpsePFure19hWWuS5MY2aAE',\n",
       " '1CF9BZJmEzLrGDokzBTntHNTdrR91G8Kgm',\n",
       " '1KqKXKsiKGsvoJCm9Dd2EJzEHbj35jMyZg',\n",
       " '1GbDcWsFSkpmWgbpdfuyd11ygMWaNBLAPR',\n",
       " '1MpanKxM4TYyivSkboivHFMcGD4QVhqkQ2',\n",
       " '1Ds2cphmD6HzSaGWNiiCoLJpVXqBjcGEWA',\n",
       " '13sthj7mwUkpsR6oDUSDwdgodNxmSbCe3R',\n",
       " '16sSmYjF27cLdRHLCTph31V2sY8XNucukX',\n",
       " '1JUVg1wVccRGpTTTSkMNvJRxc2P6dAntG1',\n",
       " '1FwjnBHDXD2QmEkrspSkgzq1U9H2ZcqyHX',\n",
       " '14jMjLqEjhw7ZRiu8nUYHyHBnf9AzoaWjK',\n",
       " '1LFYKzWa8SmiJDuxGTVrEHAgpbSK9LcRhE',\n",
       " '1KJtM6RxL3Fp2Kkm7vpAhXqrovqp7SK8fw',\n",
       " '19LosFFZr1qhEKAVG38koTqaJ4tyZHncuu',\n",
       " '1EVc27MvXfGaYa24RUE2Eb1L7se2gjKbu2',\n",
       " '1HqH2oGexEqDQSUUq5W8NP3XKuqQsxaK3u',\n",
       " '197n4pZcdTgzeW38HFKaFdQuezdhQPLhLT',\n",
       " '15Gj552rP37ocTSRzCNcztwiDdHpby7HLu',\n",
       " '17MDtE7JnLRvSxhd9YrLst4YixksQTYULB',\n",
       " '1ErTR8dxgKS5esMcYadCPGsvJMeisVc9yk',\n",
       " '1E3ysBeGrJ3iwVsgiwYD1Yk3tRhzKaZuy8',\n",
       " '1PsvLLWSmcuaq2LnH3Zc2j8wrmz7L9i3E9',\n",
       " '1CdSHTfRnnNXLtyiGPFtqKFZkYCdW466TQ',\n",
       " '12VvVN8CE24dXnesFrn1Z67sfGqWV3ArJQ',\n",
       " '14QPiqSREe5XTbqyu2otZFbv5PzLKbgjHU',\n",
       " '1EDEiZCFX4sDg17oWbe5iYJYb8ohw5QfGR',\n",
       " '1N9X4Wdqd2aWu21NxuPioB2NpmxHYcgTde',\n",
       " '13zPVc7kNp9JcoTmXfDx2NJohDkBiZRH9j',\n",
       " '1BfXNkaUAvdrAjCxxu6S5j8aLc8HZE1PYc',\n",
       " '1J6LLJGYAE8pfHN461KdJjPM2tt6mGii3x',\n",
       " '1MmTgTuepgJf5kZFUffFS6tfiNQ14uMjUf',\n",
       " '19DoKxUBSCkcBbx7hXxB6x7xQJJEzJaKS9',\n",
       " '16TfPND3UvdeXFujZqBL2BTey9ikitKVS',\n",
       " '12vuPELEepyWacMXEvH8jA6GWLVKPfeeNj',\n",
       " '17sy7nKTLobkQa3nbPuCxz74DBGvHwVGXn',\n",
       " '1GFFXhHuZGvd19uVeERTEb3pP5v7mcMYJV',\n",
       " '1A9ikuiGAAfXfBjwfaRCJ2cUZpk9vaUvbq',\n",
       " '1BXFEaLnUnxfd5Ebn2LKCJsBkpPxH959ts',\n",
       " '1PtAo8uGihnDLyXpmMngEifUfYCPfzzTYE',\n",
       " '114rHaYbg1ZkgXFgFH9G22TKTaTLurp8uq',\n",
       " '1MCvvS2vazVQdfCtuJX91szAagWSLUiH2r',\n",
       " '1Az7KcG4JnKcNYj2nFV6iXw5hrcBj12zDd',\n",
       " '1qbw91qgf7RzSUoAww4Drs48iu2zVUxAC',\n",
       " '17TmhemiuZeRwbQVF6LPHYwdBegE1eb4YY',\n",
       " '19kshS2B27xaWqVkDET5khJcMAXwKuQsc4',\n",
       " '1D9JuH3cKYjciUTeyZWTSPVgMWcaTrxwMs',\n",
       " '16M5LgAqLLwhwxyPTDPjCSEUFE5zEL1pzJ',\n",
       " '1N9EyAk1YrTMjZKzKU3rYfdwurgino3RiC',\n",
       " '1FNkSBCLBUksDWLZSDh48a1yj4ndtrPETM',\n",
       " '17DzxEs6r6MKa244iB6zgy8APsqECnc5WF',\n",
       " '16MhfhBdtU9eowLjC96jvFbwWCQbCJS84p',\n",
       " '1CL2SKmBjP3Ms3SYMxWU4xKDG2rQ1HkXj5',\n",
       " '1PPdXvcMT3MvGx4wQXMJhUrLv7EUDRiMph',\n",
       " '1GL4GNme4FFrNkZRALKfFm3xUsZTzFWGya',\n",
       " '1GSk57tVtbpx5wkQ5FydP1qowZcYEtLXGC',\n",
       " '1KrxHPHEgcpmF5kaiiHFJMZZL9snfTPgBV',\n",
       " '14P5TsrxMV5BfKbPiUJeXMEmz3mCmvxgCU',\n",
       " '1BcFPANsMumeTwnhmJVWvYki6DVdHGSDaH',\n",
       " '16pfKoBDSsFGg3DfTmV6WdJuLLKgM3Rs3b',\n",
       " '1DDjmbGRQfNyxLYCK9ScVhkAEsTZZDRHJK',\n",
       " '1C5P6PVkfPK7PdJF7RimXGf96Qm7YY2tXd',\n",
       " '1H4VUaUJfXKeSdLc8pGdoWou7BJbFsxPhM',\n",
       " '1BUYgLVGT8SadQiPYDrM1de39kQzQ8JktP',\n",
       " '19cwNDdMiBVimeFsBdRSBb9SubEkEFasQA',\n",
       " '1As3syUJd2fn8JxkxJQVQwt2ZNjtduDXkW',\n",
       " '1NseKX4WjZ2PrMVUL69x9BJ9muMF68dTvV',\n",
       " '14zyEdJZHygGyoojpAvebKfdFbGsun2cgE',\n",
       " '1PWMb4ugPdgeCnxJmyR3MvWrVbTWDKVg7W',\n",
       " '1LGjbMZ1kJRWARqgXTSJkoEyzwYPCogAwf',\n",
       " '1Mzq6Mji1Ei7Xa25tRdSPoDhNXum2uRGfU',\n",
       " '1ADEVHdKroPuaqJXTJn4pWSC8KWWPZtCMM',\n",
       " '19ZtJE4AeiEUUobiJ2vyvr6EYePzaE7cJW',\n",
       " '1CTqDzsG7f1pvQ3urLPNpoaYyx48y1dmo5',\n",
       " '1C64vbcUuvwoRYvMLAyCaPrmmxfnDNFxiD',\n",
       " '1699ym1hGT6HDam7JpXzMPuCsragx56KBX',\n",
       " '1B6WYpEMZFSuSgGivAtrwQtT4zokwaauoG',\n",
       " '17nbT6nAg2pioa6yYTAY588yoFgvkKBzYr',\n",
       " '',\n",
       " '1Q7EXDAF2FPqHbzsE4etqBHJHE74V8BGSm',\n",
       " '1EZdxdHKEcLjE9fhkdhf9vBrEYT5czAZjK',\n",
       " '16RNoNSYKzviSrRW9k4oViFYMeesGBM84X',\n",
       " '1LYSGetbgs3C4Yfkz4GAsc6ch7VUyKN47L',\n",
       " '1KRvTMo52Nmjb2CZgnYAsZyKRBQddJH5eW',\n",
       " '1EmvJf4KgdmZnkUgp1DjzghNdQVx9iWg2T',\n",
       " '1FDV8w4iDHnhipEATcJnRtcQssiBsTmmBu',\n",
       " '1FfQLmteRWGmwCcXyZtRTtAvirDAMbYpXG',\n",
       " '173TTh4isfpnnH31EchRZKTZQQmcZt5j11',\n",
       " '19Z2fLdWqezzMimmF2eRVJ6BBHNuu4wjBL',\n",
       " '19Q4FvHvXCBZGxwomUtq69FuA1s7DSoMQe',\n",
       " '1A1TzGgEq3REXgFGo3RcC9MEc1beXZ6dfm',\n",
       " '17T8UjL5xpRZiUfAGQr5hRPW5B4YoUWeyK',\n",
       " '1Kba5weSYF6oT3NvE29jrszzQzy68bzYxh',\n",
       " '1PDm8m4o3myBfoA69AiwvzFVst5PZotPLW',\n",
       " '1LSqVyyye5qBmvkfeSHkr9qo4E43aQcMAh',\n",
       " '1rLWQEW3NTFXGo1m1S4mR2UxYCdf1xSei',\n",
       " '1NUnrxsVbS8Sq8NaBw63PKcM6z2heVvLmg',\n",
       " '1LwBiZqn6d3AiDpXvU5JmesopCd8odFYnE',\n",
       " '1Mx1RMrcEXGj9ekZ788AurEeUeV9NH86fL',\n",
       " '1Kf89Mb1bDnad5Yh3BNAjKpaArncaH1fi5',\n",
       " '1NoMLBLsuWW38nJp3kva4E4V7f4sAxbM9H',\n",
       " '1ARUm29e5dWUmZzYt33t7XYSiUonB9reLj',\n",
       " '1AHG2GXrGU7MHt1t6aH9Azd4Gmt4fCezoZ',\n",
       " '14V39SGrR74kqcVyGS3fH2z1w8ZVJUwVKP',\n",
       " '1K4h46JVEUz3g9J4QiYm7ebLpAWsvMWA6g',\n",
       " '1QHpAJaQfbPrHagqUEQTJAdRnRfcfQ47LY',\n",
       " '1DkHkW2LhK8LpksTnSLN5pRtgzSeYazpKx',\n",
       " '1BqY3hU83CipeuaEKvHm7NgBn7iG7dSPQK',\n",
       " '16Yymyd8pB484uY6JZ1PJ61eQYJ23tAHtY',\n",
       " '1JERHF5noNqkkB6LJK64DHXGXxvNwns6Fh',\n",
       " '1MF8H3oUZvcfQYH3AaGwVGFtijkwPdp7QW',\n",
       " '1EPCcpXXq9VQnkskfzC3stkT356oZXPg6m',\n",
       " '17ckKSCFumVXdwveuJZgf6aJJQdD6XND6q',\n",
       " '1hSywfMZsnjhhoYKYBFwe77a7v4z8pCoq',\n",
       " '1H5a3jsgryYFdvfB9KUK24sThaNr9GzxTu',\n",
       " '1Efes3cc9rY9drKv7kExteAbMaj3gKNBRF',\n",
       " '1KHDjK1mm143xdL7kqqquS221gUCHW2Frg',\n",
       " '1K4kiFjJEw7uVdXwDki3jMSVxUCwRTG2fa',\n",
       " '1GA94gCKb31dJptiFbb8axrBYT1ibwcaH2',\n",
       " '12hnXxJ9e3K1vqTp2KrVM5SMbH7961yy32',\n",
       " '16xastC9L4dPKKdjnyjSgabQcwqX2JhUW6',\n",
       " '',\n",
       " '1PQ7fAo5uA9UwF8LoqB9Wp3LxXWeJGPFPx',\n",
       " '1BkgQk17CcHj9Gg2yHPJnuMdCFrTcF9k1A',\n",
       " '12g2hqYthhDMx3KmVCj6GUWoidZ1Wtp3V9',\n",
       " '1JSKBCtSwVpUogVMmoFX5qUHSqWKSSDTFh',\n",
       " '1JY3JzCqws6s6hVvKg51UE4kQ1JjoKoTAC',\n",
       " '15e3WgjCSz3jFrj2z68N9ULto852AhQL7L',\n",
       " '1owVVUkW9pi2ygRT1jCLiVRszFt5YyTJd',\n",
       " '1PcQtYHq1BLqHdGhamzvQtDBGzrbYxcgJh',\n",
       " '16sA91ykQ67ztSHzpmNpteAVQvBZ6jFZAV',\n",
       " '1LwnXMVjpZoPezdUDuGK5pcVUVWcXYJmhu',\n",
       " '1QJMW7xT2u3sYXSmn6RQZkxrkcngrGNfS2',\n",
       " '1AoKiLSV2cVu4cLhd1ZD7Cwbf6dE1JTTW7',\n",
       " '1Mi2tNib9qSPvJp5aex51nvH6vqQCYuxaE',\n",
       " '1BF3MiBdeYXrhHHTmYt1jFPfLYdVf2qveo',\n",
       " '1LisCjz6TSU5mHP5ue8QKrD8nazTTHp85',\n",
       " '1MWQoVUcC7NtoZDvGiXcWX7wmYVMDBXuWC',\n",
       " '1NJYXg5QcRfCBMxMRxC4HZ8qbA2SEW6BZ4',\n",
       " '17hafZnA4nstb52zKH44uworR3eNi3xhyq',\n",
       " '1NpjctKLy6W8gPwXZQ5S43Y1HWVEbV2F8b',\n",
       " '1kg2i2Xd3oLcvpRF3BFfkUeUme1C3cUCM',\n",
       " '12EykJepsTXJhsDkf8F5n1QntfuMPRBj2F',\n",
       " '18GFZ5BaxEFkAm7YxPu9FVvKUwKXnV5zW',\n",
       " '1HZGUCg9jourLN5vvn3bFjJq6XfYN2oA63',\n",
       " '1MCBH7bbtncxNH3fByz8MdyJy7Y9KiifKx',\n",
       " '1LP6pWayDwUKmwfyGLm2LW1J5jZh1451sd',\n",
       " '1E3um6FrfWCWmQRxcY469XHuWGRvQqEKmD',\n",
       " '14KFjsKMv2jB7215vP16Z7MCgADWjfQbGE',\n",
       " '1myb5Hrw4uYGYdmfwoxCZgSMRcs82bqw4',\n",
       " '1NAg16WnFcWp6ZusgypycF51B14sf1bKTn',\n",
       " '1P2nvQjWHSWGGTbS4JoGk232nefApZK8jC',\n",
       " '18Pgru2M4EsbER1krFwxbvZGkomr33eKxv',\n",
       " '14t9vZZNyjmLVi5ETmj8yrGGXrjm76hLQK',\n",
       " '1PxJ5JsqKNixkHsskYrANRPnmkJ74b5mZn',\n",
       " '11oXD1KFTbP5e598ms73r3icmrjFMHrwc',\n",
       " '1HFnCkqyAX4AwEF3Abu8QskbB9f2z9Y1YB',\n",
       " '',\n",
       " '194hsmuf1hNr7HQV2LAeRBxQ2sCFpPiNAf',\n",
       " '1AtWFaYBmyDqsdMopdmuQ4sviEo9Rj5RQK',\n",
       " '12hb5eoZeXTPk3BP72vBYbSsu6EiquQWsQ',\n",
       " '18oRnebqBAKCKngJMCJSno1FzjjLQ8QfrX',\n",
       " '1NXaRkrtvRsdiDPs1gvCVqzCwS59wfxgXW',\n",
       " '1PUzBoqLs7fAyCPpysqWh5UqixqHfqokYK',\n",
       " '1NE6VhnSXAfqzZ5VkWQQA77SQBsgpbJR66',\n",
       " '',\n",
       " '1N7QV3fE51ufBzWNVKDCaJWmwE9i7iTm3',\n",
       " '1EJUufUdVjfG1eAx31B7yoUB1cEQeaoHPF',\n",
       " '1KqCgduJ8HmR3EkcqHUvZvcdx38htQDTZt',\n",
       " '1Hz911UKiDm2zn5uhrQeMoYm5zKsHG9KC9',\n",
       " '1CWujZW5bWTnweXWnVB6LkPw8PMTeWUeRY',\n",
       " '17nuhMX6Qwi22K35QG26WHo7X432jzNf3u',\n",
       " '17z7gLz7xrhPw4CX51LXnh83XA8GaumDCu',\n",
       " '172Lt4HkfbStefnuRVHx1EBNu8PM1wqZts',\n",
       " '127jvkBRtEYGpkZE8K8wTfcijTwpVz5nYs',\n",
       " '1JKdgztpeC1Caa5QSQohUrxzXYXxsHB4eC',\n",
       " '1JEdXFMpLrW6krzLjYeUdfsAKmnf3Btcz9',\n",
       " '13bjfUUsE7A6787SmVM3cUBDc6HdsfuxYw',\n",
       " '1KG4516q6UHejAFqumJ8ufsXGXSNxsv6Bv',\n",
       " '1Eh6XGp53Gwvndb5ruCrUuU4CxjfU7EDbn',\n",
       " '13NmgMPFgJjYaPeSvjw2y5cLh6jxRp9ZJo',\n",
       " '16YrX771z5FiQtH3bRvqVDWYgpheminEYc',\n",
       " '19Zb45zNCeR5CRGscL8wQyMTTepC84Ziao',\n",
       " '1BPVQ2teN59fu8ScqPQkvVxZe3c7SsSPhQ',\n",
       " '1HjeQMfTjd5H2zPwZCsAXmD33UJQYmsxxQ',\n",
       " '1BVAdEKfZ1g2cEUsSogpp5b4CCfEpvPQvM',\n",
       " '1AMRbCSe9dGPTUWSYyRyAxEUMwyTegvrf6',\n",
       " '1DX85rsh3yWADxpjXhDz7EQyGFmxRUGAMe',\n",
       " '1JEbotLsUGJvaQpbn7RKyWgGjGHHvWzhJT',\n",
       " '1EY9fXD7D6RSJaXUAheT7YGbCxkEgX2HvK',\n",
       " '1FvhcpdCyPPHFpBT6SmKL1qCet7dpJioLx',\n",
       " '1JPU7ECJRykNEossxFdrb5W5eKrCCmCxxP',\n",
       " '134RSK1UnQMdoqtE5Tn6gcbYvL8A92naK2',\n",
       " '1A7o2epYb33eBEuVo3jS7Bpt15G1Qs8iZZ',\n",
       " '1PkmLGotjHys2xLhu8GSfgsH4ZWRvVuMkh',\n",
       " '1Mx4tiKtXMFVk8QHh3b6PoMZGcsf6fqujz',\n",
       " '16uADgScPNoFHfoTZRogtauY6WfUXfK3Ha',\n",
       " '1763ARpjrbmxgCxuQM1HMLv8zLiCLZaQDX',\n",
       " '1Bk3uE9aRRnCqazyNimbqiqBBic7k4gkDi',\n",
       " '1AsGcj1f2MHvTNNAAtptyHnoRVgfHKJcRp',\n",
       " '1E2LfRGmxEUjKcoiCSBMm3YW5bN5saLjkQ',\n",
       " '13dTwrLw8E2HDk9qDZ7y7kn9nACk4R8qGi',\n",
       " '1PDLNdCbRueuhiGeMV3kvoWCU4QEYT4Tck',\n",
       " '1KM4s9disav1aGE42u4UqTfvhvHo6wTRgi',\n",
       " '1BsvCGkPJGpAV49gAZBFL7GMedczuE9ZPB',\n",
       " '17dLcqaEqG2XiQZR3441gCpa78KwUANukr',\n",
       " '1ETN4EUPTjLnzkNjAHyzZuEk1bUwjL7uae',\n",
       " '1991hytXTdKp2P8iRmLNsDvR77D5BLQZYJ',\n",
       " '1ByLoPYuk5Y4t2jCck6pyRMacJGMh95PWD',\n",
       " '1B7qKWxfvKsS3EwMVVs9mAb217a2k4QPnu',\n",
       " '18UEBKbrsVhdDH2ijHSbpxwKfjErCSHDEg',\n",
       " '192nWETjB4y3GUxSJ5dxyU5LGkcRRwmCNF',\n",
       " '1N84zLey5ZJ8L5G5ubj5upCThAieEUN1Ls',\n",
       " '1HzVg8DS7ASwCktDMYYx8sGAu6pKKZJZTE',\n",
       " '1LhDgWnmMBModoziZnKtACu1eEjH9HpLuD',\n",
       " '1DF6t4YbQJDDw3iioxVNpmJjjq2j1PuHHz',\n",
       " '1DjaxG7KYZLfeRrAHBsc4W18qsWUDWBVsr',\n",
       " '1BQKzxP4Q7KSrC6ugmFapoLZ4ipepsSmLL',\n",
       " '1BrZ6Ecdp19osmR6p65weySWqev1xnnrac',\n",
       " '1ExKadQoYUdsL35qtrze6HdThgb745gk9t',\n",
       " '1DV5xEhmz1f8H9iFTEKdNg8jb3NGp7VW5k',\n",
       " '147w7ZE1aP4NVRk63R4JJJEBFeEKkhJPfe',\n",
       " '17fzaqqJfRsQAu5JpersCLUB1PqdRDyoXB',\n",
       " '13GR8Cs8fUUD82JfyqNaDwjupdPyhTYKwj',\n",
       " '18zbYnJ5dhm3GAzyP8FkvJaa8mP6ZuGHXF',\n",
       " '14ZQpmfdgk4RAYwKp3MwMnUXTxka6zDBnE',\n",
       " '1MkW74jtuvCvC5U1N4koyq6HLKwwFMhUyR',\n",
       " '1Bi2xxJvYmTi5frhr2wBJH7L5NjGwyrT19',\n",
       " '124k59ppGNdSYfkKfzxwsHuVdUXvnB7uPB',\n",
       " '1AwQa537Q7qVuxH2qbgjzios3GWLm89kFX',\n",
       " '1FFF14uvwMsw3xFSDZoVwks3pifzkXKv1E',\n",
       " '1MCv96c1vt1B1JbzdYYcy4vsPjsnF9qzhy',\n",
       " '19gcbQiBJyw3YXxDZjFYqtM6hZVB5G5ESH',\n",
       " '1C3z54FRSV2dXeN7kJDCzBE4duhPi3VMzT',\n",
       " '14fanXqNds2Eic6NkDp1BnHa3M29ruKm8N',\n",
       " '17S8k4PwCjK77bkMoji9EfKrsVU9125YR',\n",
       " '16C9ZV5WwoxkrHiVKpJ6JLYKLsncqsuSLz',\n",
       " '1Pdss2KWF1L6S1ZYn85GCaAbou24AvBwMF',\n",
       " '17dM1WsYM9qw4mooZDTajFKabAUNGhPkjh',\n",
       " '1PoUBDUUTreTMQvEq9dComunicr57pdMp8',\n",
       " '17otbHv9iUkMX6MzKCyYHvfmVgCHdzwTLF',\n",
       " '',\n",
       " '17ze3fvDtJrLb4scEo6oShtct7dBLMBKD',\n",
       " '14C2D1B2F8kQA2PDd4uaTpWN6WNis8EW8s',\n",
       " '1GhPVxi4MyXac4vrtowme1LyPgWdkSZ3Eu',\n",
       " '1EMHEqEPYBitvRjDFBj1Vx7vzgbEdMiJrC',\n",
       " '',\n",
       " '12n3FWEhD3DCTTYgJ8eP9a2FNFrpUxDXNK',\n",
       " '176BuiScRsELNDXyVFmndJp8EhCVTHBGKN',\n",
       " '13kWMEfCyV4hCxXiUxwTot8qvn3CNLPcBZ',\n",
       " '1LCRUotJFsDhLfTVemkQ7kNgybC6mkdESD',\n",
       " '1MdDnWe1o7g5ySzZHMTPjjYAmmkudhiq95',\n",
       " '17fSwPP5eHEkdJiyoTU8X6TtEXPnBfSpUG',\n",
       " '1DfjKUpqZY82rc5GcshVh4kQ69U5JDonz7',\n",
       " '1FCmMsdpeAkPMCa8B8zMR4AvFpVwR3P9xw',\n",
       " '1MnGApBmQyyCzMD99ZB7mpnqcXE7Tn64BN',\n",
       " '1E7ywP8aH3AgGjTgVuM8qYojzJCmSMhUQG',\n",
       " '12gLgVbjJcGYxaGgjERz1QB2HN5RY88mtj',\n",
       " '1Lm4rPDbUrhsLq5pe3gbSmjY8nT49ptHz5',\n",
       " '1PyvpizJq9sep7aQbK5raBPwseA2bKPY7Z',\n",
       " '1F9XgqEnmdKE5Cekh2pkkYG3ZUWDfqfLcC',\n",
       " '19BtcCk2hxD2vefuen8jEP9LUWudzp6n3y',\n",
       " '1KnpJ6ZaCoa11AztGKzMP2R4ZUBq8V6wBK',\n",
       " '199j9RayxXVhhhh7Em4ZXFxx4hB3Nh1Phc',\n",
       " '1QHLudDVyqukFAchCted4HGrism59hSwmy',\n",
       " '1Hf24sPVuAELnmpXxR6GpzKMZv469Q3p23',\n",
       " '15sE95Qgk2UQRVz4x3ToY8vYYC9NGGpGr4',\n",
       " '1Pnys4VVrvt6FnthFcRyRVHenRP8NJWM7g',\n",
       " '14JuMLcpHtSwVi2MFvEyNZJrLSEbh3LiCq',\n",
       " '115xtmyDTcbNUzQWXx1R44Tjje6Eku1XGp',\n",
       " '1JNwesff8LtCNZmpusstXwmKG81qehoP2H',\n",
       " '1HzWvxw8WudQTLxqLa7u3zUKc9FXLLdWAp',\n",
       " '1EFfVmeJo5geCY7dRkvLKk3jEGDdve3Yir',\n",
       " '1CJYXrP7BUdnd7Fo8j9ihDjDcyC2jEKrVE',\n",
       " '1GvczHsEv8CHYjibQH4cYb2kTEyTdJ82gF',\n",
       " '1Dd8b7M9KNKG2jF7tMX28uojHY3ECfq5Dp',\n",
       " '1AVc3QRxjGpFy842k2UDqu2mvS2iZhrGtS',\n",
       " '16wRXTunABZPmPL4zXmdMDRxvjJdApigBj',\n",
       " '1DCeQKHpFrQ7FfHRBh5r15dCWiM3UB62UH',\n",
       " '1Eio6c5b5uGcyrHPS1piSCPpe2JGr3mKv5',\n",
       " '1tnb6R17sfsgVQzsxJoHiAam8Dwt4p8hV',\n",
       " '1Nit6krndTuyKYUi9wmf5dGSitdtGto6QS',\n",
       " '13TuXnPZm3JDYxt2eS76JnArEmGonbVzyR',\n",
       " '1EEDj5NPJrUykdXG8gk88GiF1WK5eVWo7b',\n",
       " '15JPXy6M8kc4Wx3ZXh4cYDqTg3JtYQSeM6',\n",
       " '1BXPDT8guCR8nACiP4DifCFBsLTVE8etjL',\n",
       " '',\n",
       " '12WGEJntYVwo3pyVNK63SfA1siPE4F7yS2',\n",
       " '14huMbaXCK5gqbkBgHW4kRrv6niVdXjbQH',\n",
       " '15oXdxBgpjN7SHR49eUXNVKkfLfuR6RbvB',\n",
       " '',\n",
       " '1MGdC9M2qWz9cDAnZD3UY92QWjYqJXpp1Z',\n",
       " '1AfofnbAMtZ9mw9ZW7FMxEXW4gDvDZHpxK',\n",
       " '1DAJaCsk9CK6RFuWbJm1nvSdoGKiV1Cxgu',\n",
       " '1H9up4Je1sjNfQ8BXWDw937ZNctN5dxcnC',\n",
       " '18t2RLMQ5DnkYo22ASyhuvSEvMSNXni71k',\n",
       " '17iFA6mTnhF8ecyVmLv8LABYdrt6kGjbof',\n",
       " '17zQAyYSpBGbympVFzQtfuw3jeJSXX6T78',\n",
       " '16trNbJapA3PKzubhw7VgkWNbFa24cSmrd',\n",
       " '121ADTddxz7LkFbDFRjenBTQWdCHEhEGUW',\n",
       " '1FsQdF95Y3T5b3z3CxCAsQxVWwM3NpFCxT',\n",
       " '1Pu6JoAQ2dAXYhLAnogra6ToDpZoodoT2S',\n",
       " '1PbRK6ynKrZswudUiE2xQCDf7u1aXwawz5',\n",
       " '1odr43EmCrHmUxuaD82BzBghCRszt7EAn',\n",
       " '1BQDn7ecwTvFU26xhjFALq9BZUFd21nX21',\n",
       " '1Hies4ncQRE1r57V5JDVPVXB6oqfgu68Xe',\n",
       " '1KhNTdKJNDZRW5fsBmAMoxFpjCVPYzfUgp',\n",
       " '135pVHrXvdfcVTKqLZ6goHEHB2ubzfngM3',\n",
       " '18ZUy8ptvCJ8iE77eo7XaaJq5xD42GdvwY',\n",
       " '1Ed9CN46zwKHMNQSNsbJdjWbJ5BqErSjAe',\n",
       " '15RMUQFrUCBjognvF8vZjnk2pdA8DvT2zA',\n",
       " '18prmPbyNqxVmEHkgK1B87jGSQzSdrPhXW',\n",
       " '1AUY7GZFrnhf7fbCtyZC4CP51q3K6HpWDn',\n",
       " '1JAzy3VPocLmDsuwkAqkF2pLiXDeKJePvo',\n",
       " '1NKDNDyPg57uDn3vdcvHdnjGMRgEHnwWJo',\n",
       " '1AcSBN3co2cUJq2gnM4pM11xDphMzmA6T8',\n",
       " '1F6PTDV6wE6nU3Ssocuj7DxAdxwkdiqucY',\n",
       " '15SUb3r8HozzStF9QCKb9AkYxbnuYT9Yck',\n",
       " '1FYPZN4wsEzksjQMe4qg3BRAdseUjHsF8a',\n",
       " '169H4P499wxbCMhZYjouh6HD6S1wCVQ9qm',\n",
       " '1Mdp83XAR7rpmSdHm7FTfU6DndTnQVcZPe',\n",
       " '16qo7k2Vg8TPZo369pzesUxw5UZacwGmMx',\n",
       " '1J99KBqr6KJBGCbecGvfdc6LPys71go815',\n",
       " '1PRUfK5v9LiN1gxRi3Xd1a87yjy277Tsfv',\n",
       " '1B58cXXSAoZnEEkM4ULQGSzdXyuSqqH5y3',\n",
       " '19F1HegZsAqUCQhjZcWM3HRZ6vCh92ybsY',\n",
       " '1P777gTs4KNv3SfAoNML9EB789hm5GpKaV',\n",
       " '1JoMsGwtcS4hRWR4cnhjiYSjuASvHybFyQ',\n",
       " '1NNHkLksjG7DXHQW42YqtzijS8KmSPjV5J',\n",
       " '1P76WnVbdCJfWxWizFW7HzBPAtxx21AMqa',\n",
       " '184NPCatnonosg3ManTpfkymKzUUhof33i',\n",
       " '1LbzUhG6g1sJahGo5kwT1R2Rs9r98S2Xnv',\n",
       " '1DdVzYv1Y5rc1cM6c9d8fpuUx7Sybyc7mT',\n",
       " '1KJ28a2tiywY2VuMHf7QF3cvrPRMGm4TUp',\n",
       " '17Wvrex75TFGwiucTNsbZUjsqtGw6Cdxpg',\n",
       " '1NpeZJf6Rh9m91XuoRkkwPnGEUdmi4ibwE',\n",
       " '1FR1qmBb6oersUvJTruYLDKKJAyFvx1ikZ',\n",
       " '13BZRCrTqaSUDiSU79zXEnbwiHEumKkee3',\n",
       " '17xpgrD52BinocrAT588j9nVgHKfLyJDNs',\n",
       " '1PbqdP2jZqm181gp29YtdzkVKhL1TPDQfc',\n",
       " '1N2ZDwTCYsxGTCUkKzBkVGMucBXKkxSCPf',\n",
       " '16LLyAM5H1nznXbCfG7WLGD3d3uMvUfkdu',\n",
       " '19bi2RusQtaKeE8srSFELFsp7WcbCTEJqs',\n",
       " '1FaQXXbBdF5tngKHAZfMk9et5CYMyN371x',\n",
       " '14iy3xzA25puNQJ9EezxBXrHMSKh1yko4f',\n",
       " '1GNqRRbdvErxgVmKHgnJvFdmHTK36avyWG',\n",
       " '1FMmiSkFvMdNNKNZfgHKcQNEVfBZJpQyiM',\n",
       " '1BNHPQcAZG4V9ZqPS5X2dF3xmdn1X7DrrU',\n",
       " '19o7jf7b69zv2jfh9gAtSEnxuHi16aFgEm',\n",
       " '1JcUotmTgPhxvBcifHmt6eUoiaiivHhfYC',\n",
       " '1NmzZBjEJb1am7AX4BHW2q54x3fbvUabXe',\n",
       " '1HkEkJv64EN6ab57J7n8ykBjvcPW3DeoNL',\n",
       " '1CK6hjk6NQYa4rEsZjqoucGe5wKB94etah',\n",
       " '1AP3beHiJ8vyLxZ2AwK4c2y6Fb3pWAcU3Z',\n",
       " '17w2ZXVyh5biPXmWAwUjfvWmLZMUwNs1dy',\n",
       " '1Q84aGGZ3Go1SE8fLcGSAbKpTqYjx5RxwP',\n",
       " '1DuPxAyQZkbPbNxGeJp563czFLLBe3Czdf',\n",
       " '14aUoQB4NQVFzf5hYaXrT6DCsKmREiYo38',\n",
       " '16x58deBRhEEgDeeFGJwn4VxChv8KuKrXw',\n",
       " '19qN12m6QUPcT54ZJ9RHpf87sBBRvjZArg',\n",
       " '1K9jVrNAKNAhiZTftjMxdDhSUqEXrvWV1W',\n",
       " '18WNhPSMhhwVkrVgkqR8LBuN2uyFX8vVZ2',\n",
       " '14fLsSvXML31qJCkniQqdj7nFfZSVPu2aZ',\n",
       " '153CgUdbUwBMUNHDcSDWHu1kyrZ9PJBNPL',\n",
       " '17Zrr7Zi36wMmh8mf3ik8W256Sh4ptQJLh',\n",
       " '1HA1NyFnrU393j1MW8VkvXGFnf67pbGwFJ',\n",
       " '14NkopWyWY2Qsrzy4Z8tFK2w8R8rCa5hnh',\n",
       " '1GWfTd1rv5MFWtiEJBR3BK41qtra6R6KRv',\n",
       " '1KpP95MXirThKyzGv5tf5kiNNibQtU4RCe',\n",
       " '1LBRkGQZDBLBh9fF1ghvoPvi1f42b5QBn6',\n",
       " '1BMUe64qqWhJVM59iTiB4bL9NgCGP2ufP9',\n",
       " '1P2iDxGrMftaorDERGCXUymsUA4NgrspiR',\n",
       " '1HXHTdGbSYYctPFhCUep8H6WXHaHYHV7TE',\n",
       " '1EnYkZ4R2291V6DPrtRWs7bTpMeM1rni3B',\n",
       " '1KwMWHrjZbtenbRWJrDtWQb94ycM2DXkJa',\n",
       " '1MTM8McJLf7E9A4Fn4Sr37iJ85jkHfWDfW',\n",
       " '1DwT5ZUJdzTKA92YoT5uR8dituapj7j3UV',\n",
       " '16yqgycCrZ2Gp9PUcEb1gPFBZU2UZS9m8w',\n",
       " '1FAdgrxsWbLi6wgPiKVWfscr47Swtmp2K2',\n",
       " '1HxSDD5dxu1hNGinqxHeYNe4XvxMUEt3RW',\n",
       " '1D3Q2VZkGGC7FoMxbnPXuJ4h8QU3TZjNTS',\n",
       " '1ENnvStEo183Y5JhLgSjEPF4ctQRwUt3WP',\n",
       " '1LCEF5DUxvLVTaFh8kAqPgvabgzxE5oq6s',\n",
       " '1CjCyEisrBHXEq2X5YqMJ3ctzWUqyeCHD9',\n",
       " '1Fh3BH72pKrPmq7YoY7tfW4XT6f8QoHpRX',\n",
       " '1QD7NxieRDuK8SD5UELzEWqaMGG92Td6VV',\n",
       " '17iboa8RUHVi6jPemjojEx5qfCWoaa7c7f',\n",
       " '1KmEganBUqyweL9DgqJR7jY2GSG342pSzu',\n",
       " '1DQziwe2a1LExBgJ2NZpTbtr6FTvY8V9n4',\n",
       " '16syuqUygKLDWq2HETkvmxwNFkJvLKLQQ',\n",
       " '1LYbMN9W4roBnYQpbsQ6zDwbtUhyYjaSEa',\n",
       " '153YVKZ4NVFuAmdomUJRUVG5xq2xAfxpHd',\n",
       " '1Li63PXvE6J5kZfBcnurhrHjwDqGkyCHUi',\n",
       " '1FPGFoRs1YYfT6yUJ5ytyiKQrzfRBu4GK7',\n",
       " '141pCKLfQruhTRF2182d9qRt4oGc7282ta',\n",
       " '18vxshDpYDeZF68rvDhWZp1iJWd6TinAzt',\n",
       " '1Hk21AKg3Hxp5vjAV72ZQ2GQhNz7bvjF81',\n",
       " '1KM28KeNhiM41A3Ez1LiZuRByjy8vpKHPb',\n",
       " '1EhZz6hu4RJQgycvdH1TXpDFQZmxJviMdz',\n",
       " '1HqpSZfEecPL1SYGY4WJmTcV22hY3GqTam',\n",
       " '1Bw5xUfL5oEVF8tPdZCBZtCZx4cNKEKDjb',\n",
       " '17AgHMyggbknj64WfZcZr4wSYuaUShgYrv',\n",
       " '1MpTUH7NAH5tZUMAKMBDJ44KffYnWFwkpU',\n",
       " '112XLqfTM63BTToXYpwsANTz84K5bu6NGZ',\n",
       " '1BAfAsxa8PgHHuriQndmQPBMwWz5GDxVWf',\n",
       " '1KS6ogPQoLbqdXLp427DT2Y7eiZ6r77YfW',\n",
       " '1K8BnqjsEEq4CPCvdomUNwnLJtU2gSje4G',\n",
       " '1Co7WsrVwWHSBBuEWJprwCFvXVNnRAw49U',\n",
       " '15to1cRrYpwcM8tWu8i7BDxreFLSL9GT1v',\n",
       " '14A3X7d6NamQoFERw2Xr8Jc3PV3A9icAiW',\n",
       " '1Pqrzv3KtaR4uCHcCDgGCovvsAYribWuMV',\n",
       " '1LVdypHouKQNE8kkwcAvV9Ey227R7DYB8u',\n",
       " '15jJ9hXhJJZszFsfqkcFrFnXUm83iPLGi5',\n",
       " '1GVfBBowvcmP6YrEQDJLdSqZKPRmT96Cha',\n",
       " '1LKLyqaV9rhvDRzW4396Svp1hhfy1ckqnQ',\n",
       " '1Azt2u7uneLNUxukBP8YZicVmwTJit4hJ5',\n",
       " '1NXcqBa3wmkguY3NXYXNh7TfG6U5zvCyZd',\n",
       " '13ADvJsebdHN7pL6tRfP3vf8Xo7HVvAbp1',\n",
       " '1FyUkkHcMu6Jx1U8GvPptGj91Y88tkCzdE',\n",
       " '16LoxeR7gUX19E6zZQ3ws9fMQ9LbSpGcoF',\n",
       " '112FRqB4mwNtKqRhPQXeJx6PM9ovEi6nka',\n",
       " '1JtbX5QgLsCfqbckgoaUpzJwjxRk8qT3Kb',\n",
       " '16Mxmt4CnRZAAbaWyiHvKwVrWJtwYefXVu',\n",
       " '1DA2wPCgnCNoU9tXw4rR5jWr5bj8X3vC4U',\n",
       " '12D5HxLWqQamLsB3wsxa79JHtWRsjEaZV3',\n",
       " '16pkAe5WSbkmBtVRLtatQBgefjxRa9huTt',\n",
       " '16W16aoXvTUj1Mn86QKS7Mb2UJu8K8gHSU',\n",
       " '14pnEiGCpbivgLcbyAbvQJrDv8ErH4tu3i',\n",
       " '1Q4E1K4tfRK6xG3LjgmrNDaLUBZ3JnFLS8',\n",
       " '1j3aMEurfj4paGPcGqNJDfHdL2bBgQJvk',\n",
       " '1DAsbjwnZk9hFmiCQaPTaERCNxJNBXKzBh',\n",
       " '1KuxKE67TRuDSKjD68xbNZkjb3vHKmFU6',\n",
       " '1vnnSxvwTh2CQ9AhRDmuJeGXTZFoDb5s6',\n",
       " '1DmpAzMiJMap8H8J8AXrFYQszcBReZiyy',\n",
       " '1Laxfm1LWeophnDjrwm5cKUD6tSDVP4nwL',\n",
       " '1MUTsQP5DsdBPbK1pkTdzjEmj71zjvvryU',\n",
       " '1KKddEPwsEGV7je9gD8yziUsG67Gc3CKyS',\n",
       " '1GHAga6fhfTVMN6rSt4PUkDoZbDdE7LPJ1',\n",
       " '13L4PQK8FGPCfpLjxSczWaJr5irfA9BM4E',\n",
       " '13gHYeM1aXJDLnqW9voTBZfGpdcLDupwGb',\n",
       " '1MkuAJi5UJnCGgzqxnsJ8hC2JnhFWUNNgG',\n",
       " '1LqhzR2hdJD4wv5hFF4wg7QXAEHbwn9mUr',\n",
       " '1CzfBYUtnUsWBHJsnnbkpkhpGWakvuC2x6',\n",
       " '12YBxyK4oSMnwjs8jEpBrqAFrfTH9kA5yc',\n",
       " '139hFnpGk2yvNDtgfASrc7WFV56ThwTvVA',\n",
       " '1FtzM8V4ZUUBqZ8hdr8i8dHFtBhgdPsGER',\n",
       " '1ArZGwDRnbk2WffD8vvY8XaSGH6inLyXV6',\n",
       " '1K7B9cZp6v3eN7g9DTJYmWx2jkRQK6k4CX',\n",
       " '1ENHd3zWBoXQHwfjaSg9LadXY6f2s1sFtx',\n",
       " '1JDZNHeSgn2tXMrMBwL7deFYjVsFHGviBT',\n",
       " '1PvvTufffPv2xLqpLZsfTzhNGBhXHcoWsC',\n",
       " '1JRtTtjXNeUz5WuV92TEzxENDDNcMGm852',\n",
       " '1946zjJ4tE69Mqzts36St3dCsYmsUdab2b',\n",
       " '1GPvhaY3MzLyscCFEexPfr17pxinPsdq1i',\n",
       " '123XAh7kb4fAPp1dfgEfvg5EtinJjmJtn6',\n",
       " '16rXqTuroMFf7ffLKhoyvnsJHJJ1jiD98r',\n",
       " '18ZhoL4npPrmd1DszU2QtSex2UJKLwiE3R',\n",
       " '1L1RM4AN4FS49VoFyhkGpHfqPzsi2XnWxW',\n",
       " '17vn28XWeSCMEjBxqQpsW6oqgDm1DeTqRD',\n",
       " '19RAk2dkzhcXcCQDcquNDG3wZaMjBQHeC7',\n",
       " '1HXzB9uXTPQauu1ts8qcFiRo6HkHgHsu2u',\n",
       " '1Js5wH6NiZR9y48b5vtXUKpGcUBpHoL9PD',\n",
       " '1DSZLhimQc4tRuG9FgyoDrTfQJLHoGuouc',\n",
       " '1KFEhu3J3bWUSZHgVsGkBcLdJueGQHvqKy',\n",
       " '114Un4toYKc2Kbm5dGqjywuqi6FNoohJb7',\n",
       " '1HTTM74XsgWC3QHdBJM2dEq3S9Wm79JAi7',\n",
       " '1GoSDFrSRzCGiijQQ6XwEzMKaepztdwCkS',\n",
       " '',\n",
       " '137bftoGgejDQyYZuH6P6k9K9k2AMqkPK7',\n",
       " '1KJ1ozEaoL9UoE5tAEzDztdvyNWh1XRUbD',\n",
       " '1AwD5u9MXkP7byZ2GTADLh5sQuv7gyXmgL',\n",
       " '12xWmmhL6D8KCwDNojhneGA9FBEZkJFp9P',\n",
       " '1EFYstMQ33GbQqCwghZDkvHAqgJmoUqE3V',\n",
       " '1pk1H1yHca5rihAL6LPnccUoae29bxDD1',\n",
       " '1haftmNnFwcEdnUCrpT1fdQdWkksMyxqz',\n",
       " '1CvocZSXh98tNZWmQj1KtbG1v9h112djsJ',\n",
       " '1NSEKWs6ELjY8zfvYkYdnfA4QrrD6NQ4UY',\n",
       " '13AZLx45e9Pe6ei8bYyqpgtsKR6QPKPVTV',\n",
       " '1FJFcgCogPeENkVYkN4uggiLZreF2pUH6M',\n",
       " '16J4G9kDhb7JfdSBi63vxEnXSmATMLPWtK',\n",
       " '16eNgxJm745SZnTkQiy4LS6heVPC7ANyiK',\n",
       " '19DwF1p75pjCNs4wMXbDNyQtiqK3bSU3Xf',\n",
       " '1Nw3mg9NNBKrv5e7G8b4K3B1YftMftjHfc',\n",
       " '1Q1PTLTDR1BCN1y65Bey3zDK1tXS8B5Q1n',\n",
       " '17qzhPC6SGMsFV5ykqWZbnhyJcuufX7BZx',\n",
       " '1DQqvH1pg9e4xWV3tFA8NprTY88ajYqagn',\n",
       " '16S4ypwFbd7NNthYtxiZj4mmhrqRfNUNjk',\n",
       " '19W9XJxEhu4XUEVq2XtReL3EPo7v8vdS9K',\n",
       " '1PnY71AukZRNEvCv8DKLvJ1XMBurFmYxs6',\n",
       " '1BUWJVXdWSxoG7SA6VULMcmVXjMdtqm3Fo',\n",
       " '19JPRa4Tee7Fbmz2aLG1m6mHJPoW2c23XS',\n",
       " '19rnWiFxD2taMujCz1iM2ZuDNXnz7vwb36',\n",
       " '1FF1f3zVajqDJP3ozaNgxr1C2L9DW58CWL',\n",
       " '1QC4P2bb2f4BMWbUpqhgTQ7Xjnbv3aP33K',\n",
       " '17yRBNGzsR6U4U1GWWnSf63zkivz42hqwj',\n",
       " '1FNtWfiBfNa3XMvpiqb8pEHUdByPGuMFfu',\n",
       " '151MP6TRVZTzmomTAREj21rF7GPiEE9BF4',\n",
       " '1BTHrdCYVHX4GdHHJNMD2DADLcMJ2yXVKQ',\n",
       " '18WVvAcqJYYwz1HMoeaKoNXQgyXJgDw6kU',\n",
       " '12pua5wcQmWUNXRjaCpoKJcSzV5ysX3eCa',\n",
       " '14hTUyjVHdvY2psjbj5E6cCpNxB8TWY4L7',\n",
       " '1DPTcPHNNpqbjHVSiyZdGoVasmESiW33vx',\n",
       " '15KG62CbC9wm8YiVjK8ZZVnUixTz6Zgvbk',\n",
       " '',\n",
       " '1CT4pytoZvqHMaK3frgJipuqVY1atptPRv',\n",
       " '1GKLdc9bdCG5AiSHyh2DLvcCWGTx5GNnJB',\n",
       " '1CymVMkXRZidQMMfFjECrzv8HEaZJpd9k',\n",
       " '16tSWQPA4V9bTdzdGApy6BHVYtWpvvgDc6',\n",
       " '1CFZ3XQ33aWwAdcS7WK1xwo7V6v5J14umR',\n",
       " '17e431pBhM9hVxpRfF5LMtWW1fD2PSFq5T',\n",
       " '12yAEY1mdHRDEDqyFutR3yaQWfBiB9QdYe',\n",
       " '',\n",
       " '1AsSRdJR49LzomFdjReEKZ5aafABeBUHCC',\n",
       " '1rMg4dnp1VXRxfGMQoxhoi7AET5mCWt6m',\n",
       " '1PQBWFvko3xaaneg6wCEoGoQS9UEgq8qSL',\n",
       " '1BLyGofPXUFpsmonuARji9NZJPaiy12zeL',\n",
       " '18hAowcWJr1ni7hEHRBCExMBoc2YgQ6CcM',\n",
       " '19PKdq6PRmkaPNWg7gdivEzFrsNpWiEyZt',\n",
       " '1Hjn9aBJY35kWyBTpz6APWTmTmcprdwvGh',\n",
       " '156UyXWH6qUausXjSzppVycMTFukkozXbh',\n",
       " '1AA2yycx6YAcaUgkukUBE414f93mCZktXK',\n",
       " '12Px2KLooYEqiS49ALfboyssSGLETHnvXX',\n",
       " '17xKmA9qrAH2BaKijGYUmuZNUcS2onuYKJ',\n",
       " '1F2qCY9fdxmwcKh5XyBoi8N8dN2EEo7nve',\n",
       " '129rqZp9nNUhvgHxoTxvomEsSXX2yLrH3N',\n",
       " '1LYVVKGExJpeKXEbZiXXdV2o5KoVCFDYLq',\n",
       " '1FN8aXhQq879EoiRjhNtb5t1ZD6hWzpUBL',\n",
       " '1A3baRyQX9AQpWmBwqCuJfuksR4HwKgvAo',\n",
       " '14kXJvsXqo4ZR3CKSgVB2m76S7A3FrziCN',\n",
       " '1EGfBCv5Y3bJR5S1L4PcbDG1uo9TTYwRck',\n",
       " '1HRpoqJKeZ9TPAx6xzLb2PECboAg1tmMgU',\n",
       " '1P4nfnPhmD7Tat98BQLVAZ8mvCLnFTUHYs',\n",
       " '15tYpd6r5mqE8TwTTn3A5QWnzoddcK5wpC',\n",
       " '12GSY14zVsjhgfGCEUed5NQcgULh5PUe5s',\n",
       " '1F4uXW7c3bGrjrBBRDCbGVXEyL8eoUtbxk',\n",
       " '1L24upAmFza3dqHA1nabstmNWW4WSymCvJ',\n",
       " '1NjFMtc6mucERapTv91GrbRUuBj8ttte3s',\n",
       " '1Cw2LoWy2LQMaNSPbubdAHYvqT8ccz4mmJ',\n",
       " '1BkG3Q29K1Re8Y1mtipnn4hb1cNXjzCCUk',\n",
       " '1FdKkv8Vs1CFYJ9YDb2byxzFoAQXH2bFhw',\n",
       " '1AQJczdbKDUu3XYVxVyVX1Uj59pNqB2B91',\n",
       " '1FwNNMxRq9K6e9vVYRbokGDwLGjVgGamkF',\n",
       " '1D6MkTygcSppfTQwQPo7xV1hv9FX46acsf',\n",
       " '1Nn4fr6AGoVSzAXJCEeNuVnMSNNYyQRk7T',\n",
       " '18FSKNSZmmp5qEA8oa9wo83rz73GDJmo8i',\n",
       " '19diHvbBz467GHXAEhQzuqLbGmod6QtgZy',\n",
       " '1EaahiTvQUzDLjqwZZY8w2K32y9kzS78KN',\n",
       " '1FPXs35H9t7xSN8X5eNKRsMu7CUbZh2Wiq',\n",
       " '16CC9yxfH3qDuaA1heMUE5zqX8U7XcpQkT',\n",
       " '',\n",
       " '12ixcJkZrtcr5Zq3sw8T6qyQxjFzMVJLxh',\n",
       " '1JTjtAuhwVeL3k94dNqTnfxwscsV7p3xLj',\n",
       " '1G68iRKNkagjm5Nq44seYhToq6YnX9mJ7Y',\n",
       " '1CYhHTyQvBpb8wTVWWUFcApKZMTUSTqvY',\n",
       " '15NqVAfmyoF9EezX9FFE3DnrkDzKSmf1qe',\n",
       " '17Y698pUv9DJheBbbTSbojqN8ZSaWNs5Ak',\n",
       " '1AzPwCLKT5CZh2b9DLnM35DHHeSvE4rB6h',\n",
       " '1FgHuvMm5h4ZKo4YYKTpjoNXGmFRsDFvWX',\n",
       " '1BGvzLwsziMHmxVmrxpD2F1QdA3nQuCZEV',\n",
       " '1NN4RC5ZpuMkeKER1RFnWEDejU6kez4xt3',\n",
       " '14nV3FC2d6XMtD2tmBabHNQnkaHmuvcXNr',\n",
       " '16uwoUoucvmFcggvNLFaH3Cf1i9qKhxVLi',\n",
       " '1N6v5Pjp1c6WtNs3r8EgNpivvphHvWqpVT',\n",
       " '17pHNZnHnbotJ3QRaKxC1ARiq1gseB2jgH',\n",
       " '19CDKkRHvm67BuDQPU2npAZkoye4EAuvPJ',\n",
       " '1AnKBkb2Rb5LXc1ABsUo1CVZzWqV4NX2LJ',\n",
       " '1MsCMC3Aq1Yxur62GLqwWYpQ9TPXp4sVrU',\n",
       " '1FqEGMzR5unNF82JcxNiGKsyx7LzFH915u',\n",
       " '1Lu9R6UvJBTnsa3yV3d4HmFGwUSDZsoTbA',\n",
       " '19n9k2RkTs84ugP8BdYdFL88BhJtGABy9C',\n",
       " '1LTXV9pV3uB4JsarvpJZqZSzKYAGqwJX4F',\n",
       " '1CSj4UnuHkwXnGDdW7PwxbxBrcFAwCR4w4',\n",
       " '1Mpbaj3DbWtD84bJo1wgqq4ziqsVLCZgMV',\n",
       " '1GNTSbs8tSkx6MXsX4Q6uP5AeaeK8wtBnR',\n",
       " '1Ljsf1ugDgYmo1RTj3UxiG9ygpjzeoawMd',\n",
       " '1G6HrQDRdVhjcAV3GKWWa1fDxBbXPW7ns2',\n",
       " '18taAqNooMYcztXwA5ERErC4UYTCkH3G6n',\n",
       " '1FuisvWNXmoepsVXLGAyupRMA8FYt5VmMK',\n",
       " '1L2y4YC7UXcmyaEpRZQXbLc4zYNXN2cjEG',\n",
       " '1BajdWDmAd9HSs5H5o55dGUkCWEA6CGDh3',\n",
       " '1C3En2TKF8hj51KKWoJ4CUqgm1x88VXqB1',\n",
       " '1JQdw4MD8BdSrAu86gzDNgN5n595hRNVGw',\n",
       " '1F17BExiSEg89QdZEofFfwmNubogEP25ML',\n",
       " '1ETdgq4qo5BDaz8yfg95e4MngiYkYt2FPa',\n",
       " '167QhttsbSg58V3yipmZrUGZKbcS6Dd8X6',\n",
       " '1FinMWkAgW2w4p5rizxeZSgDcTypjcChQc',\n",
       " '12X6PPUpXjMYJqtb7JfEybXiewBaEhEJKL',\n",
       " '1EHt16KqDaY6FSmJo3EYnP4uZGcRdeA78m',\n",
       " '1KtdRDFczp2v89UBBqJtU9Nq61eft5Urq1',\n",
       " '1Jh2sna8o2iCfmWP9yVmpuQ8MoAWfGC3Le',\n",
       " '1NG3TtVKg1LkAH7S6KoyXiBp9X7jSUgHyn',\n",
       " '1L3kFEzkRyoARR9pdvzquAeZzQw4UsgAhF',\n",
       " '16qnjdRqW35VBFGPsLNoVYeZgG1gdgDE7q',\n",
       " '1G9W8wmcQrTFHgEuaySizPQ8aLK2fSe3oa',\n",
       " '1HSYdpUTuZWtfat83Vq2VVzURStssWaquC',\n",
       " '1KyJ1gkkVuNfzHR1uzveK5jPh8LVe7d5fN',\n",
       " '1AxWCAHuFMw3dWm9d6N4Hha19sJ8hgUQAB',\n",
       " '',\n",
       " '14yfua89EToKxEbLbqvLRgBgtK26Pv5aw9',\n",
       " '1AB8qU1gsqEGhJHNyTfFoESWSEsxQBNgcg',\n",
       " '148dznLAtngJpndReWpeo8WyqszUMisGne',\n",
       " '1P1YgP2hVw3xGzpr6AVFaAQDucZLVYqPHi',\n",
       " '14SwQXFYeYCvpQa44jYCGQ4wYCwz9CBpZH',\n",
       " '1KPByQAv72cnvap4Do8yq78z7KuRx3FkSa',\n",
       " '1BkGUXBH5C9mzkxEXuSjk998XzXm5aat7U',\n",
       " '1Dgq2aXfaUdQawd2otGYKxY1MpmkBYVA5s',\n",
       " '1NLpGYt1fVXoWhtV6iJMK2ohJMgaPYrmVG',\n",
       " '1HpXRVkk8EaLZCf6P6vcpUjsgeTt5iXHGA',\n",
       " '1KTMbAyBtJ12bxzxSvieDP8AfF4NxRgGnq',\n",
       " '141mDX4bSMKSMMjDza76mPstKkUBaKNV8G',\n",
       " '1NDCS4PPTm1LfE9KHTVso1C3e54iyU6Fow',\n",
       " '13AvYsReVXNjBsSg6mb68ohaot27wUVMfe',\n",
       " '18o5T2bbbnRHLqsjB1xsAue6aigKPRspr9',\n",
       " '1FBjfBsRK6VXhxFngHyneMTcxxpzJaZBZV',\n",
       " '1MdRXrLxFtq6bTaurhBHfNg4mNps1Sb6Ai',\n",
       " '13h5oiWV7ti5yBvJ8x8JAAyVpwgYmzKckd',\n",
       " '',\n",
       " '1Dg6bmFXTDz9Qg2YyWHxySG1R4UdqGYHEv',\n",
       " '1EdvrGtGJ8perU1hH1A9wAF6tiSkjbTByc',\n",
       " '1FoXXiTPtr89nSQJekJcd9LoVUoJEeB6UG',\n",
       " '1GWnkpfymXA5eCY8BhJrFWPDNsZhohDpH8',\n",
       " '16dseECSqCxn6vRrzTy9qFGF5LqYBHu3Ny',\n",
       " '15J85dgKNdAQAyYgz9Lo5YgNbyJDFEqNW1',\n",
       " '1PmgxYjySvkzuWh6betPh37hWgS6oADZzk',\n",
       " '14fvKTmSB9vC8qytm3MsnDzh4xLepnCCeL',\n",
       " '1922BbN9wZoQi43grYFsdo9KnXYNHYb56t',\n",
       " '12vt3GV2KgB2vxs79zVCzKJDYdzuxMJ9Fg',\n",
       " '1FHy5rmARZAswyVzxh1XPvCwg2JHfi3a6V',\n",
       " '18vcGY2ePorfNwEjG87HDTnMVeGLNT58ME',\n",
       " '1PwySdUiLDhSNBA4cjgycrkHjbGUx9kQSg',\n",
       " '',\n",
       " '14m4Y74nN9dqSyK3Z4HZSe3FpATGTB1Qhz',\n",
       " '18crm8zwe8KyN5Dfg5JDSVZCrvGikjKKto',\n",
       " '1JYr7VamLHJ5Lp8DJzUa2qQ2Y4by1WAzCu',\n",
       " '1DGe8vfq87oWxSSRwrjCi1Jmsk8wp78um9',\n",
       " '1AQNbSw5b8miH6knKkKTCbgMgaCCRa7ZLm',\n",
       " '1D2VtMN5PwoNtcEgM8dVLEWQMqbKKQE9bb',\n",
       " '1NVXEBeoYYTcdx5tU32iG3xh7aEagHF8Ei',\n",
       " '12UYpRXbyzinya2d9XtPWLpzkWEFVvRmNk',\n",
       " '1DeFRbiHMn8BSJPiJbuACqMGish2t1jcu2',\n",
       " '1MzHpzK714WiU741muNKyT4EjeYZ4AzMnE',\n",
       " '1JP7Wviv5y2fKNF16YAywKWq94LScFftWj',\n",
       " '1Kk7aiGn9ZT23t3HVGgKtbAFBDpavv1J3o',\n",
       " '1GRoziAdvxv3RYa2iNkxxL8UjvaHtZJ5o1',\n",
       " '1BWj1zZyWxwMRQZyuzhL6s7NaAk3XJEtpY',\n",
       " '1KodCbFfex2t8gYzfVCjNwhAJVJ363t3Fz',\n",
       " '1MEhKs2ocgv7uD383d9u8s73tVjVrKPwoF',\n",
       " '1PXtC7wDyuyoKgXBxL5jrmempMh2B2TeVT',\n",
       " '1DbLZQhTReN7MaMbSoxa2cjjqzLfwPe5rr',\n",
       " '1JTeVu7jHvKtNy3w8kyDqHLAD2fXMh9Sns',\n",
       " '1JUjPm5CUk1yEsX9XCo8LDZFP8vTZcfw3g',\n",
       " '14VsB54AQiAQ8LXTmvVB8tWz4zYgK4x1mv',\n",
       " '1KGyr33zutS2XFbQqAqqo6LaYEj6zXCsjJ',\n",
       " '17ihEhcoAT6StSdFLnvqQE2NxtADvs7RGk',\n",
       " '1Ms1KhGwQJQPeXqrr1poeR8Dn6b5n69fkV',\n",
       " '1HKjaVYyWLN2GjGMaYcSHLguXftS95pCir',\n",
       " '1EsEXtria6aaLokVbKFfgJ8Xfkgq1cZc73',\n",
       " '1Ps6souHMFE9ieSJsvkmWsCym6rgBGSyDh',\n",
       " '1DUPBjrq3rPbjt8ixC57u1ZPgSo9Cea4Y3',\n",
       " '1DS1ixBP6Az6H1i3gtgSAWD6h7g8Bj2vuV',\n",
       " '13QFkXxmx3DkL9gr8Ny26FcyaQj45bD2gx',\n",
       " '17ZCszU6LmWHXHRqQQ1XyeXBFNaFmbzsfn',\n",
       " '17W6RXt27uTjo6yHHSH1747RdSJcB6dQDd',\n",
       " '1G1akvVVLKorCqLg49UCN6eAJFHPokHurP',\n",
       " '1GNbajucesrACJqA6hcZR4A2DDYYHJnaUa',\n",
       " '17osHiu4ritrfftEnQaK2yy2DywuE25xyH',\n",
       " '1JMrz19UwLrHvD2iCtFAESMqxJqrP5kJbA',\n",
       " '1KsRbMsoEmqXovZ1S32zAQPDoDkfEjS1Bf',\n",
       " '12CwWqooLBd76Uxt6U9Fj7HGxiHcCUtvQS',\n",
       " '13wyhB9UndnC7UVtT8oMgCgqpSKDnLKuT8',\n",
       " '19e2S1EnFEoi7NDnJsxaW3HuH4gaAcHkHz',\n",
       " '1DXHQxvW7LLD3SF4UXxBcsRx3vwaB4ZDYw',\n",
       " '1AhvGKtq6eaPdGBq9LwfiFo7f2UvLu1Za1',\n",
       " '1PoLpszS4diRLdHyrXZzdxpRZWXZGXsLZc',\n",
       " '1EURGAUzvf4b25Sc6fmEk4WSUVTQfAVrvj',\n",
       " '1HrGWg7oEaRtuTZhTkn83c35tPYPwVpDSC',\n",
       " '1J5GUrAXQcNehLy9dorepPuJFLYKRUkMKU',\n",
       " '12NpJ8zgWUpdjbuywPhdwMGHSrXbsLd5eA',\n",
       " '1GzLLe6KNb8bwnLiroFGUgRYqBxAmKoM9C',\n",
       " '1CJ2sTum6G89NpvSqAb1W25MnNcrVjXVEx',\n",
       " '1MaM332Q69TRaZEAzjEPyHgXjicajnN7Jr',\n",
       " '1KSUwUNHtyebbNWEGjg428UsjdT4ZeSpVm',\n",
       " '1FSoXZ9cLuAyjFLMB3BvuEakc89mEic5zb',\n",
       " '13wW4em24nAMjKyMzMq2H2UosHYXFv8Qza',\n",
       " '1NoHXvzJdXsJkjeB7Es6o6tgMeQZBENnce',\n",
       " '19RoL5ARTXfb2fopsJ9VF1KQsLU85gewGu',\n",
       " '1BQceACjAXYggrScShr3SxAFd7rCpnjNXm',\n",
       " '1MjWpNCbzzqzwaEffyn48Q8ffxkQt3ATXX',\n",
       " '16ctq6UEArevYweS8fsyrTFKZzJGbB4Btc',\n",
       " '1AqXk6mpQhceVRWyhnMGosHKYezfoe8PPD',\n",
       " '16dTfU8369TL86W8knewK1vbYtYUDTdQwX',\n",
       " '1LtP3HdFYkhkGE23MbDVXEMTCjL2nTVGJ8',\n",
       " '1Etei6oGsFCcKCzkFuXiDcqy6icxBpVywW',\n",
       " '1G9iqmh2DuHnqD2zG6BwdDb2fZPtp4sGdS',\n",
       " '1MmkXC6M8UK4wnnKGhBGozG8CgDndxJS1v',\n",
       " '1zre1EjJT8P138WUX57KBrk94p8cvjvYC',\n",
       " '18s6gi4Xg3CvWwg83nvzMnxbchS2qGsjrR',\n",
       " '13Dfs7iFTXQPwTsFRnYeAtyd5k2wtJbWDH',\n",
       " '14N1yBVSvAo8QCUcFkRj64bww2izqEBBSK',\n",
       " '1EXpMiRx8oNPW1xbPoJ5GrUoYDmwuAjhk1',\n",
       " '15HnhhGCDWCsi9nzTwZKEardmKjUYQvpoS',\n",
       " '1PEQd4anLBQRji4gDjwAXfqGUX9JNNpz8e',\n",
       " '1AXGcNwWh8DW5nJyr7BgTJbzjwKgPRUHvp',\n",
       " '13WJReomzroMrWP3aqYSg4n7rzh2kQFTzP',\n",
       " '1Nj2ctQVzmU85NkbxFJ9Cq7bGMyfvHtK2r',\n",
       " '1CEkg21L6WrSKjGiwLVi1dGF4mtg5bJ1yY',\n",
       " '1QEmyuPtLTcd6VQ8uGZUadStEB22i3vtZG',\n",
       " '12edft25BrCY3evy3eZt7vF6TwsupLXPNF',\n",
       " '1w5fnKPmbWVFvBRnKjVXgevrYEduqerzQ',\n",
       " '17bD4maHP4eczLNYPevFpt9DbV43Z5TrNF',\n",
       " '1LtmiyGRRtc6qPUdWt5Zr4qL6irUpjAUhi',\n",
       " '1EGWPB9FjH8x4R9SyCFS3uBC6ugXmorctZ',\n",
       " '1AT8jAkYQ9N9XXveYFo418GjvxQZZr3Ayf',\n",
       " '1K6iky4TDHhm1B4HVKE2qPynjKj2MAwmB6',\n",
       " '1LHZq7Fzdm7mi5pFvGLgLB5A3hPNpy7F2P',\n",
       " '1BzAVkbrKcBfaAMY1sgXJzkECEmA2zokij',\n",
       " '',\n",
       " '',\n",
       " '1LUGqX6kgXdxVJEXKcBTCMgG8pK1pEFFMF',\n",
       " '1LNaLSuajEdL8HPZZUhkyvCs7XV8N7MFaU',\n",
       " '17RMk28bMzXkaRZBTwBQWDsjjYbP3dEm6X',\n",
       " '1L9rLAdiHDHYA2BaRSYCkYx9T2pThHFTQK',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_bitcoin_addresses(string):\n",
    "    pattern = r'in:[A-Za-z0-9]+'\n",
    "    word = re.findall(pattern, string)\n",
    "    word = [i[3:] if i != \"in:null\" else ''  for i in word]\n",
    "    if '' in word:\n",
    "        word.remove('')\n",
    "    return word\n",
    "    \n",
    "# To test your work, first run:\n",
    "extract_bitcoin_addresses('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n",
    "\n",
    "# Then, once that works, uncomment:\n",
    "extract_bitcoin_addresses(open('data/messy.txt', encoding='utf8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c789ffe5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q03_02</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q03_02 results: All test cases passed!"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q03_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15babce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 3.3 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Complete the implementation of the function `extract_emails`, which takes in a string (`string`) containing the contents of a server log file and returns the email addresses in the file as a list. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> extract_emails('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n",
    "['test@test55.umich.edu']\n",
    "\n",
    ">>> out = extract_emails(open('data/messy.txt', encoding='utf8').read())\n",
    ">>> out[0]\n",
    "'dottewell0@gnu.org'\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- Assume that the usernames and domain names in an email address are alphanumeric. Domain names don't need to end in `'.com'` ‚Äì assume that all parts of a domain name, including the very end, can be made up of any alphanumeric characters.\n",
    "- The returned list should not contain any empty strings or the string `'null'`. (It likely won't by default, but we've included this instruction in all four parts of this question.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74648b61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dottewell0@gnu.org',\n",
       " 'bassiter1@sphinn.com',\n",
       " 'dtitmarsh2@dailymail.co.uk',\n",
       " 'mcolliber3@fda.gov',\n",
       " 'ohachard4@bbb.org',\n",
       " 'aaikman5@cnet.com',\n",
       " 'bgiovannacci6@theglobeandmail.com',\n",
       " 'tbritton7@nytimes.com',\n",
       " 'dcheeney8@mail.ru',\n",
       " 'kkordes9@prweb.com',\n",
       " 'bcottrilla@gmpg.org',\n",
       " 'sdoumencb@cbslocal.com',\n",
       " 'fandreec@nhs.uk',\n",
       " 'epaviourd@ameblo.jp',\n",
       " 'wlongegae@disqus.com',\n",
       " 'bofihilyf@house.gov',\n",
       " 'slinceg@xrea.com',\n",
       " 'kdumphreyh@hc360.com',\n",
       " 'mhowseleei@vistaprint.com',\n",
       " 'gseelj@reuters.com',\n",
       " 'lcroixk@ocn.ne.jp',\n",
       " 'wudalll@engadget.com',\n",
       " 'wmcdavittm@comsenz.com',\n",
       " 'nalmondn@reference.com',\n",
       " 'cjesseo@mail.ru',\n",
       " 'mlibbeq@telegraph.co.uk',\n",
       " 'jmacgorleyr@rediff.com',\n",
       " 'cgooks@shinystat.com',\n",
       " 'tdipplet@apple.com',\n",
       " 'lwarinu@shop-pro.jp',\n",
       " 'slethbridgev@java.com',\n",
       " 'lteggartw@dion.ne.jp',\n",
       " 'ecoulstonx@networkadvertising.org',\n",
       " 'scheccuzziy@umn.edu',\n",
       " 'ddunstanz@cnet.com#TTt34W5xdc',\n",
       " 'fmcgooch11@joomla.org',\n",
       " 'kgommowe13@tiny.cc',\n",
       " 'sgoulding14@cmu.edu',\n",
       " 'jgrelak15@blogs.com',\n",
       " 'hcuddehay17@alexa.com',\n",
       " 'csussex18@amazon.co.uk',\n",
       " 'achippendale19@feedburner.com',\n",
       " 'lskerme1a@ehow.com',\n",
       " 'gpeeters1b@freewebs.com',\n",
       " 'gschrieves1c@infoseek.co.jp',\n",
       " 'kbrugemann1d@skyrock.com',\n",
       " 'cdeerr1e@state.tx.us',\n",
       " 'echaise1f@ucoz.ru',\n",
       " 'wbartomeu1g@wikipedia.org',\n",
       " 'ptheunissen1h@nifty.com#YiNoxXQyFsiC',\n",
       " 'nmartyntsev1i@sogou.com',\n",
       " 'myukhin1j@livejournal.com',\n",
       " 'ashimwell1k@google.com#TXoo4ysJ2zWW',\n",
       " 'afolbig1l@paypal.com',\n",
       " 'mfranceschelli1m@google.com',\n",
       " 'tgillis1n@skype.com',\n",
       " 'gaery1o@ycombinator.com',\n",
       " 'jdavis1p@zimbio.com#soyUlgWpYp',\n",
       " 'gbromidge1r@tinypic.com',\n",
       " 'bdupoy1s@wunderground.com',\n",
       " 'shickeringill1t@whitehouse.gov',\n",
       " 'ameachen1u@hud.gov',\n",
       " 'slaffling1v@npr.org',\n",
       " 'msulman1w@bravesites.com',\n",
       " 'msails1x@ning.com',\n",
       " 'jconkie1y@i2i.jp',\n",
       " 'jskyppe1z@etsy.com',\n",
       " 'bmufford20@census.gov#a9nFSvYM40r',\n",
       " 'saxelbey21@vistaprint.com',\n",
       " 'gdommersen22@wikimedia.org',\n",
       " 'dbalazot23@hatena.ne.jp',\n",
       " 'lcoo24@free.fr',\n",
       " 'anix26@meetup.com',\n",
       " 'kcoster27@prlog.org',\n",
       " 'lspringell28@biblegateway.com',\n",
       " 'pswallwell29@ycombinator.com',\n",
       " 'ywearden2a@senate.gov',\n",
       " 'elamborne2d@tripod.com',\n",
       " 'xtothacot2e@fotki.com',\n",
       " 'fscorrer2f@ted.com',\n",
       " 'tsondland2g@sphinn.com',\n",
       " 'dhadaway2h@instagram.com',\n",
       " 'atschirasche2i@google.nl',\n",
       " 'sknoles2j@sciencedirect.com',\n",
       " 'sgager2k@hud.gov',\n",
       " 'tdumbelton2l@multiply.com',\n",
       " 'ddowty2m@google.nl',\n",
       " 'tcottom2n@theguardian.com',\n",
       " 'rsimms2o@vk.com',\n",
       " 'landriveau2p@cloudflare.com',\n",
       " 'csitlinton2r@youtu.be',\n",
       " 'erowledge2s@wikia.com',\n",
       " 'wfilippo2u@elpais.com',\n",
       " 'mminifie2v@github.com#qn6iFdxTu9',\n",
       " 'rcallington2w@amazon.co.jp',\n",
       " 'ihuckett2x@ucsd.edu#mQY2iSDUT',\n",
       " 'sgilardi2y@hexun.com',\n",
       " 'skencott2z@umn.edu',\n",
       " 'ddany30@lycos.com',\n",
       " 'rarling31@taobao.com',\n",
       " 'bmccuaig32@ft.com#0Ywp76zV',\n",
       " 'hpury33@yahoo.co.jp',\n",
       " 'bziehms34@smugmug.com',\n",
       " 'gadicot35@cbslocal.com',\n",
       " 'hgorstidge37@g.co',\n",
       " 'scruddas38@slate.com',\n",
       " 'kbedford39@google.de',\n",
       " 'jrussam3a@photobucket.com',\n",
       " 'tianne3b@rakuten.co.jp',\n",
       " 'yokeshott3c@opensource.org',\n",
       " 'rkinvig3d@admin.ch',\n",
       " 'krubinlicht3e@hud.gov#7wU71pmV0pIc',\n",
       " 'mdelagua3f@ox.ac.uk',\n",
       " 'lpregal3g@nature.com#75M3OMV',\n",
       " 'ospawton3h@php.net',\n",
       " 'edeeny3i@google.cn',\n",
       " 'peaglen3j@biblegateway.com',\n",
       " 'bperigo3k@yellowbook.com',\n",
       " 'jjanosevic3l@stanford.edu',\n",
       " 'mliffey3m@theglobeandmail.com',\n",
       " 'lhinzer3n@go.com',\n",
       " 'pwildash3o@fastcompany.com',\n",
       " 'bmerry3p@wp.com',\n",
       " 'rrapp3q@jugem.jp',\n",
       " 'hsumers3r@msu.edu',\n",
       " 'cboshers3s@linkedin.com',\n",
       " 'joteague3t@illinois.edu',\n",
       " 'pdey3u@virginia.edu',\n",
       " 'mmcewan3v@nps.gov',\n",
       " 'smattiato3w@geocities.jp',\n",
       " 'ggoody3x@dailymotion.com',\n",
       " 'bpetrelli3y@163.com',\n",
       " 'mdemetz3z@statcounter.com',\n",
       " 'atrinder40@devhub.com',\n",
       " 'awoolbrook41@1und1.de',\n",
       " 'dpawelski43@about.com',\n",
       " 'ningledow44@discuz.net',\n",
       " 'gdrohun45@tiny.cc',\n",
       " 'hbreward46@sphinn.com#PRn20LFJSnto',\n",
       " 'locarran47@e-recht24.de',\n",
       " 'pbattista48@princeton.edu#KhW5uyEUicZ',\n",
       " 'amurrell49@goodreads.com',\n",
       " 'ddielhenn4a@qq.com',\n",
       " 'rtailby4b@sohu.com#VDAOq50lt8',\n",
       " 'mreams4c@ebay.com',\n",
       " 'nfriman4d@dagondesign.com#Yqg6EcSp8i',\n",
       " 'aiddison4e@so-net.ne.jp',\n",
       " 'rkowalski4f@studiopress.com',\n",
       " 'gstiffkins4g@gizmodo.com',\n",
       " 'csouthward4h@spotify.com',\n",
       " 'ehecks4i@dropbox.com',\n",
       " 'wmacclenan4j@yelp.com',\n",
       " 'wmcilharga4k@columbia.edu',\n",
       " 'phonacker4l@redcross.org#ImA8sZNOB',\n",
       " 'cbeswick4m@dot.gov',\n",
       " 'ggulk4n@si.edu',\n",
       " 'aarrigucci4o@quantcast.com',\n",
       " 'kprobets4p@businessinsider.com',\n",
       " 'pmatches4r@cpanel.net',\n",
       " 'mhammerberger4s@yolasite.com',\n",
       " 'gfrudd4t@indiatimes.com',\n",
       " 'pmorforth4v@ning.com',\n",
       " 'dlyngsted4w@cnbc.com',\n",
       " 'vassante4x@toplist.cz',\n",
       " 'pleather4y@businesswire.com',\n",
       " 'lkytley50@sfgate.com',\n",
       " 'dwalewicz51@msn.com',\n",
       " 'dphibb52@netlog.com',\n",
       " 'mpflieger53@businesswire.com',\n",
       " 'mpolon54@theglobeandmail.com',\n",
       " 'lunwins55@discuz.net',\n",
       " 'cdainton56@cnn.com',\n",
       " 'vglowach57@dagondesign.com',\n",
       " 'ewoodley58@rakuten.co.jp',\n",
       " 'kradeliffe59@scientificamerican.com',\n",
       " 'moxborrow5a@psu.edu',\n",
       " 'tfaircley5b@virginia.edu',\n",
       " 'jlemerchant5c@kickstarter.com',\n",
       " 'lblakeden5d@miibeian.gov.cn',\n",
       " 'rdaughtry5e@blogger.com',\n",
       " 'nbrownbridge5f@comsenz.com',\n",
       " 'hswinnard5g@pinterest.com',\n",
       " 'sdunsire5h@51.la#h3Dn4t0fa',\n",
       " 'mlevens5i@cargocollective.com',\n",
       " 'vconibeer5j@youku.com',\n",
       " 'lpere5k@wunderground.com',\n",
       " 'jivakhnov5l@1688.com',\n",
       " 'mlack5m@netscape.com',\n",
       " 'lomeara5n@tripod.com',\n",
       " 'avaines5o@census.gov',\n",
       " 'rganter5p@altervista.org',\n",
       " 'jtidd5q@ehow.com',\n",
       " 'lkertess5r@ed.gov',\n",
       " 'pmullinder5s@time.com',\n",
       " 'bnelles5t@huffingtonpost.com',\n",
       " 'ggaffon5u@amazon.com',\n",
       " 'ehadfield5v@ocn.ne.jp',\n",
       " 'lpennrington5w@foxnews.com#RNIg7hkaUuE',\n",
       " 'whassin5x@i2i.jp',\n",
       " 'adevaen5y@merriam-webster.com',\n",
       " 'dreek5z@gnu.org',\n",
       " 'epalmar60@salon.com',\n",
       " 'cnoad61@t-online.de',\n",
       " 'avittet62@jugem.jp',\n",
       " 'kocrotty63@ft.com',\n",
       " 'mdibdall64@wikipedia.org',\n",
       " 'ralessandone65@unblog.fr',\n",
       " 'tfleckno66@cnet.com',\n",
       " 'hwastling67@aboutads.info',\n",
       " 'alegrice68@jimdo.com',\n",
       " 'asangwin69@theatlantic.com',\n",
       " 'jwoollaston6a@smh.com.au',\n",
       " 'dhobson6b@quantcast.com',\n",
       " 'hpickford6c@dion.ne.jp',\n",
       " 'jclayill6d@eventbrite.com#9yb7gccvOE#\\ufeff',\n",
       " 'faddekin6e@wix.com',\n",
       " 'sgisburn6f@icq.com',\n",
       " 'crutley6g@nhs.uk',\n",
       " 'ileddie6h@google.com.br',\n",
       " 'ccecchi6j@marketwatch.com',\n",
       " 'gsmitherham6k@bravesites.com#27rhP3n3UdV',\n",
       " 'bellingford6l@artisteer.com#e85BCnM',\n",
       " 'wgyford6m@harvard.edu',\n",
       " 'tmorritt6o@utexas.edu',\n",
       " 'fstiell6p@about.com',\n",
       " 'mteape6q@usnews.com',\n",
       " 'tlindley6r@bigcartel.com',\n",
       " 'gmessruther6s@zdnet.com',\n",
       " 'pkhoter6t@ftc.gov',\n",
       " 'mspens6u@weibo.com',\n",
       " 'mwalesa6v@jimdo.com',\n",
       " 'xlavrick6w@xrea.com',\n",
       " 'estearne6x@amazon.co.uk',\n",
       " 'marnall6y@addthis.com',\n",
       " 'kcharville6z@nbcnews.com',\n",
       " 'dgainsborough71@businessweek.com',\n",
       " 'fyurygyn72@canalblog.com',\n",
       " 'amckinney73@seesaa.net',\n",
       " 'jseyers74@fda.gov',\n",
       " 'epetzolt75@goo.gl',\n",
       " 'bbateson76@wsj.com',\n",
       " 'twhetton77@msn.com',\n",
       " 'scaldow78@prlog.org',\n",
       " 'dmoggie79@google.ca',\n",
       " 'kdunstan7a@nydailynews.com',\n",
       " 'lmilverton7b@creativecommons.org',\n",
       " 'gcahen7c@ucoz.ru',\n",
       " 'hgeelan7d@jalbum.net',\n",
       " 'jstraw7e@dailymotion.com#CWYkr8jY7',\n",
       " 'mnerval7f@tiny.cc',\n",
       " 'kpemberton7g@cbslocal.com',\n",
       " 'reingerfield7h@bizjournals.com',\n",
       " 'dbarraclough7i@wsj.com',\n",
       " 'gabsalom7j@omniture.com',\n",
       " 'coskehan7k@pinterest.com',\n",
       " 'epellissier7l@digg.com',\n",
       " 'lcrighten7m@e-recht24.de',\n",
       " 'msanpher7n@multiply.com',\n",
       " 'tquilty7o@ucoz.ru',\n",
       " 'htort7p@who.int',\n",
       " 'gnockles7q@g.co',\n",
       " 'kvockins7r@tiny.cc',\n",
       " 'dreisk7t@livejournal.com',\n",
       " 'lhuckel7u@techcrunch.com',\n",
       " 'dpacitti7v@slideshare.net',\n",
       " 'dcallf7w@cnn.com#HkzZNw0xb',\n",
       " 'hmousby7x@mit.edu',\n",
       " 'bpilpovic7y@yahoo.co.jp',\n",
       " 'kandryushin80@cbslocal.com#0r67kU',\n",
       " 'gbosquet81@hhs.gov',\n",
       " 'vwaddell82@51.la#UOTcfp#≈ì‚àë¬¥¬Æ‚Ä†¬•¬®ÀÜ√∏œÄ‚Äú‚Äò',\n",
       " 'sstroton83@blogger.com#umLahk21',\n",
       " 'skleimt84@moonfruit.com',\n",
       " 'epoppleton85@apache.org',\n",
       " 'erattray86@squidoo.com',\n",
       " 'bgormley87@mit.edu',\n",
       " 'dkirdsch88@google.pl#ZG91cyemZS',\n",
       " 'ncutress89@examiner.com#Rcd5IPE',\n",
       " 'rmolnar8a@cnet.com',\n",
       " 'cbizzey8b@wordpress.org',\n",
       " 'hlandrick8c@gravatar.com',\n",
       " 'mstairs8d@xrea.com',\n",
       " 'abonsey8e@ask.com#Vp8bLRPlpX',\n",
       " 'hrope8f@skyrock.com',\n",
       " 'mtinson8h@mozilla.org',\n",
       " 'kcaulier8i@hao123.com#LVEndxfV9dW8',\n",
       " 'atinman8j@last.fm#Oop7sG',\n",
       " 'eharness8k@google.cn',\n",
       " 'cregi8l@bing.com',\n",
       " 'ereyne8m@webeden.co.uk',\n",
       " 'rohannen8n@about.me',\n",
       " 'etheuff8o@dailymotion.com',\n",
       " 'frosier8p@digg.com',\n",
       " 'bpisco8q@aboutads.info',\n",
       " 'aivshin8r@google.it',\n",
       " 'cbretelle8s@webmd.com',\n",
       " 'jmcilvenny8t@irs.gov',\n",
       " 'dleivers8u@example.com',\n",
       " 'gbiggins8v@storify.com',\n",
       " 'bpervoe8w@jimdo.com',\n",
       " 'dcotterrill8x@dropbox.com#fxaKjSF',\n",
       " 'wstave8y@1und1.de',\n",
       " 'cchasen90@ft.com',\n",
       " 'eattril91@weebly.com',\n",
       " 'mgodbald92@netvibes.com',\n",
       " 'wpierro93@un.org',\n",
       " 'kgaskin94@freewebs.com',\n",
       " 'arabb95@nba.com',\n",
       " 'lmartineau96@buzzfeed.com',\n",
       " 'hwassung97@shinystat.com',\n",
       " 'scruickshank98@paypal.com#Ts112Btf',\n",
       " 'lmichiel99@com.com',\n",
       " 'mpaley9a@oakley.com',\n",
       " 'ihutcheson9b@hhs.gov',\n",
       " 'jtenman9c@jugem.jp',\n",
       " 'ewebermann9d@live.com',\n",
       " 'baslett9e@mashable.com',\n",
       " 'anegri9f@cornell.edu',\n",
       " 'nsallans9h@google.com.hk',\n",
       " 'ebernolet9i@tiny.cc',\n",
       " 'eviggers9j@angelfire.com',\n",
       " 'mkonert9k@blinklist.com',\n",
       " 'hmarley9l@fda.gov#mYDaT4klnu#-1/2',\n",
       " 'bgrabb9m@mozilla.com',\n",
       " 'bhackney9n@youtube.com',\n",
       " 'ehartus9o@paypal.com',\n",
       " 'rpleat9p@cbslocal.com',\n",
       " 'sbannard9q@upenn.edu',\n",
       " 'tcorneil9r@simplemachines.org',\n",
       " 'kshere9s@sciencedirect.com',\n",
       " 'skimberly9t@angelfire.com',\n",
       " 'ccrowson9u@livejournal.com',\n",
       " 'jelderkin9v@goo.ne.jp',\n",
       " 'lscallon9w@ucoz.com',\n",
       " 'abrownell9x@house.gov',\n",
       " 'bkinnoch9y@mac.com',\n",
       " 'cprinett9z@adobe.com',\n",
       " 'fdavauxa0@slideshare.net',\n",
       " 'ngudgera1@hc360.com',\n",
       " 'wberthona2@skyrock.com',\n",
       " 'fhyslopa3@statcounter.com',\n",
       " 'ereddya4@blogger.com',\n",
       " 'dlovewella5@theglobeandmail.com',\n",
       " 'eruskea6@disqus.com',\n",
       " 'mcawsa7@yandex.ru',\n",
       " 'cchampa8@about.com',\n",
       " 'rwaddilowa9@prlog.org',\n",
       " 'dbathaaa@angelfire.com',\n",
       " 'bmaconab@squarespace.com',\n",
       " 'amcmickanac@zdnet.com',\n",
       " 'eastellad@sciencedirect.com',\n",
       " 'erollinshawae@youtu.be',\n",
       " 'mlathleiffureaf@vinaora.com',\n",
       " 'acrosdillag@elegantthemes.com',\n",
       " 'bbarochah@addthis.com',\n",
       " 'jpowlettai@creativecommons.org',\n",
       " 'mcausonaj@economist.com',\n",
       " 'mbatherak@hostgator.com#HTQ7NzTQCUZ',\n",
       " 'rlampardal@quantcast.com',\n",
       " 'dandriulisam@wiley.com',\n",
       " 'mcowburnan@examiner.com',\n",
       " 'abranchetao@indiatimes.com',\n",
       " 'jredittap@creativecommons.org',\n",
       " 'agirogettiaq@artisteer.com',\n",
       " 'lwillsherear@independent.co.uk',\n",
       " 'abootas@timesonline.co.uk',\n",
       " 'tavrahamofat@wikipedia.org',\n",
       " 'crakestrawau@psu.edu',\n",
       " 'ipochinav@photobucket.com',\n",
       " 'cduckeraw@drupal.org',\n",
       " 'bcostenax@wikipedia.org',\n",
       " 'asmallpeaceay@so-net.ne.jp',\n",
       " 'byarrowaz@sciencedaily.com',\n",
       " 'mlegalleb0@census.gov',\n",
       " 'adominellib1@flickr.com',\n",
       " 'kstarsmeareb2@ask.com',\n",
       " 'pscalab3@dropbox.com',\n",
       " 'ghallyburtonb4@sohu.com',\n",
       " 'eberkleyb5@mozilla.org#KI7fcL4hL',\n",
       " 'mtembeyb6@mapquest.com',\n",
       " 'rhuntingtonb7@salon.com',\n",
       " 'ggolagleyb8@qq.com',\n",
       " 'kpalluschekb9@blogger.com#aq6mjkKkbLt#999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999',\n",
       " 'egolsonba@networkadvertising.org',\n",
       " 'smozzinibb@acquirethisname.com#cr3qPd',\n",
       " 'ralenovbc@cornell.edu',\n",
       " 'ilearmanbd@dedecms.com',\n",
       " 'ksiebertbe@parallels.com',\n",
       " 'fbrabhambf@google.co.uk',\n",
       " 'fsimminsbg@google.es',\n",
       " 'shurfordbh@toplist.cz',\n",
       " 'rduxbarrybi@chron.com',\n",
       " 'etottlebj@statcounter.com',\n",
       " 'rstrettellbk@pcworld.com',\n",
       " 'ecrannabl@blog.com',\n",
       " 'lrichiebm@weather.com',\n",
       " 'cjirzikbn@nbcnews.com',\n",
       " 'nroobottombo@ow.ly',\n",
       " 'adryburghbp@topsy.com',\n",
       " 'istopherbq@posterous.com',\n",
       " 'lmarrowbr@barnesandnoble.com',\n",
       " 'sbingellbs@google.com',\n",
       " 'lpizzeybt@ask.com',\n",
       " 'fgabbettbu@mashable.com',\n",
       " 'bmcguckinbv@opera.com',\n",
       " 'thartnessbw@mozilla.com',\n",
       " 'rfurzeybx@feedburner.com',\n",
       " 'adasparby@yahoo.com',\n",
       " 'kdewberrybz@ow.ly#gR1Qmvkmh9',\n",
       " 'cbumphriesc0@rambler.ru',\n",
       " 'abazochec1@mediafire.com',\n",
       " 'bleathwoodc2@vistaprint.com',\n",
       " 'ahuffeyc3@mac.com',\n",
       " 'lbeverstockc4@fda.gov',\n",
       " 'rclemmittc5@npr.org#mOWyMuv1LE',\n",
       " 'vgatecliffec6@addthis.com',\n",
       " 'fbeavonc7@amazon.co.uk',\n",
       " 'mregnardc8@yahoo.com',\n",
       " 'rdemangeotc9@xinhuanet.com',\n",
       " 'agonnellyca@hostgator.com',\n",
       " 'mtorrecb@skyrock.com',\n",
       " 'rtriponcc@japanpost.jp',\n",
       " 'theywardcd@tripod.com',\n",
       " 'lglancyce@alexa.com',\n",
       " 'jyandlecf@wired.com',\n",
       " 'ffaustiancg@gmpg.org',\n",
       " 'rbingallch@loc.gov',\n",
       " 'akasci@eventbrite.com',\n",
       " 'rforsaithcj@arstechnica.com',\n",
       " 'avarnesck@buzzfeed.com',\n",
       " 'sotsoncl@surveymonkey.com',\n",
       " 'chubachcm@paginegialle.it',\n",
       " 'fwhitemancn@mashable.com',\n",
       " 'tcollacombeco@sfgate.com',\n",
       " 'jdonaticp@tinypic.com',\n",
       " 'rhymascq@cbc.ca',\n",
       " 'aashfieldcr@yellowpages.com',\n",
       " 'gviallcs@auda.org.au',\n",
       " 'skennaghct@businessinsider.com',\n",
       " 'cathercu@amazonaws.com',\n",
       " 'dmammattcv@icq.com',\n",
       " 'bdudhillcw@aboutads.info',\n",
       " 'bmoylanecx@va.gov',\n",
       " 'vgwynnecy@economist.com',\n",
       " 'rlaurentcz@behance.net',\n",
       " 'kemminesd0@bbc.co.uk',\n",
       " 'ddelled2@abc.net.au',\n",
       " 'anewittd3@mysql.com',\n",
       " 'npevsnerd4@examiner.com',\n",
       " 'cmuffittd5@fema.gov',\n",
       " 'jperrygod6@istockphoto.com',\n",
       " 'djorissend8@spotify.com',\n",
       " 'fsalvadord9@mozilla.com',\n",
       " 'lmatysiakda@cloudflare.com',\n",
       " 'dhindmoordb@comcast.net',\n",
       " 'ubarzdc@timesonline.co.uk',\n",
       " 'jwincklesdd@imdb.com',\n",
       " 'mklausende@yellowpages.com#',\n",
       " 'glangmuirdf@ed.gov',\n",
       " 'phurdwelldg@360.cn',\n",
       " 'lkellawaydh@amazon.co.jp',\n",
       " 'lwindleydi@pagesperso-orange.fr',\n",
       " 'rrossbrookdj@list-manage.com',\n",
       " 'bscranedgedk@constantcontact.com',\n",
       " 'kbrooktondl@hubpages.com',\n",
       " 'afillgatedm@typepad.com#srHeY2Og',\n",
       " 'cgareisrdn@webs.com',\n",
       " 'cshirlanddo@mapquest.com',\n",
       " 'jrawlsdp@toplist.cz',\n",
       " 'sguislerdq@soup.io',\n",
       " 'bgergelydr@bing.com#aee4GdNHth',\n",
       " 'fmeakinds@gnu.org',\n",
       " 'gvernazzadt@slate.com#k2oudK',\n",
       " 'hbinerdu@squarespace.com',\n",
       " 'lnowickdv@stanford.edu',\n",
       " 'esleightholmdw@1und1.de',\n",
       " 'rthonasondy@yolasite.com',\n",
       " 'drizzardodz@istockphoto.com',\n",
       " 'cmcduffye0@uol.com.br',\n",
       " 'abolsteridgee1@stanford.edu',\n",
       " 'ccregeene2@dion.ne.jp',\n",
       " 'bbestmane3@mediafire.com',\n",
       " 'rwandrache4@zdnet.com',\n",
       " 'hnestlee5@google.co.uk',\n",
       " 'jschwandere6@lycos.com#I80FhguH',\n",
       " 'jkettse7@etsy.com',\n",
       " 'gschorahe8@themeforest.net',\n",
       " 'aboggishe9@ifeng.com',\n",
       " 'kwychea@amazon.co.jp#QgGrVZ7NbfT',\n",
       " 'lrennereb@ehow.com#pTLPjnlyZxs',\n",
       " 'cjonesec@biblegateway.com',\n",
       " 'rorridgeed@prlog.org',\n",
       " 'zcurryeree@boston.com',\n",
       " 'rbrimelowef@hubpages.com',\n",
       " 'mhearsteg@umn.edu#9nluihr0u0FZ',\n",
       " 'ihateleyeh@themeforest.net',\n",
       " 'tgounodei@themeforest.net#IXo1obYFv',\n",
       " 'rexeterej@businesswire.com',\n",
       " 'haspel@booking.com#4fovyq9qrHTK',\n",
       " 'dgusneyem@nsw.gov.au',\n",
       " 'mgrendonen@angelfire.com',\n",
       " 'aoagereo@lycos.com',\n",
       " 'nmeddep@tmall.com',\n",
       " 'pchueeq@smugmug.com#snPkVNF',\n",
       " 'gleechmaner@engadget.com',\n",
       " 'mpitfordes@walmart.com#',\n",
       " 'hmcdermidet@godaddy.com',\n",
       " 'kgiraudyeu@cnbc.com#ZCwE5Z7LVpPR',\n",
       " 'kgilbanksev@over-blog.com',\n",
       " 'cmcandrewew@oakley.com',\n",
       " 'ibattenex@blog.com',\n",
       " 'amaclardieey@dagondesign.com',\n",
       " 'aklawiez@who.int',\n",
       " 'gwhitnellf0@youtube.com',\n",
       " 'jtoomerf1@princeton.edu',\n",
       " 'khimpsonf2@instagram.com',\n",
       " 'grottgerf3@ucsd.edu',\n",
       " 'lsporgeonf4@nhs.uk',\n",
       " 'priochf5@alexa.com',\n",
       " 'oroddickf7@theatlantic.com',\n",
       " 'atarbetf8@cpanel.net',\n",
       " 'amelleyf9@ycombinator.com',\n",
       " 'dfernandesfa@cafepress.com',\n",
       " 'cswaitefb@salon.com',\n",
       " 'deilersfc@blogs.com',\n",
       " 'btheodorefd@chron.com',\n",
       " 'ahewlingsfe@ihg.com',\n",
       " 'djeavonff@cmu.edu#6roz1Q',\n",
       " 'mdjorevicfg@topsy.com',\n",
       " 'oheismanfh@diigo.com',\n",
       " 'bmcfaellfi@nature.com',\n",
       " 'eswadlinfj@hexun.com',\n",
       " 'rolynnfk@nydailynews.com',\n",
       " 'averrillofl@istockphoto.com',\n",
       " 'nmathevetfm@feedburner.com',\n",
       " 'rmcknockiterfn@dyndns.org',\n",
       " 'astrowlgerfo@pinterest.com',\n",
       " 'gbuckinghamfp@google.co.uk',\n",
       " 'vemneyfq@illinois.edu',\n",
       " 'jdanforthfr@spotify.com#msjwHWWl',\n",
       " 'cyarmouthfs@parallels.com',\n",
       " 'kprobbinft@upenn.edu',\n",
       " 'phaddenfu@twitpic.com',\n",
       " 'bwitteyfv@constantcontact.com#bwkcKsF',\n",
       " 'lpookfw@rambler.ru',\n",
       " 'mmcalinefx@discovery.com',\n",
       " 'mmealefy@slideshare.net',\n",
       " 'dmoorefz@mlb.com',\n",
       " 'lpybusg0@trellian.com',\n",
       " 'wcrackerg1@blinklist.com',\n",
       " 'bpipeg2@nationalgeographic.com',\n",
       " 'dattacg3@latimes.com',\n",
       " 'jdesseineg4@hugedomains.com',\n",
       " 'crennardg5@dot.gov',\n",
       " 'bexelbyg6@reuters.com',\n",
       " 'ccollatong7@mail.ru',\n",
       " 'bcroomeg8@gizmodo.com#zuY9NNnQkb5D',\n",
       " 'mjakesg9@bloglovin.com',\n",
       " 'csermanga@facebook.com',\n",
       " 'gwiersmagb@wsj.com',\n",
       " 'cblavergc@umich.edu',\n",
       " 'slinnardge@vinaora.com',\n",
       " 'xachrameevgf@dion.ne.jp#Stdd0zosIrKs',\n",
       " 'jpagangg@alibaba.com',\n",
       " 'noldreygh@ask.com',\n",
       " 'rsharergi@i2i.jp',\n",
       " 'sgurkogj@dot.gov',\n",
       " 'fbadlandgk@nih.gov',\n",
       " 'dgynnigl@hp.com',\n",
       " 'gbleackleygm@yellowbook.com',\n",
       " 'phouchingn@printfriendly.com',\n",
       " 'akalkofengo@wikia.com',\n",
       " 'mbramhillgp@google.pl#JMGjNXP7jOY',\n",
       " 'lbeekmanngq@opera.com',\n",
       " 'fundrellgr@trellian.com',\n",
       " 'gshaddockgs@lulu.com',\n",
       " 'wwhethergt@seattletimes.com',\n",
       " 'vtwidellgu@ezinearticles.com',\n",
       " 'uhanbidgegv@woothemes.com#jFnO2g87K',\n",
       " 'gsivorngw@businesswire.com',\n",
       " 'kwindaybankgx@dell.com',\n",
       " 'bholseygy@ftc.gov',\n",
       " 'vkeelh0@foxnews.com#4f6PLE9Yf',\n",
       " 'cloosmoreh1@vimeo.com',\n",
       " 'mdavidmanh2@bluehost.com',\n",
       " 'jmoseh3@howstuffworks.com',\n",
       " 'kgreevesonh4@cloudflare.com',\n",
       " 'gcribbinsh5@hubpages.com',\n",
       " 'tlamperdh6@gmpg.org',\n",
       " 'nbotteh7@theglobeandmail.com',\n",
       " 'sboldrah8@wisc.edu',\n",
       " 'tmakinsonh9@plala.or.jp',\n",
       " 'ivirrha@lycos.com',\n",
       " 'cspurginhb@independent.co.uk',\n",
       " 'bferriereshc@typepad.com',\n",
       " 'gbewleyhd@rakuten.co.jp',\n",
       " 'flangabeerhe@hibu.com',\n",
       " 'tmakinsonhf@phpbb.com',\n",
       " 'cmaciakhh@cisco.com',\n",
       " 'cclementethi@kickstarter.com',\n",
       " 'gtruluckhj@ustream.tv',\n",
       " 'mandriveauxhk@altervista.org',\n",
       " 'mjerschhl@accuweather.com#sZ9jibWem',\n",
       " 'tprobackhm@usda.gov',\n",
       " 'adooreyhn@etsy.com',\n",
       " 'gthorndaleho@cornell.edu',\n",
       " 'vfarrimondhp@ehow.com',\n",
       " 'fsainsberryhq@lycos.com',\n",
       " 'tsavilehr@oaic.gov.au',\n",
       " 'piowarchhs@shop-pro.jp',\n",
       " 'cmorcomht@google.com.hk#MQGTOJ9b01h',\n",
       " 'pedmeadshu@mashable.com#qF7X3r',\n",
       " 'ahercockhv@51.la',\n",
       " 'brentollhw@dell.com#4p0PaFalQThN',\n",
       " 'mmeffinhx@auda.org.au',\n",
       " 'awalczakhy@narod.ru',\n",
       " 'pcrowtherhz@dion.ne.jp',\n",
       " 'cbachei0@sina.com.cn',\n",
       " 'fbutlerbowdoni1@walmart.com',\n",
       " 'farchelli2@youku.com',\n",
       " 'hmcnicoli3@reuters.com',\n",
       " 'pcombei4@seattletimes.com',\n",
       " 'cogdeni5@toplist.cz',\n",
       " 'bwhitmelli6@reddit.com',\n",
       " 'tguiheni7@last.fm',\n",
       " 'grammi8@prweb.com',\n",
       " 'kconrardi9@blinklist.com',\n",
       " 'bspoltonia@blogtalkradio.com',\n",
       " 'gdruhanib@go.com#',\n",
       " 'fsimmsic@acquirethisname.com#jsJZvlJ',\n",
       " 'rwinwrightid@myspace.com',\n",
       " 'jwoollardie@cornell.edu',\n",
       " 'ceuesdenif@ameblo.jp',\n",
       " 'tjumelig@dot.gov',\n",
       " 'nhammantih@economist.com',\n",
       " 'oatheisii@phpbb.com',\n",
       " 'egovinlockij@intel.com',\n",
       " 'cburdettik@unesco.org',\n",
       " 'lmcquodeil@typepad.com',\n",
       " 'kbrickellim@msn.com#2utU344t95t',\n",
       " 'mloddenin@linkedin.com',\n",
       " 'bvyseio@howstuffworks.com',\n",
       " 'bwinspeareip@dion.ne.jp',\n",
       " 'mhaylandiq@seesaa.net',\n",
       " 'jloveladyir@ezinearticles.com',\n",
       " 'sslatenis@slashdot.org',\n",
       " 'lbrasonit@dedecms.com',\n",
       " 'jdeeganiu@surveymonkey.com',\n",
       " 'jbrixeyiv@xinhuanet.com',\n",
       " 'akingcottiw@mlb.com',\n",
       " 'abeattieix@deviantart.com',\n",
       " 'ageeringiy@icio.us',\n",
       " 'jwoodroughiz@flavors.me',\n",
       " 'kwinshipj0@furl.net',\n",
       " 'pdonahoj1@nps.gov#',\n",
       " 'hmellersj2@amazon.com',\n",
       " 'ewillfordj3@twitter.com',\n",
       " 'jgettonej4@craigslist.org',\n",
       " 'ncardenasj5@wiley.com',\n",
       " 'gdimmerj6@google.fr',\n",
       " 'jgebuhrj7@google.pl',\n",
       " 'cpavlukj8@intel.com',\n",
       " 'mreadej9@gmpg.org',\n",
       " 'dziemensja@census.gov',\n",
       " 'mhankardjb@irs.gov',\n",
       " 'achelnamjc@wufoo.com',\n",
       " 'ayorkstonjd@si.edu',\n",
       " 'lhulkeje@1688.com',\n",
       " 'kkippinsjf@usgs.gov',\n",
       " 'nbernardosjg@noaa.gov',\n",
       " 'gsevillejh@imgur.com',\n",
       " 'abrownji@wsj.com#o4eLiilVw',\n",
       " 'nolyffjj@webmd.com',\n",
       " 'kpiddingtonjk@spiegel.de',\n",
       " 'mbalhatchetjl@nydailynews.com',\n",
       " 'msmeedjm@goodreads.com',\n",
       " 'ncorainijo@cam.ac.uk',\n",
       " 'cgawkesjp@reverbnation.com',\n",
       " 'mpeacejq@disqus.com',\n",
       " 'hvarnejr@oracle.com',\n",
       " 'binchcombjs@wiley.com',\n",
       " 'yochterlonyjt@taobao.com',\n",
       " 'kyerrelljv@livejournal.com#gkq6Oq1dQPv',\n",
       " 'gpantryjw@sourceforge.net',\n",
       " 'losheildsjx@furl.net',\n",
       " 'ahillattjy@techcrunch.com',\n",
       " 'acarolinejz@angelfire.com',\n",
       " 'abreensk0@geocities.com',\n",
       " 'klankfordk1@narod.ru',\n",
       " 'sgaugek2@timesonline.co.uk',\n",
       " 'vcurreyk3@infoseek.co.jp',\n",
       " 'vmaccafferkyk5@wisc.edu',\n",
       " 'ehopkinsk6@tiny.cc#FEDIn3',\n",
       " 'mreinbeckk7@github.io',\n",
       " 'omcdougaldk9@technorati.com',\n",
       " 'mrisebarerka@sphinn.com',\n",
       " 'pwickskb@shinystat.com',\n",
       " 'wmcgillegholekc@printfriendly.com',\n",
       " 'aburdenkd@google.com.au',\n",
       " 'ahyamske@fc2.com',\n",
       " 'astuttkf@symantec.com',\n",
       " 'schamberlenkg@eventbrite.com',\n",
       " 'dkelliekh@newyorker.com',\n",
       " 'whuishki@ovh.net',\n",
       " 'kbrounfieldkj@springer.com',\n",
       " 'csommerkk@huffingtonpost.com',\n",
       " 'tmckibbinkl@addthis.com',\n",
       " 'dbailiekm@tmall.com',\n",
       " 'lgriffithsko@vinaora.com#6vsSWio6MaPL',\n",
       " 'chanigankq@spotify.com',\n",
       " 'lcargenkr@joomla.org',\n",
       " 'cgarwillks@w3.org',\n",
       " 'bdreinankt@huffingtonpost.com',\n",
       " 'eivanetsku@mayoclinic.com',\n",
       " 'bkettlewellkv@hugedomains.com',\n",
       " 'cmcterrykw@51.la',\n",
       " 'lflecknokx@hatena.ne.jp',\n",
       " 'rzottoky@mediafire.com',\n",
       " 'dbrauneskz@tripadvisor.com',\n",
       " 'vovershottl0@pen.io',\n",
       " 'tmccaffertyl1@youku.com',\n",
       " 'spantryl2@php.net',\n",
       " 'amaileyl3@dailymail.co.uk',\n",
       " 'gthursfieldl4@usa.gov',\n",
       " 'lledburyl5@alexa.com',\n",
       " 'gpurchonl6@shop-pro.jp#49CrniOKyd32',\n",
       " 'ztiptaftl7@google.ru',\n",
       " 'ddiruggerol8@domainmarket.com',\n",
       " 'zperkinl9@spotify.com',\n",
       " 'johrtmannla@1688.com',\n",
       " 'aprelb@oaic.gov.au',\n",
       " 'cgreedyerlc@mysql.com',\n",
       " 'mblaskeld@spiegel.de',\n",
       " 'gpalffyle@jigsy.com',\n",
       " 'dmelsomelf@google.ca',\n",
       " 'ehandoverlg@histats.com',\n",
       " 'retchinghamlh@prweb.com',\n",
       " 'iverickli@shutterfly.com',\n",
       " 'bsheptonlj@businesswire.com',\n",
       " 'tleadbetterlk@biglobe.ne.jp',\n",
       " 'mbagehotll@mit.edu#FiC0PPxdOL',\n",
       " 'gdwellinglm@posterous.com',\n",
       " 'dheathln@nyu.edu',\n",
       " 'blissendenlo@360.cn',\n",
       " 'phendinlp@newyorker.com',\n",
       " 'cvoaslr@forbes.com',\n",
       " 'rglisenanls@usda.gov',\n",
       " 'nstockwelllt@a8.net',\n",
       " 'lmohamedlu@pcworld.com',\n",
       " 'crosenbaumlv@google.co.jp#31ZEDaLvI#◊ë÷º÷∞◊®÷µ◊ê◊©◊Å÷¥◊ô◊™',\n",
       " 'dblagbroughlw@wix.com',\n",
       " 'zrallinglx@vistaprint.com',\n",
       " 'hsummonsly@rambler.ru',\n",
       " 'hwolterslz@answers.com#qcsH1NWl1hcG',\n",
       " 'cnisbithm0@cocolog-nifty.com',\n",
       " 'mdelacotem1@goo.gl',\n",
       " 'mtrillm2@go.com',\n",
       " 'dsimoninim3@alexa.com',\n",
       " 'ndennettm4@alexa.com',\n",
       " 'fdufallm5@clickbank.net',\n",
       " 'amaynem6@miibeian.gov.cn',\n",
       " 'gyeilesm7@about.me',\n",
       " 'hscudderm8@disqus.com',\n",
       " 'pamiesm9@rakuten.co.jp',\n",
       " 'mgrossierma@homestead.com',\n",
       " 'cjeckellmb@si.edu',\n",
       " 'peslermc@reddit.com#iK6rgJw42Av',\n",
       " 'amanueaumd@themeforest.net',\n",
       " 'ihouseleeme@mit.edu',\n",
       " 'fmershmf@storify.com',\n",
       " 'mhanmg@soundcloud.com#U75pw80lZ3',\n",
       " 'gfeyermh@virginia.edu#5TIfLAZju',\n",
       " 'aduplanmi@omniture.com',\n",
       " 'csheffieldmj@addtoany.com',\n",
       " 'ysandlemk@etsy.com',\n",
       " 'tboldryml@goodreads.com',\n",
       " 'nautriemm@photobucket.com',\n",
       " 'cfinchammn@blogger.com',\n",
       " 'bcollingmo@smh.com.au',\n",
       " 'deskriettmp@nature.com',\n",
       " 'bzavatteromq@wikipedia.org',\n",
       " 'lcraddymr@patch.com',\n",
       " 'eginims@mail.ru',\n",
       " 'wharbertmt@slideshare.net',\n",
       " 'dtupiemu@dailymotion.com',\n",
       " 'pslayfordmv@rakuten.co.jp',\n",
       " 'utarneymw@over-blog.com',\n",
       " 'ktullethmx@seattletimes.com',\n",
       " 'sbracermy@tripadvisor.com',\n",
       " 'ebellhangermz@howstuffworks.com',\n",
       " 'vanettsn0@chron.com##ÏÇ¨ÌöåÍ≥ºÌïôÏõê Ïñ¥ÌïôÏó∞Íµ¨ÏÜå',\n",
       " 'mepiscopion1@utexas.edu',\n",
       " 'vorfordn2@blogs.com',\n",
       " 'idolbyn3@clickbank.net',\n",
       " 'lluttonn4@chron.com',\n",
       " 'awishartn6@imageshack.us',\n",
       " 'ecoginn7@epa.gov',\n",
       " 'efacchinin8@ebay.co.uk',\n",
       " 'imirrallsn9@ed.gov',\n",
       " 'mlangna@netlog.com',\n",
       " 'arenaknb@wikia.com',\n",
       " 'cparishnc@last.fm',\n",
       " 'jaddamsnd@amazon.com',\n",
       " 'epautene@trellian.com',\n",
       " 'smathivonnf@hibu.com',\n",
       " 'acadremanng@fda.gov#ZIRz7hs',\n",
       " 'erollesnh@redcross.org',\n",
       " 'bgillespieni@mozilla.org',\n",
       " 'glyffenj@behance.net',\n",
       " 'cbankhurstnk@theglobeandmail.com',\n",
       " 'qhirjaknl@sciencedirect.com',\n",
       " 'cdebruynnm@cafepress.com#mAu7HnBjgV',\n",
       " 'cbloornn@squidoo.com',\n",
       " 'bnorvelno@whitehouse.gov',\n",
       " 'jrichtennp@mayoclinic.com',\n",
       " 'lbuttericknq@techcrunch.com',\n",
       " 'jfearnyhoughnr@infoseek.co.jp',\n",
       " 'sbarbaryns@rambler.ru#xwtLuQf2#<img src=x onerror=alert',\n",
       " 'lcanonnt@mit.edu',\n",
       " 'aablittnu@economist.com',\n",
       " 'gshielsnv@jalbum.net',\n",
       " 'phicklingbottomnw@t-online.de',\n",
       " 'tbothennx@omniture.com',\n",
       " 'kkubyszekny@wp.com',\n",
       " 'hornilsnz@networksolutions.com',\n",
       " 'ftadmano1@creativecommons.org',\n",
       " 'dbertomeuo2@g.co',\n",
       " 'mlebarreo4@nationalgeographic.com',\n",
       " 'bguieto5@msu.edu',\n",
       " 'lwitulo7@ifeng.com',\n",
       " 'dknighto8@posterous.com',\n",
       " 'atipenso9@jigsy.com',\n",
       " 'wthumneloa@google.es',\n",
       " 'kbryersob@archive.org',\n",
       " 'atreamayneoc@archive.org#DuP5Y4wOIL35',\n",
       " 'ascroytonod@symantec.com',\n",
       " 'nfarronoe@tmall.com',\n",
       " 'pwardelof@gmpg.org',\n",
       " 'rhubbackog@epa.gov',\n",
       " 'syirrelloh@google.pl',\n",
       " 'syourelloi@tmall.com',\n",
       " 'utomblinoj@sciencedirect.com',\n",
       " 'eoulettok@vk.com',\n",
       " 'ncrowcheom@odnoklassniki.ru',\n",
       " 'pemsdenon@unc.edu',\n",
       " 'rbennettooo@telegraph.co.uk',\n",
       " 'akubczakop@fc2.com',\n",
       " 'bdoudneyoq@nps.gov',\n",
       " 'msansor@chicagotribune.com',\n",
       " 'bpaschoos@earthlink.net',\n",
       " 'scolbournot@myspace.com',\n",
       " 'eeslerou@360.cn',\n",
       " 'joaklandov@samsung.com',\n",
       " 'cbraidleyow@msn.com',\n",
       " 'sjudkinox@cnn.com',\n",
       " 'ocumineoy@theguardian.com',\n",
       " 'lscafeoz@feedburner.com',\n",
       " 'ksummersonp0@live.com',\n",
       " 'chuttleyp1@cam.ac.uk',\n",
       " 'agoodlakep2@disqus.com',\n",
       " 'imustchinp3@dot.gov',\n",
       " 'borneblowp4@fastcompany.com',\n",
       " 'mruscoep5@blogs.com',\n",
       " 'tcounihanp6@huffingtonpost.com',\n",
       " 'ltrahearnp7@live.com',\n",
       " 'greedayp8@artisteer.com',\n",
       " 'jmcarthurp9@linkedin.com',\n",
       " 'jwoakespa@simplemachines.org',\n",
       " 'amaciociapb@google.de',\n",
       " 'dstridepc@virginia.edu',\n",
       " 'ajakubovitchpd@va.gov',\n",
       " 'jsivilpe@edublogs.org',\n",
       " 'acarthewpf@github.io',\n",
       " 'wankerspg@vinaora.com',\n",
       " 'eclayhillph@cnet.com',\n",
       " 'tdopplerpi@edublogs.org',\n",
       " 'braveluspk@buzzfeed.com',\n",
       " 'uparkinsonpl@amazonaws.com',\n",
       " 'arickispm@cargocollective.com',\n",
       " 'bgiacoppopn@fc2.com',\n",
       " 'schittempo@ow.ly',\n",
       " 'gcolesonpp@craigslist.org',\n",
       " 'rfranciscopq@nbcnews.com',\n",
       " 'sbeinischpr@cbsnews.com',\n",
       " 'mstonaryps@csmonitor.com',\n",
       " 'skimmingspt@google.es',\n",
       " 'lofallownepu@sogou.com',\n",
       " 'hspillingpv@mashable.com',\n",
       " 'snazarethpw@accuweather.com',\n",
       " 'rgobatpx@stumbleupon.com',\n",
       " 'apetkovicpy@huffingtonpost.com#3SW5sRqIJK45',\n",
       " 'zopdenorthpz@google.es',\n",
       " 'aparminterq0@ning.com',\n",
       " 'gmenichiniq1@virginia.edu',\n",
       " 'adroghanq2@independent.co.uk',\n",
       " 'bdockrellq3@macromedia.com',\n",
       " 'dlintheadq4@godaddy.com',\n",
       " 'hduggenq5@clickbank.net',\n",
       " 'ipedrielliq6@cloudflare.com',\n",
       " 'rtierneyq7@who.int',\n",
       " 'lbinleyq8@prweb.com',\n",
       " 'prissenq9@squarespace.com',\n",
       " 'bamblerqa@cmu.edu',\n",
       " 'deylesqb@cbslocal.com',\n",
       " 'imclaughlinqc@myspace.com',\n",
       " 'rcaunceqd@toplist.cz',\n",
       " 'aroofeqe@fastcompany.com',\n",
       " 'emcluckyqf@nba.com',\n",
       " 'lbroadheadqg@cargocollective.com',\n",
       " 'areasceqh@wikipedia.org',\n",
       " 'apautardqi@sciencedaily.com',\n",
       " 'dwitheropqj@wp.com',\n",
       " 'geddicottqk@histats.com',\n",
       " 'amonteithql@buzzfeed.com',\n",
       " 'mhouchenqm@acquirethisname.com',\n",
       " 'gbockenqn@forbes.com',\n",
       " 'khawksbyqo@umich.edu#t8OGuc',\n",
       " 'kwoodbridgeqp@apple.com',\n",
       " 'mashmoleqq@elpais.com',\n",
       " 'mschurckeqr@live.com',\n",
       " 'kgoutcherqs@linkedin.com',\n",
       " 'mmowerqt@edublogs.org',\n",
       " 'masaafqu@fastcompany.com',\n",
       " 'gbarbourqv@skyrock.com',\n",
       " 'bcowinqw@geocities.jp#PyE9WLG0h7',\n",
       " 'jdawsqx@phpbb.com',\n",
       " 'mwincklesqy@imageshack.us',\n",
       " 'lheildqz@ask.com',\n",
       " 'rdominikr0@creativecommons.org',\n",
       " 'ecasterotr2@netlog.com',\n",
       " 'rpickinr3@ycombinator.com',\n",
       " 'gbantickr4@creativecommons.org',\n",
       " 'pnanuccioir5@miibeian.gov.cn',\n",
       " 'njohnssonr6@wsj.com',\n",
       " 'egristonr7@pagesperso-orange.fr#JJF9WpNzwa4B#\\ufeff',\n",
       " 'ggeraldezr8@weather.com',\n",
       " 'brymillr9@about.me',\n",
       " 'ftunnicliffra@arstechnica.com',\n",
       " 'bmcconnachierb@google.com.hk',\n",
       " 'hsilvertonrc@ca.gov',\n",
       " 'thartillrd@baidu.com',\n",
       " 'jpitcaithleyre@t-online.de',\n",
       " 'jhicklingbottomrf@elpais.com',\n",
       " 'ijaouenrg@un.org',\n",
       " 'ccrocerh@soup.io',\n",
       " 'churryri@macromedia.com',\n",
       " 'cfinlaysonrj@yolasite.com',\n",
       " 'telenrk@github.com',\n",
       " 'bpenhalewickrl@hao123.com',\n",
       " 'koleyrm@pcworld.com',\n",
       " 'jwestcottrn@army.mil',\n",
       " 'ebowlandro@hexun.com',\n",
       " 'pdinnagerp@delicious.com',\n",
       " 'rshearwoodrq@narod.ru',\n",
       " 'nsrawleyrr@aol.com']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_emails(string):\n",
    "    pattern  = r'\\w+@[^\\,|*(\\t)]+'\n",
    "    word = re.findall(pattern, string)\n",
    "    if '' in word:\n",
    "        word.remove('')\n",
    "    return word\n",
    "    \n",
    "# To test your work, first run:\n",
    "#extract_emails('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n",
    "# Then, once that works, uncomment:\n",
    "extract_emails(open('data/messy.txt', encoding='utf8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a32a13d4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q03_03</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q03_03 results: All test cases passed!"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q03_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e7b6e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 3.4 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Complete the implementation of the function `extract_street_addresses`, which takes in a string (`string`) containing the contents of a server log file and returns the street addresses in the file as a list. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> extract_street_addresses('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n",
    "['530 High Street']\n",
    "\n",
    ">>> out = extract_street_addresses(open('data/messy.txt', encoding='utf8').read())\n",
    ">>> out[0]\n",
    "'814 Monterey Court'\n",
    "```\n",
    "\n",
    "As before, the returned list should not contain any empty strings or the string `'null'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2aaf53fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['814 Monterey Court',\n",
       " '62 Hooker Park',\n",
       " '27811 Clyde Gallagher',\n",
       " '32553 Riverside Pass',\n",
       " '17157 Clemons Alley',\n",
       " '75 Dorton Parkway',\n",
       " '5 Manitowish Trail',\n",
       " '84 Northland Center',\n",
       " '64404 Sundown Street',\n",
       " '47144 Mockingbird Street',\n",
       " '413 Sutherland Court',\n",
       " '8906 Almo Lane',\n",
       " '34223 Graceland Crossing',\n",
       " '94 Mcguire Lane',\n",
       " '1 Delladonna Circle',\n",
       " '169 Claremont Point',\n",
       " '19475 Meadow Vale',\n",
       " '147 Cascade Center',\n",
       " '762 Knutson Terrace',\n",
       " '301 Monument Trail',\n",
       " '39 Buena Vista',\n",
       " '94 Barby Circle',\n",
       " '98 Hansons Road',\n",
       " '83525 Calypso Way',\n",
       " '61 Heath Street',\n",
       " '60 Bay Hill',\n",
       " '923 Lindbergh Place',\n",
       " '1 Elmside Circle',\n",
       " '34 High Crossing',\n",
       " '63 Bonner Lane',\n",
       " '67 Superior Terrace',\n",
       " '846 Acker Road',\n",
       " '4 Menomonie Avenue',\n",
       " '858 Arrowood Terrace',\n",
       " '2566 Anhalt Trail',\n",
       " '30840 Sherman Hill',\n",
       " '29170 Parkside Lane',\n",
       " '150 Logan Street',\n",
       " '74 North Court',\n",
       " '51374 8th Hill',\n",
       " '6432 Continental Avenue',\n",
       " '46916 Donald Court',\n",
       " '1950 Beilfuss Hill',\n",
       " '949 Park Meadow',\n",
       " '38 Tennyson Junction',\n",
       " '35 Melby Parkway',\n",
       " '55 Eggendart Circle',\n",
       " '36111 Drewry Pass',\n",
       " '3 Messerschmidt Crossing',\n",
       " '5 Hauk Terrace',\n",
       " '4335 Calypso Parkway',\n",
       " '3 Schurz Lane',\n",
       " '11 Haas Drive',\n",
       " '9639 Lindbergh Circle',\n",
       " '4 Coleman Road',\n",
       " '7751 Dahle Park',\n",
       " '699 Northport Hill',\n",
       " '754 Rockefeller Point',\n",
       " '38375 Anhalt Street',\n",
       " '4828 Carpenter Parkway',\n",
       " '5 Golden Leaf',\n",
       " '46594 Mallory Way',\n",
       " '6108 Sundown Junction',\n",
       " '92105 Melody Circle',\n",
       " '8635 Dennis Way',\n",
       " '7479 Rowland Terrace',\n",
       " '75 Buena Vista',\n",
       " '1 Michigan Junction',\n",
       " '3543 Leroy Trail',\n",
       " '47603 Doe Crossing',\n",
       " '3 Monterey Alley',\n",
       " '3 Cordelia Street',\n",
       " '4890 Center Junction',\n",
       " '12 Cardinal Road',\n",
       " '84 Haas Court',\n",
       " '46 Anthes Circle',\n",
       " '074 Erie Pass',\n",
       " '51827 Arkansas Crossing',\n",
       " '83992 Schurz Way',\n",
       " '3 Kenwood Way',\n",
       " '721 Golf Course',\n",
       " '2400 Farwell Way',\n",
       " '0 Sheridan Hill',\n",
       " '81427 Londonderry Alley',\n",
       " '8083 Melby Lane',\n",
       " '77851 Clyde Gallagher',\n",
       " '274 Colorado Drive',\n",
       " '4964 Johnson Drive',\n",
       " '453 Mesta Drive',\n",
       " '4 Cody Terrace',\n",
       " '74711 Moulton Avenue',\n",
       " '3410 Melrose Crossing',\n",
       " '6253 Cascade Trail',\n",
       " '289 South Place',\n",
       " '744 Marcy Road',\n",
       " '82060 Spenser Trail',\n",
       " '652 Roxbury Plaza',\n",
       " '57065 Dryden Trail',\n",
       " '91304 Dottie Junction',\n",
       " '10996 Schiller Alley',\n",
       " '1 Almo Plaza',\n",
       " '83 Starling Pass',\n",
       " '8423 Green Crossing',\n",
       " '3 Melody Lane',\n",
       " '7341 Linden Alley',\n",
       " '0 Columbus Hill',\n",
       " '20 Shopko Road',\n",
       " '77 Mayfield Way',\n",
       " '785 Lighthouse Bay',\n",
       " '6589 Forest Dale',\n",
       " '5 Loomis Street',\n",
       " '3 Randy Lane',\n",
       " '9 Towne Hill',\n",
       " '580 Lerdahl Street',\n",
       " '77 5th Circle',\n",
       " '3702 Ohio Center',\n",
       " '860 Marquette Alley',\n",
       " '11969 Fairview Lane',\n",
       " '770 Shopko Place',\n",
       " '997 Carpenter Plaza',\n",
       " '081 Mayer Lane',\n",
       " '5261 Maple Pass',\n",
       " '7 Swallow Road',\n",
       " '7612 Autumn Leaf',\n",
       " '8 Bellgrove Junction',\n",
       " '3 Helena Pass',\n",
       " '06 Loftsgordon Alley',\n",
       " '6402 Summer Ridge',\n",
       " '88 Vera Drive',\n",
       " '3162 Milwaukee Center',\n",
       " '0 Northland Park',\n",
       " '76307 Bashford Crossing',\n",
       " '54 Doe Crossing',\n",
       " '87 Pine View',\n",
       " '5574 Pine View',\n",
       " '17303 Ilene Circle',\n",
       " '8 Warner Court',\n",
       " '88400 New Castle',\n",
       " '6 Continental Terrace',\n",
       " '7 Thompson Road',\n",
       " '6 Harbort Terrace',\n",
       " '11090 Almo Junction',\n",
       " '21261 Norway Maple',\n",
       " '477 Carpenter Point',\n",
       " '3360 Express Avenue',\n",
       " '5908 Cardinal Hill',\n",
       " '913 Gina Trail',\n",
       " '8548 Boyd Junction',\n",
       " '5250 Sommers Point',\n",
       " '3 Green Ridge',\n",
       " '78146 Kenwood Park',\n",
       " '1376 Banding Plaza',\n",
       " '2206 Lawn Alley',\n",
       " '48279 Sullivan Avenue',\n",
       " '1 Badeau Drive',\n",
       " '55 Nelson Drive',\n",
       " '096 Chinook Lane',\n",
       " '82 Mayer Lane',\n",
       " '3857 Northland Crossing',\n",
       " '9 Dovetail Court',\n",
       " '198 Oxford Circle',\n",
       " '078 Mitchell Place',\n",
       " '11 Thompson Place',\n",
       " '8 Fair Oaks',\n",
       " '893 Doe Crossing',\n",
       " '96190 Sommers Pass',\n",
       " '768 Bultman Center',\n",
       " '288 Hintze Alley',\n",
       " '61 Anthes Park',\n",
       " '461 Ronald Regan',\n",
       " '10072 Shoshone Terrace',\n",
       " '711 Artisan Place',\n",
       " '6 Commercial Pass',\n",
       " '854 Coleman Place',\n",
       " '09411 Ramsey Way',\n",
       " '9633 Mifflin Lane',\n",
       " '75 Briar Crest',\n",
       " '24922 Gateway Pass',\n",
       " '93 Garrison Center',\n",
       " '189 Pearson Junction',\n",
       " '39898 Doe Crossing',\n",
       " '945 Forster Pass',\n",
       " '647 Rieder Parkway',\n",
       " '5 Parkside Terrace',\n",
       " '1 Trailsway Place',\n",
       " '2 Anthes Junction',\n",
       " '3891 Bonner Pass',\n",
       " '7915 Arapahoe Pass',\n",
       " '9 Rusk Way',\n",
       " '47278 Elgar Park',\n",
       " '8788 Pierstorff Way',\n",
       " '432 3rd Terrace',\n",
       " '00081 Crowley Place',\n",
       " '02 Lakewood Trail',\n",
       " '3874 Blackbird Street',\n",
       " '5328 Loomis Terrace',\n",
       " '237 Mitchell Parkway',\n",
       " '43526 Pepper Wood',\n",
       " '8 Leroy Road',\n",
       " '7 Troy Place',\n",
       " '78676 Prairieview Road',\n",
       " '6772 Ramsey Drive',\n",
       " '43 Calypso Point',\n",
       " '5504 Meadow Ridge',\n",
       " '058 Forster Plaza',\n",
       " '992 Delladonna Crossing',\n",
       " '0543 Maple Wood',\n",
       " '8608 Monument Junction',\n",
       " '1345 Goodland Court',\n",
       " '96 Garrison Drive',\n",
       " '6 Florence Circle',\n",
       " '503 Sugar Junction',\n",
       " '50869 Westerfield Pass',\n",
       " '2 Delladonna Avenue',\n",
       " '94665 Corscot Pass',\n",
       " '8485 Hanson Junction',\n",
       " '582 Thierer Park',\n",
       " '90 Fallview Center',\n",
       " '19756 Petterle Drive',\n",
       " '65 Artisan Hill',\n",
       " '4636 Welch Crossing',\n",
       " '25931 Vermont Road',\n",
       " '325 Superior Alley',\n",
       " '01 Armistice Circle',\n",
       " '41 Morning Crossing',\n",
       " '0218 Daystar Circle',\n",
       " '57823 Harper Trail',\n",
       " '732 Pearson Circle',\n",
       " '93 Fuller Place',\n",
       " '9797 Steensland Court',\n",
       " '54 Rowland Road',\n",
       " '9509 Dennis Alley',\n",
       " '84 Northridge Park',\n",
       " '378 Talmadge Terrace',\n",
       " '33140 Southridge Center',\n",
       " '31 La Follette',\n",
       " '2568 Warner Court',\n",
       " '21 Pawling Street',\n",
       " '774 Northland Junction',\n",
       " '6303 Di Loreto',\n",
       " '9 Longview Plaza',\n",
       " '461 Anderson Avenue',\n",
       " '05 Lawn Park',\n",
       " '070 Village Avenue',\n",
       " '2 Hermina Court',\n",
       " '873 Nova Circle',\n",
       " '542 International Park',\n",
       " '04 Michigan Street',\n",
       " '0892 Maywood Point',\n",
       " '7745 Susan Trail',\n",
       " '9218 Burrows Court',\n",
       " '72142 Gulseth Terrace',\n",
       " '3832 Oxford Way',\n",
       " '278 Forest Dale',\n",
       " '91091 5th Center',\n",
       " '89128 Fordem Hill',\n",
       " '3797 Fuller Place',\n",
       " '04115 Darwin Avenue',\n",
       " '3264 Village Court',\n",
       " '0445 Oneill Alley',\n",
       " '95405 Becker Place',\n",
       " '05 Columbus Lane',\n",
       " '1 Hudson Parkway',\n",
       " '5 Westport Lane',\n",
       " '27 Prentice Place',\n",
       " '12 South Pass',\n",
       " '786 Ludington Plaza',\n",
       " '06505 Lakeland Road',\n",
       " '99 Shelley Court',\n",
       " '13179 Dottie Point',\n",
       " '058 Thierer Terrace',\n",
       " '7 Roxbury Pass',\n",
       " '192 Holy Cross',\n",
       " '829 Northfield Terrace',\n",
       " '96305 Butterfield Drive',\n",
       " '4308 Kropf Trail',\n",
       " '10549 Kipling Park',\n",
       " '290 Stuart Street',\n",
       " '93016 Meadow Ridge',\n",
       " '8955 Harper Crossing',\n",
       " '480 Barby Place',\n",
       " '571 Rowland Street',\n",
       " '805 Harper Terrace',\n",
       " '3 Nevada Hill',\n",
       " '7 Nova Road',\n",
       " '7 Macpherson Circle',\n",
       " '97541 Kropf Court',\n",
       " '13 Commercial Parkway',\n",
       " '4494 Golf Course',\n",
       " '93860 Eagan Avenue',\n",
       " '2 Eastlawn Lane',\n",
       " '1931 Fallview Way',\n",
       " '3 Waywood Way',\n",
       " '58196 Green Alley',\n",
       " '7958 Elka Circle',\n",
       " '02487 Carberry Trail',\n",
       " '95025 Moose Drive',\n",
       " '4599 Meadow Ridge',\n",
       " '6592 8th Point',\n",
       " '47 Northwestern Hill',\n",
       " '4648 Vahlen Trail',\n",
       " '5 Transport Road',\n",
       " '16544 Fremont Alley',\n",
       " '98 Briar Crest',\n",
       " '8 Melody Way',\n",
       " '8752 Oxford Street',\n",
       " '84 Ridge Oak',\n",
       " '63 Spenser Center',\n",
       " '9 Tennyson Road',\n",
       " '3 Sauthoff Road',\n",
       " '21 Maple Wood',\n",
       " '7526 Aberg Park',\n",
       " '367 Prentice Park',\n",
       " '0 Badeau Drive',\n",
       " '948 Northview Hill',\n",
       " '752 Vermont Place',\n",
       " '99628 Glacier Hill',\n",
       " '33 Londonderry Lane',\n",
       " '6767 Boyd Alley',\n",
       " '860 Northfield Lane',\n",
       " '0552 Ludington Lane',\n",
       " '96 Lawn Plaza',\n",
       " '3 Corben Center',\n",
       " '1 Algoma Avenue',\n",
       " '8924 Porter Parkway',\n",
       " '67 Springs Plaza',\n",
       " '892 Sugar Avenue',\n",
       " '590 Park Meadow',\n",
       " '7440 Grayhawk Park',\n",
       " '67 Loftsgordon Street',\n",
       " '9863 Shopko Point',\n",
       " '1 Upham Junction',\n",
       " '3566 Nobel Avenue',\n",
       " '9 Mosinee Center',\n",
       " '45 Muir Trail',\n",
       " '347 Roth Junction',\n",
       " '9 Sauthoff Circle',\n",
       " '49708 Myrtle Center',\n",
       " '40 Hintze Place',\n",
       " '29756 Cottonwood Lane',\n",
       " '53 Derek Point',\n",
       " '51 Crowley Hill',\n",
       " '7 Cardinal Place',\n",
       " '91 Chive Circle',\n",
       " '225 Fieldstone Park',\n",
       " '6 Helena Junction',\n",
       " '69690 Kennedy Circle',\n",
       " '2 Lukken Center',\n",
       " '335 Mallard Way',\n",
       " '499 Prairie Rose',\n",
       " '350 Nevada Circle',\n",
       " '9392 Fremont Place',\n",
       " '858 Tennyson Way',\n",
       " '082 Katie Circle',\n",
       " '852 Evergreen Street',\n",
       " '422 Jackson Street',\n",
       " '93 Dunning Center',\n",
       " '13563 Kinsman Plaza',\n",
       " '12 Blackbird Alley',\n",
       " '89 Lakeland Place',\n",
       " '588 Bellgrove Road',\n",
       " '6 Fuller Park',\n",
       " '92611 Scoville Terrace',\n",
       " '8 Dunning Court',\n",
       " '296 Eliot Center',\n",
       " '1 Loftsgordon Drive',\n",
       " '790 Express Drive',\n",
       " '81730 Sauthoff Road',\n",
       " '5 Lunder Avenue',\n",
       " '9 Warrior Hill',\n",
       " '06 Fairfield Parkway',\n",
       " '644 Parkside Lane',\n",
       " '25214 Meadow Vale',\n",
       " '98 Cambridge Terrace',\n",
       " '81644 Blaine Point',\n",
       " '1442 Moulton Circle',\n",
       " '5 Crest Line',\n",
       " '369 Warner Center',\n",
       " '4753 Farwell Trail',\n",
       " '594 Southridge Center',\n",
       " '6509 Lakewood Gardens',\n",
       " '235 Lien Court',\n",
       " '581 Clove Hill',\n",
       " '3 Canary Pass',\n",
       " '93685 Kedzie Terrace',\n",
       " '0057 Coolidge Place',\n",
       " '2923 Spohn Terrace',\n",
       " '33 Melody Center',\n",
       " '805 Amoth Junction',\n",
       " '9 Sloan Point',\n",
       " '82094 Del Mar',\n",
       " '4925 Redwing Trail',\n",
       " '743 Nancy Way',\n",
       " '918 Lunder Court',\n",
       " '2 Duke Avenue',\n",
       " '0 Holy Cross',\n",
       " '23795 Hermina Crossing',\n",
       " '56 Boyd Parkway',\n",
       " '96 Atwood Junction',\n",
       " '94 Village Green',\n",
       " '3 Mallard Circle',\n",
       " '322 Texas Drive',\n",
       " '0831 Burrows Drive',\n",
       " '63686 Northfield Alley',\n",
       " '03 North Place',\n",
       " '923 Merry Terrace',\n",
       " '6073 Harbort Junction',\n",
       " '100 Londonderry Avenue',\n",
       " '5369 Fairview Alley',\n",
       " '942 Oxford Court',\n",
       " '7 Mariners Cove',\n",
       " '06935 Alpine Drive',\n",
       " '68282 High Crossing',\n",
       " '91661 Hanover Lane',\n",
       " '8 Ridgeway Road',\n",
       " '397 Sage Junction',\n",
       " '66 Green Avenue',\n",
       " '8969 Norway Maple',\n",
       " '558 Dwight Trail',\n",
       " '274 Cardinal Terrace',\n",
       " '12197 Anhalt Street',\n",
       " '3161 Cardinal Circle',\n",
       " '58139 Butternut Road',\n",
       " '8265 Jackson Avenue',\n",
       " '322 Memorial Circle',\n",
       " '1 Fieldstone Center',\n",
       " '16485 Troy Plaza',\n",
       " '60 Sunfield Terrace',\n",
       " '02175 Old Gate',\n",
       " '0871 Barnett Way',\n",
       " '0243 Arrowood Junction',\n",
       " '3 Summerview Street',\n",
       " '8758 Dorton Trail',\n",
       " '6 Lakewood Gardens',\n",
       " '7381 Summit Center',\n",
       " '13146 Crowley Court',\n",
       " '98842 Continental Terrace',\n",
       " '67 Lyons Terrace',\n",
       " '5300 Victoria Terrace',\n",
       " '25 Anzinger Way',\n",
       " '938 Eliot Center',\n",
       " '956 Pond Junction',\n",
       " '21736 Doe Crossing',\n",
       " '05 Carberry Center',\n",
       " '9866 Memorial Plaza',\n",
       " '5219 Vidon Crossing',\n",
       " '53 Lyons Parkway',\n",
       " '2 Everett Drive',\n",
       " '50391 Nancy Junction',\n",
       " '57147 Armistice Plaza',\n",
       " '5734 Kipling Terrace',\n",
       " '3199 Golden Leaf',\n",
       " '686 Red Cloud',\n",
       " '889 Mitchell Park',\n",
       " '92 Monica Lane',\n",
       " '1200 Shoshone Center',\n",
       " '50551 Muir Park',\n",
       " '1 Crownhardt Lane',\n",
       " '01256 Sachs Junction',\n",
       " '2620 Scofield Hill',\n",
       " '3809 Briar Crest',\n",
       " '950 Mosinee Way',\n",
       " '959 Dawn Junction',\n",
       " '858 Mesta Alley',\n",
       " '6 Wayridge Junction',\n",
       " '5 Coolidge Alley',\n",
       " '330 Anhalt Trail',\n",
       " '1782 Donald Street',\n",
       " '668 2nd Circle',\n",
       " '21631 Fisk Terrace',\n",
       " '5 Melody Hill',\n",
       " '9 Brickson Park',\n",
       " '8 Aberg Terrace',\n",
       " '83676 Nobel Junction',\n",
       " '1766 Crownhardt Junction',\n",
       " '8 Gina Crossing',\n",
       " '14 Anderson Crossing',\n",
       " '16 Blue Bill',\n",
       " '67453 Kipling Center',\n",
       " '9 8th Hill',\n",
       " '5 Melrose Terrace',\n",
       " '9462 Pleasure Plaza',\n",
       " '50277 Browning Park',\n",
       " '889 David Alley',\n",
       " '46 Lunder Crossing',\n",
       " '8582 Judy Crossing',\n",
       " '528 Westend Drive',\n",
       " '4 Spohn Court',\n",
       " '67143 Briar Crest',\n",
       " '6972 Buell Center',\n",
       " '1243 Sunbrook Street',\n",
       " '6 Memorial Lane',\n",
       " '0 Butternut Alley',\n",
       " '626 Vidon Crossing',\n",
       " '8711 Dexter Drive',\n",
       " '218 Maple Wood',\n",
       " '1 Fieldstone Center',\n",
       " '31792 Spaight Crossing',\n",
       " '270 Pepper Wood',\n",
       " '77 Arapahoe Hill',\n",
       " '5560 West Park',\n",
       " '142 Lakewood Gardens',\n",
       " '86318 Memorial Trail',\n",
       " '5042 Mallory Crossing',\n",
       " '8892 Thompson Lane',\n",
       " '6 Manufacturers Pass',\n",
       " '1 Killdeer Park',\n",
       " '87254 Fulton Road',\n",
       " '1834 Eastwood Lane',\n",
       " '82436 1st Way',\n",
       " '7 Ridge Oak',\n",
       " '6 Rutledge Plaza',\n",
       " '7663 8th Road',\n",
       " '897 Moulton Lane',\n",
       " '399 Village Green',\n",
       " '24404 6th Drive',\n",
       " '126 Glacier Hill',\n",
       " '057 Mockingbird Road',\n",
       " '24 Coolidge Pass',\n",
       " '8647 Surrey Way',\n",
       " '8 Daystar Way',\n",
       " '30 Sunbrook Parkway',\n",
       " '099 Roxbury Park',\n",
       " '28 Center Circle',\n",
       " '457 Dawn Hill',\n",
       " '52009 Doe Crossing',\n",
       " '66 Ridgeview Junction',\n",
       " '94 Barnett Plaza',\n",
       " '26911 Service Road',\n",
       " '0 Di Loreto',\n",
       " '242 Elmside Terrace',\n",
       " '71219 Portage Terrace',\n",
       " '276 1st Point',\n",
       " '28 Golden Leaf',\n",
       " '91614 Washington Center',\n",
       " '34 Becker Road',\n",
       " '5981 Farragut Way',\n",
       " '8 Pleasure Street',\n",
       " '9600 Elmside Place',\n",
       " '7132 Oak Valley',\n",
       " '68 Acker Place',\n",
       " '570 Ohio Pass',\n",
       " '1 Brown Avenue',\n",
       " '344 Heffernan Way',\n",
       " '9 Maple Junction',\n",
       " '46 Gina Way',\n",
       " '70 Golden Leaf',\n",
       " '26 Mosinee Circle',\n",
       " '02618 Blaine Park',\n",
       " '9 Londonderry Pass',\n",
       " '2 Havey Way',\n",
       " '74 Hudson Terrace',\n",
       " '92 Marquette Avenue',\n",
       " '6 Golden Leaf',\n",
       " '20979 Transport Drive',\n",
       " '6 Bartillon Junction',\n",
       " '3 Dakota Road',\n",
       " '58658 David Circle',\n",
       " '8 Thackeray Lane',\n",
       " '6063 Mccormick Way',\n",
       " '25 Sugar Point',\n",
       " '4 Meadow Valley',\n",
       " '13937 Westend Alley',\n",
       " '30373 Parkside Center',\n",
       " '75364 Fordem Way',\n",
       " '0 Pepper Wood',\n",
       " '34217 Mosinee Crossing',\n",
       " '54 Butternut Hill',\n",
       " '9301 3rd Drive',\n",
       " '325 Nancy Pass',\n",
       " '0 Moose Way',\n",
       " '311 Stuart Plaza',\n",
       " '80182 Fairfield Park',\n",
       " '247 Montana Parkway',\n",
       " '23298 Sauthoff Plaza',\n",
       " '2412 Maryland Road',\n",
       " '22859 Crescent Oaks',\n",
       " '287 Eagan Terrace',\n",
       " '0 Nelson Crossing',\n",
       " '006 Burrows Pass',\n",
       " '7 Cordelia Junction',\n",
       " '60 Clove Center',\n",
       " '238 Vera Court',\n",
       " '0915 Almo Crossing',\n",
       " '82 Shopko Parkway',\n",
       " '58 Manley Junction',\n",
       " '841 Katie Place',\n",
       " '4305 Mandrake Pass',\n",
       " '6120 Columbus Circle',\n",
       " '79320 Nevada Place',\n",
       " '4 Briar Crest',\n",
       " '70270 Lunder Alley',\n",
       " '4 Green Avenue',\n",
       " '85229 Pawling Point',\n",
       " '762 Fisk Parkway',\n",
       " '8 Browning Terrace',\n",
       " '821 Buhler Place',\n",
       " '52964 Kedzie Avenue',\n",
       " '97 Basil Trail',\n",
       " '35 Raven Avenue',\n",
       " '8179 Arkansas Court',\n",
       " '21365 Crest Line',\n",
       " '19 Hovde Court',\n",
       " '7796 Derek Place',\n",
       " '6107 Spohn Crossing',\n",
       " '5 Carpenter Alley',\n",
       " '2 Northport Pass',\n",
       " '7 Esker Point',\n",
       " '36 Northview Point',\n",
       " '01669 Harbort Crossing',\n",
       " '7 Starling Avenue',\n",
       " '2 Maywood Parkway',\n",
       " '76877 Donald Way',\n",
       " '3 Rusk Trail',\n",
       " '5 Stang Road',\n",
       " '763 Anzinger Center',\n",
       " '27 Ruskin Hill',\n",
       " '7818 Hintze Road',\n",
       " '6953 Mesta Street',\n",
       " '44 Park Meadow',\n",
       " '7200 3rd Hill',\n",
       " '0003 Riverside Court',\n",
       " '914 8th Alley',\n",
       " '7 Duke Lane',\n",
       " '71142 Mccormick Place',\n",
       " '016 Bluejay Pass',\n",
       " '2 Morningstar Crossing',\n",
       " '9 Briar Crest',\n",
       " '96135 Dahle Plaza',\n",
       " '1725 Mallory Plaza',\n",
       " '93732 Waubesa Street',\n",
       " '629 Meadow Ridge',\n",
       " '23101 Anthes Point',\n",
       " '8342 Jenifer Alley',\n",
       " '0049 Clemons Circle',\n",
       " '499 Scofield Court',\n",
       " '32 Bultman Point',\n",
       " '843 Buhler Circle',\n",
       " '9842 Dapin Drive',\n",
       " '160 Declaration Center',\n",
       " '7 Southridge Trail',\n",
       " '5223 Sunfield Avenue',\n",
       " '01 Mosinee Trail',\n",
       " '51747 Schlimgen Hill',\n",
       " '7540 Fallview Lane',\n",
       " '78013 Holmberg Plaza',\n",
       " '126 Menomonie Center',\n",
       " '8700 Portage Circle',\n",
       " '6 Homewood Crossing',\n",
       " '251 Sunnyside Parkway',\n",
       " '9 Northridge Crossing',\n",
       " '11 Moland Road',\n",
       " '45 Darwin Hill',\n",
       " '9 Magdeline Avenue',\n",
       " '41 Novick Pass',\n",
       " '32138 Myrtle Plaza',\n",
       " '76 Golf Way',\n",
       " '1172 Pierstorff Court',\n",
       " '60321 Londonderry Parkway',\n",
       " '6 Maryland Park',\n",
       " '5 Spenser Plaza',\n",
       " '5908 Chinook Place',\n",
       " '65551 Westend Avenue',\n",
       " '364 Beilfuss Crossing',\n",
       " '3992 Memorial Way',\n",
       " '7 Briar Crest',\n",
       " '934 Farragut Road',\n",
       " '71374 Manufacturers Point',\n",
       " '568 Sauthoff Trail',\n",
       " '81063 Dorton Junction',\n",
       " '43313 Sutherland Court',\n",
       " '4318 Susan Place',\n",
       " '7678 Marcy Crossing',\n",
       " '3 Larry Avenue',\n",
       " '07 Riverside Crossing',\n",
       " '29 Talmadge Terrace',\n",
       " '40 Rusk Park',\n",
       " '1 Village Terrace',\n",
       " '57856 Mariners Cove',\n",
       " '548 Pearson Pass',\n",
       " '4 Sherman Court',\n",
       " '547 Crownhardt Crossing',\n",
       " '87222 Basil Alley',\n",
       " '43 Ruskin Court',\n",
       " '04 Paget Parkway',\n",
       " '11 Utah Trail',\n",
       " '203 Columbus Alley',\n",
       " '38946 Del Sol',\n",
       " '0 Valley Edge',\n",
       " '6 Thompson Way',\n",
       " '628 Colorado Point',\n",
       " '2737 Eastwood Avenue',\n",
       " '9 Morning Park',\n",
       " '98 Glendale Trail',\n",
       " '47 Clarendon Court',\n",
       " '94 Westridge Terrace',\n",
       " '51425 Del Mar',\n",
       " '242 Hayes Pass',\n",
       " '6973 Saint Paul',\n",
       " '0022 Spohn Junction',\n",
       " '7 Farwell Pass',\n",
       " '7948 Canary Junction',\n",
       " '1 Clove Alley',\n",
       " '78274 Ohio Lane',\n",
       " '067 Stone Corner',\n",
       " '23 Steensland Way',\n",
       " '9 Gulseth Circle',\n",
       " '40918 Sheridan Center',\n",
       " '45 Waywood Point',\n",
       " '2 Onsgard Parkway',\n",
       " '2334 Annamark Center',\n",
       " '5669 Myrtle Alley',\n",
       " '52768 Union Plaza',\n",
       " '32378 Shopko Lane',\n",
       " '8 Bunting Point',\n",
       " '9508 Hazelcrest Point',\n",
       " '91326 Roth Pass',\n",
       " '33 Linden Court',\n",
       " '37 American Ash',\n",
       " '5 Mayer Pass',\n",
       " '2 Springs Road',\n",
       " '4318 Service Circle',\n",
       " '31905 Weeping Birch',\n",
       " '640 Sage Way',\n",
       " '5 Green Way',\n",
       " '181 Warner Place',\n",
       " '1 Loomis Park',\n",
       " '2073 Summerview Way',\n",
       " '7019 Vermont Park',\n",
       " '281 Raven Way',\n",
       " '52014 Crownhardt Lane',\n",
       " '50 Sachs Terrace',\n",
       " '33 Carey Crossing',\n",
       " '27 Loeprich Point',\n",
       " '60387 Ryan Pass',\n",
       " '05486 Bluejay Drive',\n",
       " '4 Messerschmidt Point',\n",
       " '2 Carpenter Crossing',\n",
       " '884 Monument Road',\n",
       " '6 Warbler Place',\n",
       " '6 Utah Hill',\n",
       " '776 Ridgeview Avenue',\n",
       " '22 Burrows Terrace',\n",
       " '38363 Jenna Street',\n",
       " '73925 Menomonie Plaza',\n",
       " '0 South Alley',\n",
       " '872 Burrows Crossing',\n",
       " '22375 Clove Plaza',\n",
       " '8 Hauk Crossing',\n",
       " '1 Morningstar Crossing',\n",
       " '6156 Laurel Way',\n",
       " '413 Merchant Pass',\n",
       " '83 North Way',\n",
       " '0 Chinook Way',\n",
       " '940 Fisk Drive',\n",
       " '487 Bartelt Park',\n",
       " '48314 Homewood Alley',\n",
       " '5012 Comanche Road',\n",
       " '73046 Oriole Lane',\n",
       " '5 Pleasure Terrace',\n",
       " '53642 Del Mar',\n",
       " '7499 Fairfield Junction',\n",
       " '72 Northland Drive',\n",
       " '962 Spohn Terrace',\n",
       " '0620 Esker Road',\n",
       " '12055 Village Alley',\n",
       " '40875 West Avenue',\n",
       " '2 4th Alley',\n",
       " '4 Delladonna Center',\n",
       " '93173 West Point',\n",
       " '8783 Parkside Junction',\n",
       " '7706 Memorial Court',\n",
       " '86590 Manufacturers Road',\n",
       " '818 Delaware Avenue',\n",
       " '66 Schurz Circle',\n",
       " '210 Manufacturers Junction',\n",
       " '2 Leroy Court',\n",
       " '97528 Thompson Terrace',\n",
       " '432 Barnett Street',\n",
       " '4 Sundown Crossing',\n",
       " '1 Algoma Crossing',\n",
       " '564 Toban Pass',\n",
       " '950 Fulton Hill',\n",
       " '0271 Menomonie Avenue',\n",
       " '195 Luster Avenue',\n",
       " '85 Moland Point',\n",
       " '88987 Paget Parkway',\n",
       " '4340 Elgar Park',\n",
       " '832 Kings Place',\n",
       " '7 Jay Point',\n",
       " '96 Northridge Trail',\n",
       " '82 Buena Vista',\n",
       " '6 Brickson Park',\n",
       " '41392 Nancy Avenue',\n",
       " '0267 Harbort Crossing',\n",
       " '69 Dennis Circle',\n",
       " '261 Westport Junction',\n",
       " '1155 Vermont Center',\n",
       " '732 Butterfield Plaza',\n",
       " '161 Fuller Street',\n",
       " '03 Blue Bill',\n",
       " '12 Lillian Center',\n",
       " '14361 Packers Terrace',\n",
       " '9 Burrows Drive',\n",
       " '24256 Stang Circle',\n",
       " '7 Erie Junction',\n",
       " '532 Bay Plaza',\n",
       " '3128 Pepper Wood',\n",
       " '3328 Novick Plaza',\n",
       " '6837 Knutson Hill',\n",
       " '675 Manley Street',\n",
       " '86389 Monica Center',\n",
       " '74694 Farragut Circle',\n",
       " '90 Anhalt Road',\n",
       " '89701 Kennedy Court',\n",
       " '34770 Mendota Lane',\n",
       " '5316 Old Gate',\n",
       " '49608 Dryden Court',\n",
       " '95116 Westerfield Alley',\n",
       " '0 Lawn Road',\n",
       " '131 Southridge Circle',\n",
       " '7 Kropf Plaza',\n",
       " '77 Amoth Crossing',\n",
       " '458 Cascade Street',\n",
       " '2 Miller Crossing',\n",
       " '88 Vidon Road',\n",
       " '808 Ramsey Terrace',\n",
       " '96 Kedzie Street',\n",
       " '06 Algoma Terrace',\n",
       " '260 Fair Oaks',\n",
       " '93 Dayton Place',\n",
       " '55296 Gateway Avenue',\n",
       " '1 Larry Plaza',\n",
       " '6 Chinook Way',\n",
       " '019 Burrows Way',\n",
       " '4 Larry Street',\n",
       " '04653 Porter Alley',\n",
       " '6 Esch Lane',\n",
       " '1 Portage Place',\n",
       " '4 Crescent Oaks',\n",
       " '20616 Canary Pass',\n",
       " '71349 Carpenter Street',\n",
       " '139 Fremont Street',\n",
       " '0303 Buhler Drive',\n",
       " '7 Swallow Circle',\n",
       " '141 David Parkway',\n",
       " '74 Fremont Pass',\n",
       " '3620 Bartillon Parkway',\n",
       " '7932 Melvin Center',\n",
       " '49 Grasskamp Terrace',\n",
       " '2768 Waubesa Court',\n",
       " '50991 Doe Crossing',\n",
       " '383 Autumn Leaf',\n",
       " '42860 Clove Parkway',\n",
       " '587 Gateway Avenue',\n",
       " '43603 Nobel Place',\n",
       " '35383 Surrey Center',\n",
       " '58410 Mesta Lane',\n",
       " '214 Hollow Ridge',\n",
       " '276 Hagan Hill',\n",
       " '374 Superior Pass',\n",
       " '0945 Mitchell Center',\n",
       " '35379 Forster Lane',\n",
       " '0425 Melrose Avenue',\n",
       " '6297 Barby Avenue',\n",
       " '2216 Harbort Point',\n",
       " '87988 Wayridge Circle',\n",
       " '0 Mccormick Center',\n",
       " '471 Almo Lane',\n",
       " '028 Drewry Street',\n",
       " '06190 Scott Plaza',\n",
       " '67767 Merry Center',\n",
       " '86 Bunting Pass',\n",
       " '312 Portage Point',\n",
       " '2901 Haas Drive',\n",
       " '52282 Orin Way',\n",
       " '958 Butternut Point',\n",
       " '778 South Center',\n",
       " '6 Hoepker Crossing',\n",
       " '152 Prairieview Center',\n",
       " '1839 Morningstar Court',\n",
       " '7 Cambridge Crossing',\n",
       " '947 Mallard Place',\n",
       " '104 Hoffman Park',\n",
       " '4244 Heffernan Circle',\n",
       " '72 Harbort Road',\n",
       " '3675 Swallow Park',\n",
       " '89384 Graceland Street',\n",
       " '01 La Follette',\n",
       " '240 Del Sol',\n",
       " '13 Stephen Park',\n",
       " '854 Pine View',\n",
       " '58 Hooker Park',\n",
       " '7 East Terrace',\n",
       " '86 Bobwhite Street',\n",
       " '0 Artisan Place',\n",
       " '825 Mayfield Circle',\n",
       " '424 Mallory Way',\n",
       " '8524 Huxley Trail',\n",
       " '33 Algoma Junction',\n",
       " '48 Summer Ridge',\n",
       " '976 Arkansas Junction',\n",
       " '66697 Kings Road',\n",
       " '0230 Weeping Birch',\n",
       " '15 Hoard Road',\n",
       " '95608 Crest Line',\n",
       " '05 Artisan Court',\n",
       " '83 Hovde Drive',\n",
       " '46130 Becker Street',\n",
       " '0 Veith Drive',\n",
       " '8389 Brown Plaza',\n",
       " '91007 Mosinee Park',\n",
       " '81 Sommers Street',\n",
       " '47 Luster Circle',\n",
       " '9 Ruskin Avenue',\n",
       " '04 Westport Lane',\n",
       " '4 Rowland Point',\n",
       " '96 Judy Terrace',\n",
       " '94 Stuart Center',\n",
       " '7769 Portage Lane',\n",
       " '1088 Redwing Place',\n",
       " '107 Sycamore Lane',\n",
       " '45254 Hoepker Center',\n",
       " '50255 Sommers Point',\n",
       " '30658 5th Point',\n",
       " '6304 Browning Point',\n",
       " '90 Hansons Circle',\n",
       " '95 Coleman Circle',\n",
       " '89302 Del Mar',\n",
       " '4 Anthes Terrace',\n",
       " '15643 Charing Cross',\n",
       " '5262 Duke Plaza',\n",
       " '94739 Pennsylvania Drive',\n",
       " '23 Coolidge Crossing',\n",
       " '320 Mayer Terrace',\n",
       " '541 Anthes Way',\n",
       " '6851 Messerschmidt Plaza',\n",
       " '43490 Grover Way',\n",
       " '21 Granby Lane',\n",
       " '16 Pierstorff Way',\n",
       " '10 Homewood Road',\n",
       " '99 Pearson Pass',\n",
       " '886 Thackeray Road',\n",
       " '459 Bowman Crossing',\n",
       " '09943 Daystar Crossing',\n",
       " '9555 Bultman Park',\n",
       " '429 Holy Cross',\n",
       " '4 Charing Cross',\n",
       " '38154 Hoepker Terrace',\n",
       " '30454 Clove Drive',\n",
       " '273 Waywood Hill',\n",
       " '50952 Evergreen Street',\n",
       " '0 Cordelia Pass',\n",
       " '6607 Sachs Way',\n",
       " '58 Shasta Terrace',\n",
       " '58 Redwing Center',\n",
       " '3979 Old Gate',\n",
       " '04232 Monterey Circle']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_street_addresses(string):\n",
    "    pattern = r'\\d+ \\w+ \\w+'\n",
    "    word = re.findall(pattern, string)\n",
    "    return word\n",
    "\n",
    "# To test your work, first run:\n",
    "#extract_street_addresses('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n",
    "# Then, once that works, uncomment:\n",
    "extract_street_addresses(open('data/messy.txt', encoding='utf8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e762bea",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q03_04</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q03_04 results: All test cases passed!"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q03_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294bc0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 4: GPTEECS ü§ñ\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "Large Language Models (LLM), like GPT-4 by OpenAI, Claude by Anthropic, or Llama by Meta, are statistical models that were trained on massive datasets for the purpose of generating useful new text. [ChatGPT](https://chat.openai.com) and other similar chat interfaces make calls to an LLM API under-the-hood, and show you the results in a text message-like format.\n",
    "\n",
    "Open ChatGPT or your favorite other LLM chat interface, and ask it:\n",
    "\n",
    "> What's the difference between the late submission policy in EECS 467 and EECS 492?\n",
    "\n",
    "Until very recently (when ChatGPT started being able to search the internet), ChatGPT would tell you that it doesn't know what EECS 467 and EECS 492 are. And even if it did give you an answer, it's not necessarily clear whether it pulled the answer from a reliable source, or whether it's still true today (it may have found syllabi online from many years ago, and could be hallucinating). \n",
    "\n",
    "### Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "A solution to this issue is **Retrieval-Augmented Generation (RAG)**. **In this question, we will use RAG to implement GPTEECS, a chat interface designed to answer questions about EECS syllabi.** Here's the general idea behind RAG, and how we'll use it in this question:\n",
    "\n",
    "1. We want to implement a chat bot that can answer questions about something specific.<br><small>**Here**, we want our chat bot to answer questions about EECS class' syllabi.</small>\n",
    "1. To do so, we download and store documents that contain the relevant context that we wish our LLM knew about.<br><small>**Here**, we'll download the syllabi of various EECS classes and store them as `.txt` files. We've already done this for you.</small>\n",
    "1. Then, when the user asks a question ‚Äì called a **query** ‚Äì we determine which of our locally-stored documents are most relevant in answering their question.<br><small>**Here**, when a user asks a question about EECS class(es), we'll determine which syllabus documents are most likely to have the answer.</small>\n",
    "1. Once we find the most relevant documents, we send the user's query, **along with** the most relevant documents, to our language model, allowing it to find the answer for us with the context it needs.\n",
    "\n",
    "<center><img src=\"imgs/retrieval-augmented-generation.png\" width=700><br>(<a href=\"https://towhee.io/tasks/detail/pipeline/retrieval-augmented-generation\">image source</a>)</center>\n",
    "\n",
    "RAG enables organizations to create customized chat interfaces that are better equipped to answer questions about the organization than an out-of-the-box language model. For instance, if you operated a store and wanted an AI-powered customer support chat, you may use RAG to create a chat bot that knows about your store's catalog, return policies, etc. ChatGPT even allows you to make custom GPTs [yourself](https://openai.com/index/introducing-gpts/) by uploading customized knowledge bases, and these (likely) use a process similar to RAG.\n",
    "\n",
    "### FAQs\n",
    "\n",
    "- **How do we determine which documents are most relevant to the user's query?** Here, we'll implement this using TF-IDF and cosine similarity, as we've seen in [Lecture 12](https://practicaldsc.org/resources/lectures/lec12/lec12-filled.html)! In practice, more sophisticated, state-of-the-art techniques for converting text to numbers are used (if you're curious, look into \"word embeddings\").\n",
    "- **Why not just send all of the documents to our language model, instead of finding the documents that are most relevant?** LLMs have a [context window](https://www.hopsworks.ai/dictionary/context-window-for-llms), which is a limit on the length of the input query they can take in. If your query is too long, an LLM may not be able to process it. (And, if it includes unnecessary information, it can be hard for the LLM to give you an accurate response.)\n",
    "\n",
    "### Your Task\n",
    "The folder `data/syllabi` contains syllabi for several EECS classes. These documents together comprise our **corpus**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6a64715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183.txt 280.txt 373.txt 390.txt 465.txt 471.txt 481.txt 484.txt 489.txt 493.txt\n",
      "203.txt 281.txt 376.txt 445.txt 467.txt 473.txt 482.txt 485.txt 490.txt 494.txt\n",
      "270.txt 370.txt 388.txt 453.txt 470.txt 475.txt 483.txt 487.txt 492.txt\n"
     ]
    }
   ],
   "source": [
    "!ls data/syllabi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5ef03",
   "metadata": {},
   "source": [
    "Shortly, using the ideas from Lecture 12, you will develop a working implementation of the following function:\n",
    "\n",
    "```python\n",
    ">>> top_n_similar_documents('C++ programming and systems design', 4, bow)\n",
    "['482.txt', '473.txt', '370.txt', '281.txt']\n",
    "```\n",
    "\n",
    "And even cooler, you'll implement a function that can fully answer questions, like:\n",
    "\n",
    "```python\n",
    ">>> ask_gpteecs(\"I really want to learn theoretical probability and math, what should I take?\")\n",
    "'Based on your interest in theoretical probability and math, I recommend taking EECS 445: Introduction to Machine Learning. This course covers the foundational algorithms and \"tricks of the trade\" in machine learning, including regression, classification...'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04368aef",
   "metadata": {},
   "source": [
    "### Question 4.1 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "First, let's figure out how to call a Large Language Model directly from our notebook.\n",
    "\n",
    "OpenAI does have a Python API, but it's relatively limited on the free plan. Instead, we'll use tools from [Groq](https://groq.com/). Groq is a hardware company designing processors for training LLMs efficiently, and allows for fast, free access to open-source LLM APIs. We'll use the [Groq API](https://console.groq.com/docs/quickstart) to make calls to Meta's Llama 3 API. (As mentioned at the start of this section, Llama is Meta's competitor to GPT. So technically, we're not implementing GPTEECS, but EECSLlama?)\n",
    "\n",
    "Go [**here**](https://console.groq.com/docs/quickstart) and create a Groq API key. Then, complete the implementation of `query_llama`, a function that takes in a string (`query_string`) and returns the text response that results from passing `query_string` to Groq. The function has largely been implemented for you; most of what you need to do is create an API key and put it in the right place below.\n",
    "\n",
    "(Yes, confusingly, we're using the word \"query\" in this homework to refer to slightly different, but related, ideas: in SQL, queries are used to extract information from a **database**, and here, our queries pull information from an API.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f397e",
   "metadata": {},
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e89fce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "EECS 492 and EECS 493 are both sections of the same upper-level undergraduate electrical engineering course, but there are a few important differences between them:\n",
       "\n",
       "1. EECS 492 is typically a more advanced version of the course, designed for students who have already completed the prerequisite coursework and are looking to delve deeper into the subject matter. This section often covers more difficult and specialized topics, and may require more independent study and research.\n",
       "2. EECS 493, on the other when compared with 492, is a more beginner-friendly course. It covers the basics of electrical engineering, including circuit analysis and digital logic. It is often taken by students who are new to the field and want a solid foundation in the basics of electrical engineering.\n",
       "3. EECS 492 and EECS 493 are often taken together in the same semester as the two courses are complementary to one another and build upon each other. The 493 course usually lays the foundation for 492.\n",
       "4. EECS 492 is more research-oriented, where as EECS 493 is more project-oriented.\n",
       "\n",
       "In summary, EECS 492 is a more advanced version of the course and is often taken by students who have already completed the prerequisite coursework and are looking to delve deeper into the subject matter, while EECS 493 is a beginner-friendly course that covers the basics of electrical engineering."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_llama(query_string):\n",
    "    client = groq.Groq(\n",
    "        api_key= \"\"\n",
    "    )\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_string\n",
    "            }\n",
    "        ],\n",
    "        model=\"llava-v1.5-7b-4096-preview\",\n",
    "        # temperature=0 # Try uncommenting this and running the call to query_llama below many times. What do you notice? Recomment it out afterwards.\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "# Feel free to change the input below to test out your implementation of query_llama.\n",
    "# The Markdown function behaves like the print function,\n",
    "# but renders text formatting (e.g. bolding, bullet points) when the output from Llama\n",
    "# contains these elements.\n",
    "Markdown(query_llama('what is the difference between EECS 492 and EECS 493?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afa6842a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q04_01</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q04_01 results: All test cases passed!"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q04_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b577e425",
   "metadata": {},
   "source": [
    "Now, we can call `query_llama`! Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d262d88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "EECS 485 at the University of Michigan is a senior-level design project course that requires students to design and implement a complete embedded control system. The course is project-based and provides students with the opportunity to apply their knowledge of computer engineering principles to real-world problems. Students work in teams to design and develop a system, and are required to present their work to the class. The course also includes lectures and discussions on topics such as programming languages, compilers, and computer architecture."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(query_llama('Tell me about EECS 485 at Michigan, but keep it concise: just one paragraph.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe509f9",
   "metadata": {},
   "source": [
    "To experiment:\n",
    "- Run the cell many times. You'll notice that the response is very different every time ‚Äì and it's almost never accurate! (Click [here](https://eecs485.org) to see what EECS 485 here is actually about.)\n",
    "- Uncomment the line that says `temperature=0` in your definition of `query_llama`, and then run the above cell many times again. What do you notice now? (To see what argument is doing, go to the [documentation](https://console.groq.com/docs/api-reference#chat-create) and search for \"temperature\".) Recomment out the line before proceeding.\n",
    "- If you remove \"but keep it concise: just one paragraph.\", what do you notice?\n",
    "\n",
    "Now we have a way of passing queries to a Large Language Model and getting back results. Right now, it's not knowledgeable enough to answer questions about EECS classes. Soon, we'll change that.\n",
    "\n",
    "We'll get back to using `query_llama` in the final part of this question. For now, we need to switch our attention to implementing RAG ‚Äì that is, being able to find the syllabus documents that are most similar to our input query. Once we implement it, when we pass our (new) function the input `'Tell me about EECS 485 at Michigan, but keep it concise: just one paragraph.'`, it'll provide accurate, up-to-date information about EECS 485, since we'll send the syllabus for EECS 485 to Llama along with the original input. **Keep this goal in mind. The next few parts may seem unrelated, but they all come together at the end!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0367a",
   "metadata": {},
   "source": [
    "### Question 4.2 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "A **token** is an alphanumeric string. In Lecture 12, we referred to tokens as \"terms\". Before computing any numbers, we need to find the terms in each syllabus, i.e. we need to **tokenize** each syllabus.\n",
    "\n",
    "Complete the implementation of the function `tokenize`, which takes in a string (`string`) of text and returns a list containing all of the tokens in `string`. Convert all characters to lowercase before extracting tokens.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> tokenize(\"EECS 398-003 Practical Data Science's about data management and applied machine learning.\")\n",
    "['eecs',\n",
    " '398',\n",
    " '003',\n",
    " 'practical',\n",
    " 'data',\n",
    " 'science',\n",
    " 's',\n",
    " 'about',\n",
    " 'data',\n",
    " 'management',\n",
    " 'and',\n",
    " 'applied',\n",
    " 'machine',\n",
    " 'learning']\n",
    "\n",
    ">>> tokenize(open('data/syllabi/485.txt').read())[:20]\n",
    "['eecs',\n",
    " '485',\n",
    " 'web',\n",
    " 'systems',\n",
    " 'syllabus',\n",
    " 'the',\n",
    " 'university',\n",
    " 'of',\n",
    " 'michigan',\n",
    " 'fall',\n",
    " '2024',\n",
    " 'a',\n",
    " 'holistic',\n",
    " 'course',\n",
    " 'of',\n",
    " 'modern',\n",
    " 'web',\n",
    " 'systems',\n",
    " 'and',\n",
    " 'technologies']\n",
    "```\n",
    "\n",
    "Note that this part is only worth 1 point, so it shouldn't take very long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f96d0892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eecs',\n",
       " '398',\n",
       " '003',\n",
       " 'practical',\n",
       " 'data',\n",
       " 'science',\n",
       " 's',\n",
       " 'about',\n",
       " 'data',\n",
       " 'management',\n",
       " 'and',\n",
       " 'applied',\n",
       " 'machine',\n",
       " 'learning']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(string):\n",
    "    new = re.findall(r'\\w+',string.lower())\n",
    "    return new\n",
    "\n",
    "# Feel free to change the input below to test out your implementation of tokenize.\n",
    "tokenize(\"EECS 398-003 Practical Data Science's about data management and applied machine learning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "225bde6e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q04_02</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q04_02 results: All test cases passed!"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q04_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bda969b",
   "metadata": {},
   "source": [
    "Before we move onto Question 4.3, it's worth mentioning that in practice, we'd put a bit more care into tokenizing our documents. For one, we might **lemmatize** our tokens, which would allow us to group words like `'eating'`, `'ate'`, and `'eatery'` all to `'eat'`. We've omitted such steps here for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0829d64",
   "metadata": {},
   "source": [
    "### Question 4.3 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Complete the implementation of the function `files_to_bow`, which takes in a string describing the **path** to a folder with syllabus files (`path`) and returns the corresponding **bag of words matrix** as a DataFrame, with:\n",
    "- One row per file, indexed by the file name. The DataFrame should be sorted by the index in ascending order.\n",
    "- One column per unique word (token) among all syllabi (i.e. across the entire corpus). The order of the columns in the DataFrame does not matter.\n",
    "- Values corresponding to the number of occurrences of each word in each file.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> out = files_to_bow('data/syllabi')\n",
    ">>> out.shape\n",
    "(29, 4306)\n",
    "\n",
    ">>> out.loc['280.txt', 'computer']\n",
    "12\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- You must implement all of the steps by hand, i.e. no using `sklearn`'s `CountVectorizer`.\n",
    "- To find all of the files in a folder, use `os.listdir` (we've already imported `os`). Make sure to verify that the files you're processing end in `.txt` ‚Äì there may be other files in `path` that aren't valid syllabi, and we don't want to process those.\n",
    "- Our solution involved creating an intermediate helper function that read in the necessary files, tokenized them, and stored them in an appropriate data structure. You can design your implementation however you'd like, but it's a good idea to break it down into smaller pieces.\n",
    "- Since we've already tokenized each file, it's not necessary to use regular expressions to count the number of occurrences of particular words in each document. Look into the list `count` method, which you can use in conjunction with a `for`-loop or the Series `apply` method. Our solution follows the work in Lecture 12 closely.\n",
    "- Our solution only takes ~5 seconds to run on `files_to_bow('data/syllabi')`. Make sure yours is similarly quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "455dc94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>and</th>\n",
       "      <th>you</th>\n",
       "      <th>a</th>\n",
       "      <th>of</th>\n",
       "      <th>in</th>\n",
       "      <th>for</th>\n",
       "      <th>will</th>\n",
       "      <th>be</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>012</th>\n",
       "      <th>ereader</th>\n",
       "      <th>1006</th>\n",
       "      <th>opinion</th>\n",
       "      <th>011</th>\n",
       "      <th>auditorium</th>\n",
       "      <th>chesebrough</th>\n",
       "      <th>flaws</th>\n",
       "      <th>withdrawal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183.txt</th>\n",
       "      <td>183</td>\n",
       "      <td>131</td>\n",
       "      <td>97</td>\n",
       "      <td>101</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.txt</th>\n",
       "      <td>206</td>\n",
       "      <td>136</td>\n",
       "      <td>105</td>\n",
       "      <td>114</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270.txt</th>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280.txt</th>\n",
       "      <td>157</td>\n",
       "      <td>102</td>\n",
       "      <td>128</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281.txt</th>\n",
       "      <td>214</td>\n",
       "      <td>132</td>\n",
       "      <td>78</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370.txt</th>\n",
       "      <td>114</td>\n",
       "      <td>76</td>\n",
       "      <td>52</td>\n",
       "      <td>66</td>\n",
       "      <td>62</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373.txt</th>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376.txt</th>\n",
       "      <td>116</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388.txt</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390.txt</th>\n",
       "      <td>188</td>\n",
       "      <td>115</td>\n",
       "      <td>102</td>\n",
       "      <td>78</td>\n",
       "      <td>85</td>\n",
       "      <td>87</td>\n",
       "      <td>63</td>\n",
       "      <td>82</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445.txt</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453.txt</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465.txt</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467.txt</th>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470.txt</th>\n",
       "      <td>57</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471.txt</th>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473.txt</th>\n",
       "      <td>58</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475.txt</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481.txt</th>\n",
       "      <td>87</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482.txt</th>\n",
       "      <td>116</td>\n",
       "      <td>71</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483.txt</th>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485.txt</th>\n",
       "      <td>80</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487.txt</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489.txt</th>\n",
       "      <td>79</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490.txt</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492.txt</th>\n",
       "      <td>110</td>\n",
       "      <td>94</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>72</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493.txt</th>\n",
       "      <td>97</td>\n",
       "      <td>39</td>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494.txt</th>\n",
       "      <td>97</td>\n",
       "      <td>39</td>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows √ó 4306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         the   to  and  you    a  of  in  for  will  be  ...  1017  012  \\\n",
       "183.txt  183  131   97  101   77  74  70   76    47  43  ...     0    0   \n",
       "203.txt  206  136  105  114   59  68  80   65    62  50  ...     0    0   \n",
       "270.txt   57   25   26   31   34  22  19   12    21  26  ...     0    0   \n",
       "280.txt  157  102  128   77   94  73  70   78    20  32  ...     0    0   \n",
       "281.txt  214  132   78  110  110  85  83   63    61  64  ...     0    0   \n",
       "370.txt  114   76   52   66   62  45  50   44    50  53  ...     0    0   \n",
       "373.txt   63   37   46   22   26  31  20   13    16  18  ...     0    0   \n",
       "376.txt  116   94   90   65   59  60  45   56    45  38  ...     0    0   \n",
       "388.txt   14    6   18    7    1  18   3    8     4   3  ...     0    0   \n",
       "390.txt  188  115  102   78   85  87  63   82    39  30  ...     0    0   \n",
       "445.txt   24   10    9    3   12  15   2    9    13   8  ...     1    1   \n",
       "453.txt    6    9   20    0    1   6   2    6     5   3  ...     0    0   \n",
       "465.txt   14    7   15    3    7   7   3    1     7   9  ...     0    0   \n",
       "467.txt   44   20   46    5   27  24  19   16     6   6  ...     0    0   \n",
       "470.txt   57   36   34   24   22  24  33   22    38  35  ...     0    0   \n",
       "471.txt   72   41   19   31   19  26  25   15    17  23  ...     0    0   \n",
       "473.txt   58   28   39   19   26  22  16   10    28  27  ...     0    0   \n",
       "475.txt   11    5   17    4    6  12   3    3     2   3  ...     0    0   \n",
       "481.txt   87   54   62   40   49  37  40   40    14  24  ...     0    0   \n",
       "482.txt  116   71   55   56   40  40  37   26    29  34  ...     0    0   \n",
       "483.txt   29   20   15   12    6  12   4    9     6   8  ...     0    0   \n",
       "484.txt   10    4    7    5    3   2   2    2     6   3  ...     0    0   \n",
       "485.txt   80   43   60   39   45  44  40   36    19  24  ...     0    0   \n",
       "487.txt   16   12   23    1    6  15   8    9     7   7  ...     0    0   \n",
       "489.txt   79   53   63   48   40  42  40   33    17  20  ...     0    0   \n",
       "490.txt   24    9   19    9    6   8  15    4     8   7  ...     0    0   \n",
       "492.txt  110   94   55   74   49  48  60   34    72  57  ...     0    0   \n",
       "493.txt   97   39   51   39   32  30  41   41    41  24  ...     0    0   \n",
       "494.txt   97   39   51   39   32  30  41   41    41  24  ...     0    0   \n",
       "\n",
       "         ereader  1006  opinion  011  auditorium  chesebrough  flaws  \\\n",
       "183.txt        0     0        0    0           0            0      0   \n",
       "203.txt        0     0        0    0           0            0      0   \n",
       "270.txt        1     0        1    0           0            0      1   \n",
       "280.txt        0     0        0    0           0            0      0   \n",
       "281.txt        0     0        0    0           0            0      0   \n",
       "370.txt        0     0        0    0           0            0      0   \n",
       "373.txt        0     0        0    0           0            0      0   \n",
       "376.txt        0     0        0    0           0            0      0   \n",
       "388.txt        0     0        0    0           0            0      0   \n",
       "390.txt        0     0        0    0           0            0      0   \n",
       "445.txt        0     1        0    1           1            1      0   \n",
       "453.txt        0     0        0    0           0            0      0   \n",
       "465.txt        0     0        0    0           0            0      0   \n",
       "467.txt        0     0        0    0           0            0      0   \n",
       "470.txt        0     0        0    0           0            0      0   \n",
       "471.txt        0     0        0    0           0            0      0   \n",
       "473.txt        0     0        0    0           0            0      0   \n",
       "475.txt        0     0        0    0           0            0      0   \n",
       "481.txt        0     0        0    0           0            0      0   \n",
       "482.txt        0     0        0    0           0            0      0   \n",
       "483.txt        0     0        0    0           0            0      0   \n",
       "484.txt        0     0        0    0           0            0      0   \n",
       "485.txt        0     0        0    0           0            0      0   \n",
       "487.txt        0     0        0    0           0            0      0   \n",
       "489.txt        0     0        0    0           0            0      0   \n",
       "490.txt        0     0        0    0           0            0      0   \n",
       "492.txt        0     0        0    0           0            0      0   \n",
       "493.txt        0     0        0    0           0            0      0   \n",
       "494.txt        0     0        0    0           0            0      0   \n",
       "\n",
       "         withdrawal  \n",
       "183.txt           0  \n",
       "203.txt           0  \n",
       "270.txt           0  \n",
       "280.txt           0  \n",
       "281.txt           1  \n",
       "370.txt           0  \n",
       "373.txt           0  \n",
       "376.txt           0  \n",
       "388.txt           0  \n",
       "390.txt           0  \n",
       "445.txt           0  \n",
       "453.txt           0  \n",
       "465.txt           0  \n",
       "467.txt           0  \n",
       "470.txt           0  \n",
       "471.txt           0  \n",
       "473.txt           0  \n",
       "475.txt           0  \n",
       "481.txt           0  \n",
       "482.txt           0  \n",
       "483.txt           0  \n",
       "484.txt           0  \n",
       "485.txt           0  \n",
       "487.txt           0  \n",
       "489.txt           0  \n",
       "490.txt           0  \n",
       "492.txt           0  \n",
       "493.txt           0  \n",
       "494.txt           0  \n",
       "\n",
       "[29 rows x 4306 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def files_to_bow(path):\n",
    "    name = []\n",
    "    text = []\n",
    "    \n",
    "    for i in os.listdir(path):\n",
    "        if i.endswith(\".txt\"):  \n",
    "            file_path = os.path.join(path, i)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                content = f.read()\n",
    "            name.append(i)\n",
    "            text.append(tokenize(content))\n",
    "    \n",
    "\n",
    "    new = pd.DataFrame({\"filename\": name, \"text\": text})\n",
    "    new.set_index('filename', inplace=True)\n",
    "    new = new.sort_index()\n",
    "    name = sorted(name)\n",
    "\n",
    "    all_words = new['text'].explode().value_counts().index\n",
    "    \n",
    "    counts_dict = {fname: {} for fname in name}\n",
    "    \n",
    "    for term in (all_words):\n",
    "        for i in range(len(new)):\n",
    "            filename = name[i]\n",
    "            counts_dict[filename][term] = new['text'].iloc[i].count(term)\n",
    "    \n",
    "    counts = pd.DataFrame.from_dict(counts_dict, orient='index').fillna(0).astype(int)\n",
    "\n",
    "    return counts.sort_index()\n",
    "\n",
    "make = files_to_bow('data/syllabi')\n",
    "make "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd4bb1d9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q04_03</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q04_03 results: All test cases passed!"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q04_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4d451",
   "metadata": {},
   "source": [
    "Since we'll need it in all of our future calculations, we'll create a globally-defined instance of `bow` below. **Make sure that throughout the rest of your notebook, `bow` is defined exactly as below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "956eea95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>and</th>\n",
       "      <th>you</th>\n",
       "      <th>a</th>\n",
       "      <th>of</th>\n",
       "      <th>in</th>\n",
       "      <th>for</th>\n",
       "      <th>will</th>\n",
       "      <th>be</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>012</th>\n",
       "      <th>ereader</th>\n",
       "      <th>1006</th>\n",
       "      <th>opinion</th>\n",
       "      <th>011</th>\n",
       "      <th>auditorium</th>\n",
       "      <th>chesebrough</th>\n",
       "      <th>flaws</th>\n",
       "      <th>withdrawal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183.txt</th>\n",
       "      <td>183</td>\n",
       "      <td>131</td>\n",
       "      <td>97</td>\n",
       "      <td>101</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.txt</th>\n",
       "      <td>206</td>\n",
       "      <td>136</td>\n",
       "      <td>105</td>\n",
       "      <td>114</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270.txt</th>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280.txt</th>\n",
       "      <td>157</td>\n",
       "      <td>102</td>\n",
       "      <td>128</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281.txt</th>\n",
       "      <td>214</td>\n",
       "      <td>132</td>\n",
       "      <td>78</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 4306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         the   to  and  you    a  of  in  for  will  be  ...  1017  012  \\\n",
       "183.txt  183  131   97  101   77  74  70   76    47  43  ...     0    0   \n",
       "203.txt  206  136  105  114   59  68  80   65    62  50  ...     0    0   \n",
       "270.txt   57   25   26   31   34  22  19   12    21  26  ...     0    0   \n",
       "280.txt  157  102  128   77   94  73  70   78    20  32  ...     0    0   \n",
       "281.txt  214  132   78  110  110  85  83   63    61  64  ...     0    0   \n",
       "\n",
       "         ereader  1006  opinion  011  auditorium  chesebrough  flaws  \\\n",
       "183.txt        0     0        0    0           0            0      0   \n",
       "203.txt        0     0        0    0           0            0      0   \n",
       "270.txt        1     0        1    0           0            0      1   \n",
       "280.txt        0     0        0    0           0            0      0   \n",
       "281.txt        0     0        0    0           0            0      0   \n",
       "\n",
       "         withdrawal  \n",
       "183.txt           0  \n",
       "203.txt           0  \n",
       "270.txt           0  \n",
       "280.txt           0  \n",
       "281.txt           1  \n",
       "\n",
       "[5 rows x 4306 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = files_to_bow('data/syllabi')\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea9a0a2",
   "metadata": {
    "id": "69ae9112"
   },
   "source": [
    "### Question 4.4 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Complete the implementation of the function `bow_to_tfidf`, which takes in a bag of words matrix (`bow`) returned by `files_to_bow`. `bow_to_tfidf` should return a DataFrame with the same row labels and column labels as `bow`, but with all values converted to TF-IDFs ‚Äì that is, the outputted DataFrame should contain the TF-IDF of every word in every file.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    "# Here, we're referring to the globally-defined bow.\n",
    ">>> out = bow_to_tfidf(bow)\n",
    ">>> out.shape == bow.shape\n",
    "True\n",
    "\n",
    ">>> out.loc['485.txt', 'science']\n",
    "0.0005272966438261625\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- Follow our logic from Lecture 12 to convert `bow` to a TF-IDF matrix. Your implementation here should be relatively short (< 10 lines).\n",
    "- While not strictly required (in that we won't test it), we recommend you implement `compute_idfs`, which takes in a DataFrame like `bow` and returns a **Series** containing the inverse document frequency (IDF) of each word in `bow`. Not only will this help compartmentalize your work for this question, but it'll make your life much easier in Question 4.5, when you'll again need to use the IDFs of every word in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ebb7e8b",
   "metadata": {
    "id": "78cb787f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>and</th>\n",
       "      <th>you</th>\n",
       "      <th>a</th>\n",
       "      <th>of</th>\n",
       "      <th>in</th>\n",
       "      <th>for</th>\n",
       "      <th>will</th>\n",
       "      <th>be</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>012</th>\n",
       "      <th>ereader</th>\n",
       "      <th>1006</th>\n",
       "      <th>opinion</th>\n",
       "      <th>011</th>\n",
       "      <th>auditorium</th>\n",
       "      <th>chesebrough</th>\n",
       "      <th>flaws</th>\n",
       "      <th>withdrawal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 4306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         the   to  and       you    a   of   in  for  will   be  ...  1017  \\\n",
       "183.txt  0.0  0.0  0.0  0.000813  0.0  0.0  0.0  0.0   0.0  0.0  ...   0.0   \n",
       "203.txt  0.0  0.0  0.0  0.000925  0.0  0.0  0.0  0.0   0.0  0.0  ...   0.0   \n",
       "270.txt  0.0  0.0  0.0  0.000948  0.0  0.0  0.0  0.0   0.0  0.0  ...   0.0   \n",
       "280.txt  0.0  0.0  0.0  0.000631  0.0  0.0  0.0  0.0   0.0  0.0  ...   0.0   \n",
       "281.txt  0.0  0.0  0.0  0.000852  0.0  0.0  0.0  0.0   0.0  0.0  ...   0.0   \n",
       "\n",
       "         012   ereader  1006   opinion  011  auditorium  chesebrough  \\\n",
       "183.txt  0.0  0.000000   0.0  0.000000  0.0         0.0          0.0   \n",
       "203.txt  0.0  0.000000   0.0  0.000000  0.0         0.0          0.0   \n",
       "270.txt  0.0  0.002933   0.0  0.002933  0.0         0.0          0.0   \n",
       "280.txt  0.0  0.000000   0.0  0.000000  0.0         0.0          0.0   \n",
       "281.txt  0.0  0.000000   0.0  0.000000  0.0         0.0          0.0   \n",
       "\n",
       "            flaws  withdrawal  \n",
       "183.txt  0.000000    0.000000  \n",
       "203.txt  0.000000    0.000000  \n",
       "270.txt  0.002933    0.000000  \n",
       "280.txt  0.000000    0.000000  \n",
       "281.txt  0.000000    0.000743  \n",
       "\n",
       "[5 rows x 4306 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_idfs(bow):\n",
    "    num_docs = len(bow)\n",
    "    doc_freqs = bow.astype(bool).sum()\n",
    "    idfs = np.log(num_docs / (doc_freqs))\n",
    "    return idfs\n",
    "\n",
    "def bow_to_tfidf(bow):\n",
    "    idfs = compute_idfs(bow)\n",
    "    tf = bow.div(bow.sum(axis=1), axis=0)\n",
    "    tfidfs = tf * idfs\n",
    "    \n",
    "    return tfidfs\n",
    "\n",
    "# Uncomment the line below once you've implemented bow_to_tfidf.\n",
    "bow_to_tfidf(bow).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e927b997",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q04_04</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q04_04 results: All test cases passed!"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q04_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c6bf5",
   "metadata": {},
   "source": [
    "Before we move forward, it's worth stopping and looking at what we've already accomplished. Run the cell below to see the 5 words with the highest TF-IDFs in each syllabus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5042aafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183.txt               zybooks, eecs183, codelab, 183, ecoach\n",
       "203.txt             match, enrolled, homework, ecoach, pages\n",
       "270.txt                   digital, closed, lab, really, book\n",
       "280.txt                     partners, 280, lab, fci, debrief\n",
       "281.txt            999999, least, attempt, eecs281admin, lab\n",
       "370.txt                   score, hardware, computers, 55, 99\n",
       "373.txt          373, extenuating, penalty, embedded, unfair\n",
       "376.txt         algorithm, solution, solvable, 376, workshop\n",
       "388.txt       asynchronously, musaddequr, br, security, face\n",
       "390.txt         score, paradigms, partners, 390, partnership\n",
       "445.txt                dow, theoretical, 30pm, machine, zhao\n",
       "453.txt         deep, unsupervised, 09, learning, supervised\n",
       "465.txt           standing, 2004, berenson, press, cambridge\n",
       "467.txt           robots, localization, robot, physical, sum\n",
       "470.txt         projects, format, verilog, architecture, 470\n",
       "471.txt             cuda, ia, graphics, processors, parallel\n",
       "473.txt                     drivers, pcb, device, power, 373\n",
       "475.txt    probability, impossible, ciphers, encryption, ...\n",
       "481.txt       former, 481, advice, comprehension, activities\n",
       "482.txt             members, operating, beyster, group, 1695\n",
       "483.txt       pre, decaf, requisite, construction, compilers\n",
       "484.txt                relational, morning, j, eastern, zoom\n",
       "485.txt                  instagram, dynamic, web, 485, pages\n",
       "487.txt                       yujian, liu, lu, wang, natural\n",
       "489.txt              streaming, network, layer, 489, routing\n",
       "490.txt                              tue, fri, nov, sep, oct\n",
       "492.txt                            ch, feb, ethics, jan, mar\n",
       "493.txt             ui, surveys, eecs493, milestone, quizzes\n",
       "494.txt             ui, surveys, eecs493, milestone, quizzes\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def five_largest(row):\n",
    "    return ', '.join(row.index[row.argsort()][-5:])\n",
    "\n",
    "bow_to_tfidf(bow).apply(five_largest, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d6634",
   "metadata": {},
   "source": [
    "Compare that to the 5 words with the highest frequences in each syllabus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29cf4190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183.txt                  a, and, you, to, the\n",
       "203.txt                 in, and, you, to, the\n",
       "270.txt                  be, and, you, a, the\n",
       "280.txt                  for, a, to, and, the\n",
       "281.txt                   of, a, you, to, the\n",
       "370.txt                   be, a, you, to, the\n",
       "373.txt                   a, of, to, and, the\n",
       "376.txt                 of, you, and, to, the\n",
       "388.txt               for, the, face, of, and\n",
       "390.txt                  of, we, and, to, the\n",
       "445.txt                  to, a, will, of, the\n",
       "453.txt    1, and, supervised, week, learning\n",
       "465.txt              of, course, be, the, and\n",
       "467.txt                   is, of, a, the, and\n",
       "470.txt                and, be, to, will, the\n",
       "471.txt                  in, of, you, to, the\n",
       "473.txt                be, will, to, and, the\n",
       "475.txt                eecs, is, the, of, and\n",
       "481.txt                  are, a, to, and, the\n",
       "482.txt                  a, and, you, to, the\n",
       "483.txt               code, you, and, to, the\n",
       "484.txt          will, course, and, the, zoom\n",
       "485.txt                   to, of, a, and, the\n",
       "487.txt                  is, to, of, the, and\n",
       "489.txt                 of, you, to, and, the\n",
       "490.txt                in, thu, tue, and, the\n",
       "492.txt                in, will, you, to, the\n",
       "493.txt               for, in, will, and, the\n",
       "494.txt               for, in, will, and, the\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.apply(five_largest, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5bdd6",
   "metadata": {},
   "source": [
    "Hopefully, the value of TF-IDF is clear, but it's also clear that TF-IDF isn't perfect in summarizing documents. But, as we'll soon see, it'll serve our purposes well!\n",
    "\n",
    "Before you move to Question 4.5, there's one piece of syntax that you'll find useful: the Series `reindex` method. Here's an example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "127dd449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    2\n",
       "b    5\n",
       "c    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "things = pd.Series({'a': 2, 'b': 5, 'c': 1})\n",
    "things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52cdc24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    hello\n",
       "b       hi\n",
       "x        9\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff = pd.Series({'a': 'hello', 'b': 'hi', 'x': 9})\n",
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da0a709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    2.0\n",
       "b    5.0\n",
       "x    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "things.reindex(stuff.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8da402e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    2.0\n",
       "b    5.0\n",
       "x    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "things.reindex(stuff.index).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede056c",
   "metadata": {
    "id": "37808b3c"
   },
   "source": [
    "### Question 4.5 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Complete the implementation of the function `new_query_to_tfidf`, which takes in a string (`query_string`) and a bag of words matrix (`bow`) and returns a Series such that:\n",
    "- The index contains the same labels as `bow`'s columns (meaning that if `bow` has 4306 columns, the outputted Series should have 4306 elements).\n",
    "- The values contain the TF-IDF of each word, using `query_string` to compute TFs and **the entire corpus of syllabi (not including the new query)** to compute IDFs.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> out = new_query_to_tfidf('yooo I am very very very interested in a practical machine learning course', bow)\n",
    ">>> out.shape\n",
    "(4306,)\n",
    "\n",
    "# Most of the values in out are 0, since\n",
    "# \"yooo I am very very very interested in a practical machine learning course\"\n",
    "# doesn't contain most of the 4306 words in bow.\n",
    "# Since 'yooo' is not in bow.columns, it doesn't appear in the index of out, either.\n",
    ">>> out[out > 0]\n",
    "machine       0.090005\n",
    "interested    0.174514\n",
    "very          0.328012\n",
    "am            0.152385\n",
    "i             0.032527\n",
    "practical     0.109337\n",
    "learning      0.050711\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "To be clear, the TF-IDF of a word $t$ in a new query string $q$ is:\n",
    "\n",
    "$$\\text{tfidf}(t, q) = \\underbrace{\\frac{\\text{\\# of occurrences of $t$ in $q$}}{\\text{total \\# of tokens in $q$}}}_{\\text{computed using } q \\: (\\texttt{query\\_string})} \\cdot \\underbrace{\\log \\left(\\frac{\\text{total \\# of syllabi}}{\\text{\\# of syllabi in which $t$ appears}} \\right)}_{\\text{computed solely using \\texttt{bow}}}$$\n",
    "\n",
    "Note that this means that the IDFs of each word have nothing to do with the `query_string` that is passed in. This is precisely why we suggested you implement `compute_idfs(bow)` in the previous part ‚Äì because it would help your implementation of `bow_to_tfidf`, and also help your implementation of `new_query_to_tfidf`.\n",
    "\n",
    "Some additional guidance:\n",
    "- This function should only take a few lines to implement, but requires combining several steps, going all the way back to Question 4.2. Think about how the `reindex` method might be useful.\n",
    "- In the function signature below, you'll see `new_query_to_tfidf(query_string, bow=bow)`. `bow=bow` sets the default value of the `bow` argument to the globally-defined value of `bow`, meaning if we only pass one argument (`query_string`) to `new_query_to_tfidf`, it will automatically use the global `bow`. It's important for our function to be able to take in bag of words matrices other than our globally-defined `bow`, in case we want to use it on a different corpus of documents. But, most of the time we will call it on the global `bow`, so this is done for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9cfaeab1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0.0\n",
       "00             0.0\n",
       "000            0.0\n",
       "001            0.0\n",
       "002            0.0\n",
       "              ... \n",
       "zhongren       0.0\n",
       "zhongsydney    0.0\n",
       "zone           0.0\n",
       "zoom           0.0\n",
       "zybooks        0.0\n",
       "Length: 4306, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_query_to_tfidf(query_string, bow=bow):\n",
    "    query_tokens = tokenize(query_string)\n",
    "    query_counts = pd.Series(query_tokens).value_counts()\n",
    "    set_1 = set(compute_idfs(bow).index)\n",
    "    set_2 = set(query_counts.index)\n",
    "    diff = set_2 - set_1\n",
    "    new = (query_counts/len(query_tokens)) * (compute_idfs(bow))\n",
    "    return new.drop(index = diff).fillna(0)\n",
    "\n",
    "# Feel free to change the input below to test out your implementation of new_query_to_tfidf.\n",
    "out = new_query_to_tfidf('yooo I am very very very interested in a practical machine learning course')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c18406c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the            0.0\n",
       "to             0.0\n",
       "and            0.0\n",
       "you            0.0\n",
       "a              0.0\n",
       "              ... \n",
       "011            0.0\n",
       "auditorium     0.0\n",
       "chesebrough    0.0\n",
       "flaws          0.0\n",
       "withdrawal     0.0\n",
       "Length: 4306, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_query_to_tfidf(query_string, bow=bow):\n",
    "    # Tokenize the query string\n",
    "    query_tokens = tokenize(query_string)\n",
    "    \n",
    "    # Count the occurrences of each token\n",
    "    query_counts = pd.Series(query_tokens).value_counts()\n",
    "\n",
    "    # Calculate term frequency (TF)\n",
    "    tf = query_counts / len(query_tokens)\n",
    "    \n",
    "    # Compute IDF only for terms that exist in the bow\n",
    "    idfs = compute_idfs(bow)\n",
    "\n",
    "    # Keep only the terms that exist in the query and in the bow\n",
    "    valid_terms = tf.index.intersection(idfs.index)\n",
    "\n",
    "    # Calculate TF-IDF for the valid terms\n",
    "    tfidf = tf[valid_terms] * idfs[valid_terms]\n",
    "\n",
    "    # Return the resulting Series, filled with 0s for terms not present\n",
    "    return tfidf.reindex(bow.columns, fill_value=0)\n",
    "\n",
    "out = new_query_to_tfidf('yooo I am very very very interested in a practical machine learning course')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "599d469d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q04_05</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q04_05 results: All test cases passed!"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q04_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e3345",
   "metadata": {},
   "source": [
    "Let's take stock of what we have so far.\n",
    "- We have the TF-IDFs of every word in every document in our corpus. This means that we have a **vector representation** of each syllabus.\n",
    "- We have a function that can take any query string and turn it into a **vector** of TF-IDF scores, as well.\n",
    "\n",
    "Now, we can use techniques from Lecture 12 ‚Äì specifically, cosine similarity ‚Äì to find the syllabi that are most similar (and, hence, most relevant) to our query string!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb19266",
   "metadata": {},
   "source": [
    "### Question 4.6 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Complete the implementation of the function `top_n_similar_documents`, which takes in a string (`query_string`), a positive integer `n`, and a bag of words matrix (`bow`) and returns a list containing the names of the `n` most similar documents to `query_string`. \n",
    "\n",
    "Use cosine similarity to measure the similarity between two vectors; you can implement cosine similarity however you'd like. Remember that document names are stored in the index of `bow`. The documents in the returned list should be sorted in **decreasing order of similarity**.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> top_n_similar_documents('yooo I am very very very interested in a practical machine learning course', 3, bow)\n",
    "['467.txt', '445.txt', '453.txt']\n",
    "\n",
    ">>> top_n_similar_documents('C++ programming and systems design', 4, bow)\n",
    "['482.txt', '473.txt', '370.txt', '281.txt']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc9cd722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5059a1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['471.txt', '485.txt', '482.txt']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_n_similar_documents(query_string, n, bow=bow):\n",
    "    query_tfidf = new_query_to_tfidf(query_string, bow).fillna(0)\n",
    "    arr =  np.array(query_tfidf)\n",
    "    tfidf = bow_to_tfidf(bow).fillna(0)\n",
    "    new = [0] * len(tfidf)\n",
    "    for i in range(len(tfidf)):\n",
    "        vec = np.array(tfidf.iloc[i])\n",
    "        new[i] = cosine_similarity(vec, arr)\n",
    "    npnew = pd.Series(new)\n",
    "    yay = npnew.nlargest(n).index\n",
    "    return  [bow.index[i] for i in yay]\n",
    "\n",
    "\n",
    "# Feel free to change the inputs below to test out your implementation of top_n_similar_documents.\n",
    "top_n_similar_documents('hey teach me about programming', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59f48a23",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q04_06</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q04_06 results: All test cases passed!"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q04_06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca0989",
   "metadata": {},
   "source": [
    "Awesome! You've implemented the retrieval step in RAG. That is, given a query, you're able to automatically find the most relevant documents in our \"knowledge database\" for answering that query.\n",
    "\n",
    "It's time for the final step: passing a `query_string`, along with the contents of the most relevant documents, to a Large Language Model (which we already learned how to access, using `query_llama`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b7530b",
   "metadata": {},
   "source": [
    "### Question 4.7 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Complete the implementation of the function `ask_gpteecs`, which takes in a string (`query_string`) containing a question about EECS courses, a positive integer `n`, and a bag of words matrix `bow`. `ask_gpteecs` should return a **string** containing the result of:\n",
    "\n",
    "- querying Llama 3 using `query_llama` from Question 4.1,\n",
    "- where the query contains **both** the contents of `query_string` and\n",
    "- the **top `n`** most similar syllabus documents,\n",
    "- stitched together in a way that you deem appropriate.\n",
    "\n",
    "Here's what we mean by \"in a way that you deem appropriate.\" Suppose our query is `'yooo I am very very very interested in a practical machine learning course'`, and suppose `n=3` (the default).\n",
    "- The top 3 most similar documents are `'467.txt'`, `'445.txt'`, and `'453.txt'`.\n",
    "- If we just ask Llama, `'yooo I am very very very interested in a practical machine learning course'`, it won't know anything about EECS 467, EECS 445, or EECS 453. If we ask it, `'yooo I am very very very interested in a practical machine learning course, tell me about them: 467.txt, 445.txt, and 453.txt'`, it also won't know anything about those courses.\n",
    "- Instead, once we identify which (3) documents are most relevant, we need to read them in as strings once again using `open`, then create a new `query_string` that looks something like:\n",
    "\n",
    "```python\n",
    "'''\n",
    "Hi! I'm looking to answer this query that a student sent me, regarding EECS courses at the University of Michigan:\n",
    "\n",
    "yooo I am very very very interested in a practical machine learning course\n",
    "\n",
    "Here are some relevant courses from my knowledge base.\n",
    "\n",
    "here's EECS 467\n",
    "EECS 467: Autonomous Robots\n",
    "Software methods and implementation for robot perception, world mapping, ...\n",
    "...\n",
    "\n",
    "here's EECS 445\n",
    "Syllabus\n",
    "Introduction to Machine LearningFall 2016\n",
    "The course is a programming-focused introduction to Machine Learning.\n",
    "...\n",
    "\n",
    "here's EECS 453\n",
    "Course Instructor: Prof. Qing Qu\n",
    "Course Time: Mon/Wed 12:00 PM ‚Äì 1:30 PM\n",
    "...\n",
    "'''\n",
    "```\n",
    "\n",
    "- You can structure your final query string however you'd like, and you're encouraged to experiment with different phrasings to see if they influence your results; you can start by copying the example format above, but then try and make it your own. (This is called **prompt engineering**.)\n",
    "- In the example above, we only included the first few lines of the relevant syllabi, but in your actual prompts, you'd include the entire text. You'll need to figure out a way of programmatically adding the course numbers and course syllabi text to your prompt string ‚Äì remember, `n` might be something other than 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd198468",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1478a13b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Introduction to Machine Learning (6.0 units)\n",
       "    \n",
       "    - Syllabus: Introductory guide to ML concepts and techniques, including supervised learning, unsupervised learning, and reinforcement learning. Covers common ML algorithms like linear regression, logistic regression, decision trees, and neural networks.\n",
       "    - Prerequisites: Basic programming skills, calculus, probability, and linear algebra.\n",
       "    - Learning outcomes:\n",
       "        - Understand the principles of ML and the various techniques used in data analysis and modeling.\n",
       "        - Develop models using common ML algorithms and evaluate their performance using metrics like accuracy and precision.\n",
       "        - Implement and compare different ML models on real-world datasets.\n",
       "    \n",
       "    - Contact hours: 72 hours (12 2-hour sessions)\n",
       "    - Course materials: Lectures, assignments, exams, and practical exercises.\n",
       "    - Assessment: Graded assignments, exams, and a final project.\n",
       "    \n",
       " 2. Advanced Machine Learning (6.0 units)\n",
       "    \n",
       "    - Syllabus: Deep learning, natural language processing, computer vision, and reinforcement learning. Covers advanced techniques for dealing with complex data structures and large-scale datasets.\n",
       "    - Prerequisites: Basic understanding of ML, programming skills, and comfort with mathematical concepts and linear algebra.\n",
       "    - Learning outcomes:\n",
       "        - Gain advanced knowledge in ML, focusing on advanced techniques and modern applications.\n",
       "        - Develop models using cutting-edge ML techniques like deep learning, NLP, and computer vision.\n",
       "        - Apply advanced ML methods to solve complex problems and tackle real-world challenges.\n",
       "    \n",
       "    - Contact hours: 72 hours (12 2-hour sessions)\n",
       "    - Course materials: Lectures, assignments, research papers, and real-world case studies.\n",
       "    - Assessment: Graded assignments, exams, research paper presentation, and a final project.\n",
       "    \n",
       "3. Data Science for Machine Learning (6.0 units)\n",
       "    \n",
       "    - Syllabus: Data preprocessing, feature engineering, model evaluation, and dealing with imbalanced datasets. Focuses on practical skills required to be a data scientist in the context of ML.\n",
       "    - Prerequisites: Basic understanding of ML, programming skills, and experience with Python or R.\n",
       "    - Learning outcomes:\n",
       "        - Develop models using ML techniques in a way that is consistent with your field of study and work experience.\n",
       "        - Apply data preparation, feature engineering, and model evaluation techniques to real-world datasets.\n",
       "        - Identify common problems in data science and ML and propose potential solutions.\n",
       "    \n",
       "    - Contact hours: 72 hours (12 2-hour sessions)\n",
       "    - Course materials: Lectures, assignments, real-world case studies, and online resources/toolsets (Python or R).\n",
       "    - Assessment: Graded assignments, exams, group projects, and a final project for real-world datasets.\n",
       "    \n",
       "Each of these courses aims to ensure you acquireEECS 453: Course Instructor: Prof. Qing Qu\n",
       "\n",
       "Course Time: Mon/Wed 12:00 PM ‚Äì 1:30 PM,  3 credit hour\n",
       "\n",
       "Office Hour: Wed 3:30 PM ‚Äì 5:00 PM\n",
       "\n",
       "Prerequisite: EECS 351, or EECS 301, or any linear algebra courses\n",
       "\n",
       "Notice: This is an entry-level ECE machine learning course targeted for senior EE & CE undergraduate, and junior master students outside SIPML area. All students outside EECS that want to learn the basics of ML are also welcome! Compared to EECS 445, this course places slightly greater emphasis on mathematical principles and is better suited for students who have limited experience with programming and machine learning. \n",
       "\n",
       "Overview: The class will cover basic principles in machine learning, such as unsupervised learning (e.g., clustering, mixture models, dimension reduction), and supervised learning (e.g., regression, classification, neural networks & deep learning). For each topic, key algorithmic ideas/intuitions and basic theoretical insights will be highlighted.\n",
       "\n",
       "Course Materials: slides and videos will be accessed via Canvas (TBA). Tentative topics that will be covered in this course are supervised learning, unsupervised learning, and reinforcement learning:\n",
       "\n",
       "Basics of probability, linear algebra, and optimization\n",
       "Regression and linear prediction\n",
       "Support vector machines and kernel methods\n",
       "Deep neural networks\n",
       "Dimension reduction: PCA, autoencoder\n",
       "Clustering (Kmeans, Mixture of Gaussians, EM)\n",
       "Representation learning: nonnegative matrix factorization, dictionary learning\n",
       "Assessment: (i) 5 homework assignments (40%), (ii) mid-term exam (30%), (iii) course projects (25%), (iv) participation & course evaluation (5%)\n",
       "\n",
       "Assessment\t Percentage  \n",
       "Homework (5)\t40%\n",
       "Midterm Exam\t30%\n",
       "Projects\t25%\n",
       "Participation & Course Evaluation\t5%\n",
       "Textbook: We recommend the following books and articles, although we will not follow them closely.\n",
       "\n",
       "Foundations of Machine Learning, by Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.\n",
       "The Elements of Statistical Learning: Data Mining, Inference, and Prediction, by Trevor Hastie, Robert Tibshirani, and Jerome Friedman.\n",
       "Deep Learning, by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.\n",
       "Mathematics for Machine Learning, by Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong.\n",
       "Linear Algebra and Optimization for Machine Learning, by Charu C. Aggarwal.\n",
       "Related courses:\n",
       "\n",
       "EECS 445. Introduction to Machine Learning\n",
       "EECS 453. Applied Matrix Algorithms for Signal Processing, Data Analysis, and Machine Learning\n",
       "EECS 505. Computational Data Science and Machine Learning\n",
       "EECS 545. Machine Learning\n",
       "Course Syllabus (Note: the schedule is tentative, and is subject to change during the semester.)\n",
       "\n",
       "Week\tDate\t Topic\tContents\tHomework, Review\n",
       "Week-1-1\t08/29\tIntroduction (Remote)\tCourse overview\t \n",
       "Week-1-2\t08/31\tSupervised Learning (Remote)\tIntroduction to supervised learning, linear models, regularization\tLinear Algebra Review \n",
       "Week-2-1\t09/05\tLabor Day\tNo class\t \n",
       "Week-2-2\t09/07\tSupervised Learning\tLearning Theory\tProbability Review, HW1 Release \n",
       "Week-3-1\t09/12\tSupervised Learning\tLinear regression I\t \n",
       "Week-3-2\t09/14\tSupervised Learning\tLinear regression II\tPython Review \n",
       "Week-4-1\t09/19\tSupervised Learning\tLinear Classifiers\t \n",
       "Week-4-2\t09/21\tSupervised Learning\tLinear Discriminant Analysis\tHW1 Due, HW2 Release \n",
       "Week-5-1\t09/26\tSupervised Learning (remote)\tLogistic regression\t \n",
       "Week-5-2\t09/28\tSupervised Learning (remote)\tOptimization methods I\t \n",
       "Week-6-1\t10/03\tSupervised Learning\tOptimization methods II\t \n",
       "Week-6-2\t10/05\tSupervised Learning \tSupport vector machine (SVM) I\tHW2 Due,  HW3 Release  \n",
       "Week-7-1\t10/10\tSupervised Learning \tSupport vector machine (SVM) II\t \n",
       "Week-7-2\t10/12\tSupervised Learning \tSupport vector machine (SVM) III\t \n",
       "Week-8-1\t10/17\tFall Study Day\tNo class\t \n",
       "Week-8-2\t10/19\tSupervised Learning\tDual SVM\t HW3 Due\n",
       "Week-9-1\t10/24\tSupervised Learning\tNonlinear models, kernel methods\t \n",
       "Week-9-2\t10/26\tSupervised Learning\tIntroduction to deep neural networks I\t \n",
       "Week-10-1\t10/31\tSupervised Learning\tIntroduction to deep neural networks II\t \n",
       "Week-10-2\t11/02\tSupervised Learning\tIntroduction to deep neural networks III\t \n",
       "Week-11-1\t11/07\tMidterm\tMidterm\t \n",
       "Week-11-2\t11/09\tUnsupervised Learning\tIntroduction to unsupervised learning, clustering problem, K-means\tProject Proposal Due, HW4 Release\n",
       "Week-12-1\t11/14\tUnsupervised Learning\tK-means, mixtures of Gaussian, expectation maximization\t \n",
       "Week-12-2\t11/16\tUnsupervised Learning\tDimension reduction, PCA\t \n",
       "Week-13-1\t11/21\tUnsupervised Learning\tDimension reduction II\t \n",
       "Week-13-2\t11/23\tThanksgiving\tNo Class\t \n",
       "Week-14-1\t11/28\tUnsupervised Learning (Remote)\tRepresentation learning, matrix factorization\tHW4 Due, HW5 Release   \n",
       "Week-14-2\t11/30\tUnsupervised Learning (Remote)\tAutoencoder & self-supervised learning\t \n",
       "Week-15-1\t 12/05\tUnsupervised Learning\tGenerative Models\tHW5 Due \n",
       "Week-15-2\t 12/07\t Final Presentation\tEECS 445: Syllabus\n",
       "Introduction to Machine LearningFall 2016\n",
       "The course is a programming-focused introduction to Machine Learning. Increasingly, extracting value from data is an important contributor to the global economy across a range of industries. The field of Machine Learning provides the theoretical underpinnings for data-analysis as well as more broadly for modern artificial intelligence approaches to building artificial agents that interact with data; it has had a major impact on many real-world applications.\n",
       "\n",
       "This is an undergraduate course. Graduate students seeking to take a machine learning course should consider EECS 545.\n",
       "\n",
       "The course will emphasize understanding the foundational algorithms and ‚Äútricks of the trade‚Äù through implementation and basic-theoretical analysis. On the implementation side, the emphasis will be on practical applications of machine learning to computer vision, data mining, speech recognition, text processing, bioinformatics, and robot perception and control. Real data sets will be used whenever feasible to encourage understanding of practical issues. The course will provide an opportunity for an open-ended research project. On the theoretical side, the course will give a undergraduate-level introduction to the foundations of machine learning topics including regression, classification, kernel methods, regularization, neural networks, graphical models, and unsupervised learning.\n",
       "\n",
       "Basic Information\n",
       "Professors\tDr. Jacob Abernethy and Dr. Jia Deng\n",
       "TAs\tChansoo Lee, Zhao Fu, Ben Bray, Valli Chockalingham\n",
       "Prerequisites\t\n",
       "The only enforced prerequisite is EECS 281. However, if you are not familiar with at least one of the following topics you will struggle in this course.\n",
       "\n",
       "Linear algebra at the level of MATH 419 or MATH 214, but preferrably at the level of MATH 217.\n",
       "Probability at the level of EECS 401, MATH 425, or equivalent.\n",
       "We understand that most EECS students will only ever encounter a proper subset of these topics, so we will be providing a brief review of important concepts at the beginning of the semester. We'll move fast, though, so be warned!\n",
       "\n",
       "Textbook\t\n",
       "A good textbook is invaluable for self-study. Although there is no required textbook, we highly recommend purchasing one of the following books for your own use and future reference:\n",
       "\n",
       "Murphy, Kevin P. Machine learning: A Probabilistic Perspective. MIT press, 2012.\n",
       "Bishop, Christopher M. Pattern Recognition and Machine Learning. Springer-Verlag New York, Inc., 2006.\n",
       "Lectures\t\n",
       "This semester, we will be experimenting with a flipped classroom format. The later section will be a typical lecture and will be video recorded for online viewing. The earlier section will be more hands-on, where students will spend most of their time working together in groups to better understand challenging concepts.\n",
       "\n",
       "Section 001 (Hands-on Lecture) Mon/Wed 4:30-6pm, 1670 BBB\n",
       "Section 002 (Standard Lecture) Mon/Wed 6-7:30pm, Chesebrough Auditorium\n",
       "Discussion\t\n",
       "Discussions begin Tuesday, September 13, 2016.\n",
       "\n",
       "Discussion 011 (Ben) Fri 11:30am-12:30pm, 1006 DOW\n",
       "Discussion 012 (Zhao) Thu 4:30-5:30pm, 1017 DOW\n",
       "Discussion 013 (Zhao) Fri 1:30-2:30pm, 1303 EECS\n",
       "Discussion 014 (Chansoo) Tue 4:30-5:30pm, 2150 DOW\n",
       "Discussion 016 (Valli) Thu 2:30-3:30pm, 1005 EECS\n",
       "Office Hours\tSee the course calendar below for our office hour schedule.\n",
       "Communication\tNo email policy! Use Piazza instead! Our only exception to this policy is for personal issues, for which you may email or make an appointment with a professor.\n",
       "EECS 471: Course Overview\n",
       "The goal of this class is to teach parallel computing and developing applications for massively parallel processors (e.g. GPUs). Self¬≠driving cars, machine learning and augmented reality are examples of applications involving parallel computing. The class focuses on computational thinking, forms of parallelism, programming models, mapping computations to parallel hardware, efficient data structures, paradigms for efficient parallel algorithms, and application case studies.\n",
       "\n",
       "The course will cover popular programming interface for graphics processors (CUDA for NVIDIA processors), internal architecture of graphics processors and how it impacts performance, and implementations of parallel algorithms on graphics processors. The curriculum will be delivered in ~29 lectures. The class has heavy programming components, including five hands¬≠on assignments and a final project.\n",
       "\n",
       "Prerequisites\n",
       "Students must have taken both EECS 281 and EECS 370\n",
       "\n",
       "UG Requirements met by the class:\n",
       "4 credits, Upper-level elective for CS and CE majors, Flex Tech electives.\n",
       "\n",
       "Programming Assignments\n",
       "Six assignments will be assigned during the term.\n",
       "\n",
       "The most common reason for not doing well on the assignments is not starting them early enough. You will be given plenty of time to complete each assignment. However, if you wait until the last minute to start, you may not be able to finish. Plan to have it finished about 2 days ahead of the due date - many unexpected problems arise during programming, especially in the debugging phase. Plan for these things to happen. Your lack of starting early is not an excuse for turning in your assignment late, even if some unfortunate situations arise such as having your computer crash.\n",
       "\n",
       "There are many sources of help on which you can draw. Many questions can be submitted to the course staff and your fellow classmates via the class forum. The policies for using the class forum are contained in the first post in the forum. These will typically be answered within the day, often more quickly during working hours. However, some types of questions cannot be answered without seeing your code. If you have detailed questions on your program, speak to a IA or professor in office hours.\n",
       "\n",
       "Students are also encouraged to help one another on the course concepts (but not the implementation of the assignments). One of the best ways for you to make sure that you understand a concept is to explain it to someone else. Keep in mind, however, that you should not expect anyone else to do any part of your programming assignment for you. The programming assignment that you turn in must be completely your own.\n",
       "\n",
       "Turning in Assignments\n",
       "Assignments are due at 11:59 pm exactly on the due date.\n",
       "\n",
       "Each assignment has a programming component to be submitted on Great Lakes, and a quiz component to be submitted on Gradescope. The programming component is 80% of the assignment grade, and the quiz component is 20% of the assignment grade.\n",
       "\n",
       "Final Project\n",
       "There will be a final project with an open ended implementation. You will be responsible for using the knowledge you gained throughout the course to optimize an applied problem. Project details will be posted later in the term.\n",
       "\n",
       "Assignment and Project Grading\n",
       "The assignments and project will be graded on both correctness and performance. All grading questions should first be discussed with your IA. If you cannot resolve a problem with the IA, bring the project to the instructor.\n",
       "\n",
       "Doing Your Own Assignments\n",
       "All assignments and exams in this course are to be done on your own, with the exception of the final project where you will be allowed to have a partner. Any suspected violation will result in the initiation of formal procedures with the LS&A or Engineering Honor Council. Violators will receive a 0 in the assignment, in addition to additional grade repercussions, as recommended by the appropriate Honor Council.\n",
       "\n",
       "We will be using a sophisticated automated program to correlate programming work, including those submitted in previous semesters.\n",
       "\n",
       "We do encourage students to help each other learn the course material. As in most courses, there is a boundary separating these two situations. You may give or receive help on any of the concepts covered in lecture or discussion and on the specifics of CUDA syntax. You are allowed to consult with other students in the current class to help you understand the assignment specification (i.e. the problem definition). However, you may not collaborate in any way when constructing your solution - the solution to the assignment must be generated by your work alone and the work of other students must not have contributed to your solution. You are not allowed to work out the programming details of the problems with anyone or to collaborate to the extent that your programs are identifiably similar. You are not allowed to look at or in any way derive advantage from the existence of specifications or solutions prepared in prior years (e.g. programs written by former students, solutions provided by instructors, or handouts).\n",
       "\n",
       "If you have any questions as to what constitutes unacceptable collaboration, please talk to the instructor right away. You are expected to exercise reasonable precautions in protecting your own work. Do not leave your program in a publicly accessible directory, and take care when discarding printouts.\n",
       "\n",
       "Exams\n",
       "There will be two exams this semester. You are expected to take the exams at the scheduled times. If you do not take an exam without verifying a documented medical or personal emergency causing you to miss an exam, you will receive a zero for that exam. If you anticipate conflicts with the exam time, declare your conflicts by the date specifed on the exams page. The exam dates are given near the beginning of the semester so you can avoid scheduling job interviews or other commitments on exam days. Outside commitments are not considered a valid reason for missing an exam. If you need to request any special accommodation during any exam, please bring the necessary paperwork from the SSD office by the end of the first month of classes.\n",
       "\n",
       "Grading Policy\n",
       "Final grades will be based on the total points earned on homeworks, programming assignments and exams. Factors such as class participation may be used to adjust your final grade, especially if it falls on a borderline. T We consider the following grading policies:\n",
       "\n",
       "Programming Assignments = 50%\n",
       "Final Project = 15%\n",
       "Midterm = 15%\n",
       "Final exam = 20%\n",
       "Incompletes will generally not be given. According to university policy, doing poorly in a course is not a valid reason for an incomplete. If you are having problems in the course, your best bet is to come talk to the instructor as soon as you are aware of them."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_gpteecs(query_string, n=3, bow=bow):\n",
    "    similar = top_n_similar_documents(query_string, n, bow)\n",
    "    arr = []\n",
    "    content = []\n",
    "    names = []\n",
    "    new = f''' Here's what we mean by \"in a way that you deem appropriate.\" Suppose our query is\n",
    "    \"{query_string}\".\n",
    "    \n",
    "    Here are the top {n} syllabi that are most similar to your query:\n",
    "    '''\n",
    "    hello = query_llama(new)\n",
    "    for i in similar:\n",
    "        open_file = open(f'data/syllabi/{i}', 'r')\n",
    "        #content.append(open_file.read())\n",
    "        #names.append('EECS ' + i[:3])\n",
    "        hello += f'EECS {i[:3]}: {open_file.read()}'\n",
    "\n",
    "    return hello\n",
    "    \n",
    "    \n",
    "\n",
    "# Feel free to change the inputs below to test out your implementation of ask_gpteecs.\n",
    "# The Markdown function behaves like the print function,\n",
    "# but renders text formatting (e.g. bolding, bullet points) when the output from Llama\n",
    "# contains these elements.\n",
    "(Markdown(ask_gpteecs('teach me about machine learning')))\n",
    "#outs = [ask_gpteecs('yooo I am very very very interested in a practical machine learning course') for _ in range(1)]\n",
    "#outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "91302071",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q04_07</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q04_07 results: All test cases passed!"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q04_07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2b034",
   "metadata": {},
   "source": [
    "**Great work!** You've now implemented Retrieval-Augmented Generation, and have your very own ChatGPT-like interface that knows about EECS classes.\n",
    "\n",
    "Unfortunately, it's not perfect. Look what happens with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4aebb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Markdown(ask_gpteecs('what is different about eecs 280 and eecs 281'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b3bb0",
   "metadata": {},
   "source": [
    "At the bottom, the error says:\n",
    "\n",
    "```\n",
    "BadRequestError: Error code: 400 - {'error': {'message': 'Please reduce the length of the messages or completion.', 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
    "```\n",
    "\n",
    "This is telling us that the query sent to Llama is longer than its **context window**, an idea we discussed at the start of Question 4. Since we're using the model `'llama3-8b-8192'`, the largest possible query we can send is 8192 tokens. If we take a look at the length of each syllabus, we see that the 280 and 281 syllabi together are longer than 8192 tokens (not including punctuation, or the input query, or our instructions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fefb6298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281.txt    4533\n",
       "183.txt    4358\n",
       "203.txt    4325\n",
       "280.txt    4284\n",
       "390.txt    4177\n",
       "492.txt    3387\n",
       "376.txt    3068\n",
       "370.txt    2810\n",
       "481.txt    2398\n",
       "482.txt    2254\n",
       "485.txt    2219\n",
       "489.txt    2125\n",
       "493.txt    1878\n",
       "494.txt    1878\n",
       "470.txt    1440\n",
       "373.txt    1317\n",
       "473.txt    1205\n",
       "270.txt    1148\n",
       "467.txt    1121\n",
       "471.txt    1106\n",
       "490.txt     875\n",
       "453.txt     735\n",
       "487.txt     582\n",
       "445.txt     547\n",
       "483.txt     540\n",
       "388.txt     400\n",
       "465.txt     388\n",
       "475.txt     372\n",
       "484.txt     246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.sum(axis=1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f1efdd",
   "metadata": {},
   "source": [
    "Feel free to keep toying with `query_llama` (see the [Groq documentation here](https://console.groq.com/docs/quickstart) to see what you can customize) and `ask_gpteecs` to try and improve the performance of your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25ade0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finish Line üèÅ\n",
    "\n",
    "Congratulations! You're ready to submit Homework 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec12fd2",
   "metadata": {},
   "source": [
    "To submit your homework:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope under \"Homework 6\".\n",
    "5. Stick around while the Gradescope autograder grades your work. **Remember that Homework 6 has no hidden tests! This means the tests you see in your notebook are the exact same as the ones that will be used to grade your work on Gradescope. When you submit on Gradescope, you'll see your score shortly after you submit, once the autograder finishes running.** \n",
    "6. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189604c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7bec44e1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q01_01 results: All test cases passed!\n",
       "\n",
       "q01_02 results: All test cases passed!\n",
       "\n",
       "q01_03 results: All test cases passed!\n",
       "\n",
       "q02_01 results: All test cases passed!\n",
       "\n",
       "q02_02 results: All test cases passed!\n",
       "\n",
       "q02_03 results: All test cases passed!\n",
       "\n",
       "q02_04 results: All test cases passed!\n",
       "\n",
       "q02_05 results: All test cases passed!\n",
       "\n",
       "q02_06 results: All test cases passed!\n",
       "\n",
       "q02_07 results: All test cases passed!\n",
       "\n",
       "q02_08 results: All test cases passed!\n",
       "\n",
       "q02_09 results: All test cases passed!\n",
       "\n",
       "q02_10 results: All test cases passed!\n",
       "\n",
       "q03_01 results: All test cases passed!\n",
       "\n",
       "q03_02 results: All test cases passed!\n",
       "\n",
       "q03_03 results: All test cases passed!\n",
       "\n",
       "q03_04 results: All test cases passed!\n",
       "\n",
       "q04_01 results: All test cases passed!\n",
       "\n",
       "q04_02 results: All test cases passed!\n",
       "\n",
       "q04_03 results: All test cases passed!\n",
       "\n",
       "q04_04 results: All test cases passed!\n",
       "\n",
       "q04_05 results: All test cases passed!\n",
       "\n",
       "q04_06 results: All test cases passed!\n",
       "\n",
       "q04_07 results: All test cases passed!"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "otter": {
   "tests": {
    "q01_01": {
     "name": "q01_01",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(query_1, str) and isinstance(run_sql(query_1), pd.DataFrame)\nTrue",
         "failure_message": "Make sure query_1 is a string and run_sql(query_1) returns a DataFrame!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> list(run_sql(query_1).columns) == ['purpose', 'total_loans']\nTrue",
         "failure_message": "DataFrame has incorrect column names.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> run_sql(query_1).shape == (8, 2)\nTrue",
         "failure_message": "DataFrame has incorrect shape.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (run_sql(query_1)['purpose'].head(3) == ['debt_consolidation', 'credit_card', 'home_improvement']).all()\nTrue",
         "failure_message": "DataFrame has incorrect row order.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = run_sql(query_1)\n>>> np.isclose(out.loc[out['purpose'] == 'credit_card', 'total_loans'].iloc[0], 582675.0)\nTrue",
         "failure_message": "DataFrame has incorrect values.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_02": {
     "name": "q01_02",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(query_2, str) and isinstance(run_sql(query_2), pd.DataFrame)\nTrue",
         "failure_message": "Make sure query_2 is a string and run_sql(query_2) returns a DataFrame!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> list(run_sql(query_2).columns) == ['state', 'average_credit']\nTrue",
         "failure_message": "DataFrame has incorrect column names.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> run_sql(query_2).shape == (14, 2)\nTrue",
         "failure_message": "DataFrame has incorrect shape.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (run_sql(query_2)['state'].head(5) == ['FL', 'VA', 'NJ', 'OH', 'MI']).all()\nTrue",
         "failure_message": "DataFrame has incorrect row order.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = run_sql(query_2)\n>>> np.isclose(out.loc[out['state'] == 'TX', 'average_credit'].iloc[0], 699.3128390596745)\nTrue",
         "failure_message": "DataFrame has incorrect values.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_03": {
     "name": "q01_03",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(query_3, str) and isinstance(run_sql(query_3), pd.DataFrame)\nTrue",
         "failure_message": "Make sure query_3 is a string and run_sql(query_3) returns a DataFrame!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> list(run_sql(query_3).columns) == ['amount', 'term', 'interest', 'monthly']\nTrue",
         "failure_message": "DataFrame has incorrect column names.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> run_sql(query_3).shape == (1, 4)\nTrue",
         "failure_message": "DataFrame has incorrect shape.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (run_sql(query_3).iloc[0].to_numpy()[:-1] == [39475, 36, 23.88]).all()\nTrue",
         "failure_message": "Incorrect amount, term, or interest.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(run_sql(query_3).iloc[0].to_numpy()[-1], 1882.0802777777778)\nTrue",
         "failure_message": "Incorrect monthly payment amount.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_01": {
     "name": "q02_01",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> match_1(\"abcde]\") == False\nTrue",
         "failure_message": "match_1('abcde]') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_1(\"ab[cde\") == False\nTrue",
         "failure_message": "match_1('ab[cde') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_1(\"a[cd]\") == False\nTrue",
         "failure_message": "match_1('a[cd]') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_1(\"ab[cd]\") == True\nTrue",
         "failure_message": "match_1('ab[cd]') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_1(\"1ab[cd]\") == False\nTrue",
         "failure_message": "match_1('1ab[cd]') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_1(\"ab[cd]ef\") == True\nTrue",
         "failure_message": "match_1('ab[cd]ef') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_1(\"1b[#d] _\") == True\nTrue",
         "failure_message": "match_1('1b[#d] _') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_1('_ab[c#]') == False\nTrue",
         "failure_message": "match_1('_ab[c#]') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_1('_a[c#]!')\nTrue",
         "failure_message": "match_1('_a[c#]!') should return True.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_02": {
     "name": "q02_02",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> match_2(\"(123) 456-7890\") == False\nTrue",
         "failure_message": "match_2('(123) 456-7890') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_2(\"734-456-7890\") == False\nTrue",
         "failure_message": "match_2('734-456-7890') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_2(\"(734)45-7890\") == False\nTrue",
         "failure_message": "match_2('(734)45-7890') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_2(\"(734) 456-7890\") == True\nTrue",
         "failure_message": "match_2('(734) 456-7890') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_2(\"(734)456-789\") == False\nTrue",
         "failure_message": "match_2('(734)456-789') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_2(\"(734)456-7890\") == False\nTrue",
         "failure_message": "match_2('(734)456-7890') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_2(\"a(734) 456-7890\") == False\nTrue",
         "failure_message": "match_2('a(734) 456-7890') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_2(\"(734) 456-7890b\") == False\nTrue",
         "failure_message": "match_2('(734) 456-7890b') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_2('(734) 235-6781')\nTrue",
         "failure_message": "match_2('(734) 235-6781') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_2('(abc) def-ghi') == False\nTrue",
         "failure_message": "match_2('(abc) def-ghi') should return False.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_03": {
     "name": "q02_03",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> match_3(\"qwertsd?\") == True\nTrue",
         "failure_message": "match_3('qwertsd?') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_3(\"qw?ertsd?\") == True\nTrue",
         "failure_message": "match_3('qw?ertsd?') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_3(\"ab c?\") == False\nTrue",
         "failure_message": "match_3('ab c?') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_3(\"ab   c ?\") == True\nTrue",
         "failure_message": "match_3('ab   c ?') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_3(\" asdfqwes ?\") == False\nTrue",
         "failure_message": "match_3(' asdfqwes ?') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_3(\" adfqwes ?\") == True\nTrue",
         "failure_message": "match_3(' adfqwes ?') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_3(\" adf!qes ?\") == False\nTrue",
         "failure_message": "match_3(' adf!qes ?') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_3(\" adf!qe? \") == False\nTrue",
         "failure_message": "match_3(' adf!qe? ') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_3('wwwWW  ?')\nTrue",
         "failure_message": "match_3('wwwWW  ?') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_3('wwwWW .? ') == False\nTrue",
         "failure_message": "match_3('wwwWW .? ') should return False.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_04": {
     "name": "q02_04",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> match_4(\"$$AaaaaBbbbc\") == True\nTrue",
         "failure_message": "match_4('$$AaaaaBbbbc') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_4(\"$!@#$aABc\") == True\nTrue",
         "failure_message": "match_4('$!@#$aABc') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_4(\"$a$aABc\") == False\nTrue",
         "failure_message": "match_4('$a$aABc') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_4(\"$iiuABc\") == False\nTrue",
         "failure_message": "match_4('$iiuABc') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_4(\"123$$$Abc\") == False\nTrue",
         "failure_message": "match_4('123$$$Abc') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_4(\"$$Abc\") == True\nTrue",
         "failure_message": "match_4('$$Abc') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_4(\"$qw345t$AAAc\") == False\nTrue",
         "failure_message": "match_4('$qw345t$AAAc') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_4(\"$s$Bca\") == False\nTrue",
         "failure_message": "match_4('$s$Bca') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_4(\"$!@$\") == False\nTrue",
         "failure_message": "match_4('$!@$') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_4('$qw!!  $aaBC')\nTrue",
         "failure_message": "match_4('$qw!!  $aaBC') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_4('$qw!!  ABC') == False\nTrue",
         "failure_message": "match_4('$qw!!  ABC')) should return False.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_05": {
     "name": "q02_05",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> match_5(\"eecs398.py\") == True\nTrue",
         "failure_message": "match_5('eecs398.py') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_5(\"here is a Python file eecs398.py\") == False\nTrue",
         "failure_message": "match_5('here is a Python file eecs398.py') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_5(\"eecs398py\") == False\nTrue",
         "failure_message": "match_5('eecs398py') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_5(\"eecs398..py\") == False\nTrue",
         "failure_message": "match_5('eecs398..py') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_5(\"eecs398+.py\") == False\nTrue",
         "failure_message": "match_5('eecs398+.py') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_5('eecs398_.py')\nTrue",
         "failure_message": "match_5('eecs398_.py') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_5('eecs398_.py.py') == False\nTrue",
         "failure_message": "match_5('eecs398_.py.py') should return False.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_06": {
     "name": "q02_06",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> match_6(\"aab_cbb_bc\") == False\nTrue",
         "failure_message": "match_6('aab_cbb_bc') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_6(\"aab_cbbbc\") == True\nTrue",
         "failure_message": "match_6('aab_cbbbc') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_6(\"aab_Abbbc\") == False\nTrue",
         "failure_message": "match_6('aab_Abbbc') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_6(\"abcdef\") == False\nTrue",
         "failure_message": "match_6('abcdef') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_6(\"ABCDEF_ABCD\") == False\nTrue",
         "failure_message": "match_6('ABCDEF_ABCD') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_6('zebra_') == False\nTrue",
         "failure_message": "match_6('zebra_') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_6('zebra_d')\nTrue",
         "failure_message": "match_6('zebra_d') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_6('here zebra_d') == False\nTrue",
         "failure_message": "match_6('here zebra_d') should return False.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_07": {
     "name": "q02_07",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> match_7(\"_abc_\") == True\nTrue",
         "failure_message": "match_7('_abc_') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_7(\"_ZeBr@45Din000!!!\\b_\") == True\nTrue",
         "failure_message": "match_7(\"_ZeBr@45Din000!!!\\b_\") should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_7(\"abd\") == False\nTrue",
         "failure_message": "match_7('abd') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_7(\"bcd\") == False\nTrue",
         "failure_message": "match_7('bcd') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_7(\"_ncde\") == False\nTrue",
         "failure_message": "match_7('_ncde') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_7('_') == False\nTrue",
         "failure_message": "match_7('_') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_7('abc_dc_') == False\nTrue",
         "failure_message": "match_7('abc_dc_') should return False.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_08": {
     "name": "q02_08",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> match_8(\"ASJDKLFK10ASDO\") == False\nTrue",
         "failure_message": "match_8('ASJDKLFK10ASDO') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_8(\"iPhone 10\") == False\nTrue",
         "failure_message": "match_8('iPhone 10') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_8(\"ASJDKLFK0ASDo!!!!!!! !!!!!!!!!\")\nTrue",
         "failure_message": "match_8('ASJDKLFK0ASDo!!!!!!! !!!!!!!!!') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_8(\"JKLSDNM01IDKSL\") == False\nTrue",
         "failure_message": "match_8('JKLSDNM01IDKSL') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_8(\"ASDKJLdsi0SKLl\") == False\nTrue",
         "failure_message": "match_8('ASDKJLdsi0SKLl') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_8('ASDJKL9380JKAL')\nTrue",
         "failure_message": "match_8('ASDJKL9380JKAL') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_8(\"hi ASDJKL9380JKAL\") == False\nTrue",
         "failure_message": "match_8('hi ASDJKL9380JKAL') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_8('ASJDKLFK10ASDO') == False\nTrue",
         "failure_message": "match_8('ASJDKLFK10ASDO') should return False.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_09": {
     "name": "q02_09",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> match_9('MI-32-LAN-1232')\nTrue",
         "failure_message": "match_9('MI-32-LAN-1232') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('TX-32-DTW-1232')\nTrue",
         "failure_message": "match_9('TX-32-DTW-1232') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('CA-32-LAN-1232') == False\nTrue",
         "failure_message": "match_9('CA-32-LAN-1232') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('mI-32-LAN-1232') == False\nTrue",
         "failure_message": "match_9('mI-32-LAN-1232') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('ca-23-SAN-1231') == False\nTrue",
         "failure_message": "match_9('ca-23-SAN-1231') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('TX-00-JFK-1345')\nTrue",
         "failure_message": "match_9('TX-00-JFK-1345') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('TX-00') == False\nTrue",
         "failure_message": "match_9('TX-00') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('TX-000-JFK-1345') == False\nTrue",
         "failure_message": "match_9('TX-000-JFK-1345') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('TX-00-JFK-134') == False\nTrue",
         "failure_message": "match_9('TX-00-JFK-134') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('ca-00-JFK-1345') == False\nTrue",
         "failure_message": "match_9('ca-00-JFK-1345') should return False.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('MI-19-DTW-1998')\nTrue",
         "failure_message": "match_9('MI-19-DTW-1998') should return True.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_9('MI-19-DTW-19980') == False\nTrue",
         "failure_message": "match_9('MI-19-DTW-19980') should return False.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_10": {
     "name": "q02_10",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> match_10('ABCdef') == ['bcd']\nTrue",
         "failure_message": "match_10('ABCdef') should return ['bcd'].",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_10(' DEFaabc !g ') == ['def', 'bcg']\nTrue",
         "failure_message": "match_10(' DEFaabc !g ') should return ['def', 'bcg'].",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_10('Come ti chiami?') == ['com', 'eti', 'chi']\nTrue",
         "failure_message": "match_10('Come ti chiami?') should return ['com', 'eti', 'chi'].",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_10('and') == []\nTrue",
         "failure_message": "match_10('and') should return [].",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_10('Ab..DEF') == ['bde']\nTrue",
         "failure_message": "match_10('Ab..DEF') should return ['bde'].",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_10('acaadac!') == ['cdc']\nTrue",
         "failure_message": "match_10('acaadac!') should return ['cdc'].",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_10('h9i9hOWW44areY@') == ['h9i', '9ho', 'ww4', '4re']\nTrue",
         "failure_message": "match_10('h9i9hOWW44areY@') should return ['h9i', '9ho', 'ww4', '4re'].",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> match_10('FINALS are COMING A') == ['fin', 'lsr', 'eco', 'min']\nTrue",
         "failure_message": "match_10('FINALS are COMING A') should return ['fin', 'lsr', 'eco', 'min'].",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q03_01": {
     "name": "q03_01",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = extract_ssns('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.ca,lkj5r%ji|ssn:423-01-9575,530 High Street')\n>>> out[0] == '423-01-9575'\nTrue",
         "failure_message": "The first SSN in the example string should be 423-01-9575.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_ssns(s)\n>>> 2200 <= len(out) <= 3000\nTrue",
         "failure_message": "Between 2200 and 3000 SSNs should be extracted.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_ssns(s)\n>>> sixes = len([x for x in out if x[0] == '6'])\n>>> 300 <= sixes <= 350\nTrue",
         "failure_message": "Between 300 and 350 SSNs beginning with 6 should be extracted.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_ssns(s)\n>>> '634-49-4764' in out[15]\nTrue",
         "failure_message": "'634-49-4764' should be among the SSNs extracted.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q03_02": {
     "name": "q03_02",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = extract_bitcoin_addresses('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n>>> out[0] == '1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2'\nTrue",
         "failure_message": "The first bitcoin address in the example string should be 1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_bitcoin_addresses(s)\n>>> 2500 <= len(out) <= 3000\nTrue",
         "failure_message": "Between 2500 and 3000 bitcoin addresses need to be extracted.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_bitcoin_addresses(s)\n>>> 'null' not in out\nTrue",
         "failure_message": "The string 'null' should not be in the returned list.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q03_03": {
     "name": "q03_03",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = extract_emails('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n>>> out[0] == 'test@test55.umich.edu'\nTrue",
         "failure_message": "The first email in the example string should be \"test@test55.umich.edu\".",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_emails(s)\n>>> out[0] == 'dottewell0@gnu.org'\nTrue",
         "failure_message": "Between 550 and 1000 emails should be extracted.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_emails(s)\n>>> 550 <= len(out) <= 1000\nTrue",
         "failure_message": "Between 550 and 1000 emails should be extracted.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_emails(s)\n>>> gov = len([x for x in out if '.gov' in x])\n>>> 25 <= gov <= 100\nTrue",
         "failure_message": "Between 25 and 100 emails should contain \".gov\".",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_emails(s)\n>>> sd = len([x for x in out if 'google.pl' in x])\n>>> 1 <= sd <= 4\nTrue",
         "failure_message": "Between 1 and 4 emails should contain \"google.pl\".",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_emails(s)\n>>> 'ihouseleeme@mit.edu' in out\nTrue",
         "failure_message": "'ihouseleeme@mit.edu' should be among the emails extracted.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_emails(s)\n>>> 'null' not in out\nTrue",
         "failure_message": "The returned list should have no empty strings.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q03_04": {
     "name": "q03_04",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = extract_street_addresses('bitcoin:1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2$jk%^3\\t,test@test55.umich.edu,lkj5r%ji|ssn:423-01-9575,530 High Street')\n>>> out[0] == '530 High Street'\nTrue",
         "failure_message": "The first street address in the example string should be '530 High Street'.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_street_addresses(s)\n>>> 700 <= len(out) <= 1400\nTrue",
         "failure_message": "Between 700 and 1400 addresses should be extracted.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_street_addresses(s)\n>>> addr = len([x for x in out if x[-4:] == 'Lane'])\n>>> 30 <= addr <= 60\nTrue",
         "failure_message": "Between 30 and 60 addresses ending in \"Lane\" should be extracted.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> s = open('data/messy.txt', encoding='utf8').read()\n>>> out = extract_street_addresses(s)\n>>> '732 Butterfield Plaza' in out\nTrue",
         "failure_message": "'732 Butterfield Plaza' should be extracted as a street address from messy.txt.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_01": {
     "name": "q04_01",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(query_llama('Tell me a joke about data science'), str)\nTrue",
         "failure_message": "Make sure query_llama returns a string.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_llama('Tell me a joke about data science') != query_llama('What is 1+1')\nTrue",
         "failure_message": "Make sure query_llama isn't hard-coded to always return the same string.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_02": {
     "name": "q04_02",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> tokenize('hi there') == ['hi', 'there']\nTrue",
         "failure_message": "Incorrect output for input 'hi there'.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> tokenize(\"EECS 398-003: Practical Data Science, Fall 2024's about data management and applied machine learning.\") == ['eecs', '398', '003', 'practical', 'data', 'science', 'fall', '2024', 's', 'about', 'data', 'management', 'and', 'applied', 'machine', 'learning']\nTrue",
         "failure_message": "Incorrect output for input \"EECS 398-003 Practical Data Science's about data management and applied machine learning.\".",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = tokenize(open('data/syllabi/485.txt', 'r').read())\n>>> out[:20] == ['eecs', '485', 'web', 'systems', 'syllabus', 'the', 'university', 'of', 'michigan', 'fall', '2024', 'a', 'holistic', 'course', 'of', 'modern', 'web', 'systems', 'and', 'technologies']\nTrue",
         "failure_message": "Incorrect output for eecs485.txt (first 20 tokens).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = tokenize(open('data/syllabi/280.txt', 'r').read())\n>>> 'grade we ll compute it both ways and take the higher you can max out this credit even if you miss a few lectures labs' in ' '.join(out)\nTrue",
         "failure_message": "Incorrect output for eecs280.txt (missing substring).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = tokenize(open('data/syllabi/280.txt', 'r').read())\n>>> ('.' not in out) and ('!' not in out) and (':' not in out) and ('@' not in out)\nTrue",
         "failure_message": "Incorrect output for eecs280.txt (found punctuation, but there should be none).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = tokenize(open('data/syllabi/203.txt', 'r').read())\n>>> counts = pd.Series(out).value_counts()\n>>> counts.loc['the'] == 206 and counts.loc['prof'] == 3\nTrue",
         "failure_message": "Incorrect output for eecs203.txt (wrong frequency of tokens).",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_03": {
     "name": "q04_03",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = files_to_bow('data/syllabi')\n>>> out.shape == (29, 4306)\nTrue",
         "failure_message": "Outputted DataFrame has incorrect shape.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = files_to_bow('data/syllabi')\n>>> (out.index == ['183.txt', '203.txt', '270.txt', '280.txt', '281.txt', '370.txt', '373.txt', '376.txt', '388.txt', '390.txt', '445.txt', '453.txt', '465.txt', '467.txt', '470.txt', '471.txt', '473.txt', '475.txt', '481.txt', '482.txt', '483.txt', '484.txt', '485.txt', '487.txt', '489.txt', '490.txt', '492.txt', '493.txt', '494.txt']).all()\nTrue",
         "failure_message": "Outputted DataFrame has incorrect index (remember to sort it in ascending order).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = files_to_bow('data/syllabi')\n>>> set(out.columns) >= {'data', 'machine', 'learning', 'professor', 'has'}\nTrue",
         "failure_message": "Outputted DataFrame has missing column names (i.e. missing tokens).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = files_to_bow('data/syllabi')\n>>> out.loc['280.txt', 'computer'] == 5\nTrue",
         "failure_message": "Outputted DataFrame has incorrect 'computer' frequency for 280.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = files_to_bow('data/syllabi')\n>>> (out.loc['493.txt'] > 0).sum() == 587\nTrue",
         "failure_message": "Outputted DataFrame has incorrect counts for 493.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = files_to_bow('data/syllabi')\n>>> out.sum(axis=1).max() == 4533 and out.sum(axis=1).idxmax() == '281.txt'\nTrue",
         "failure_message": "Outputted DataFrame has incorrect counts for 281.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_04": {
     "name": "q04_04",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> out.shape == (29, 4306)\nTrue",
         "failure_message": "Outputted DataFrame has incorrect shape.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> (out.index == ['183.txt', '203.txt', '270.txt', '280.txt', '281.txt', '370.txt', '373.txt', '376.txt', '388.txt', '390.txt', '445.txt', '453.txt', '465.txt', '467.txt', '470.txt', '471.txt', '473.txt', '475.txt', '481.txt', '482.txt', '483.txt', '484.txt', '485.txt', '487.txt', '489.txt', '490.txt', '492.txt', '493.txt', '494.txt']).all()\nTrue",
         "failure_message": "Outputted DataFrame has incorrect index (keep the same index as bow).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> np.isclose(out.loc['280.txt', 'computer'], 0.0006941026000778394)\nTrue",
         "failure_message": "Outputted DataFrame has incorrect 'computer' TF-IDF for 280.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> np.isclose(out.loc['485.txt', 'science'], 0.0005272966438261625)\nTrue",
         "failure_message": "Outputted DataFrame has incorrect 'science' TF-IDF for 485.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> out['the'].sum() == 0\nTrue",
         "failure_message": "Outputted DataFrame has non-zero TF-IDFs for \"the\", but all should be 0.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> (out.loc['484.txt'] > 0).sum() == 122\nTrue",
         "failure_message": "Outputted DataFrame has incorrect number of non-zero values for 484.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> out.loc['183.txt'].idxmax() == 'ecoach'\nTrue",
         "failure_message": "Outputted DataFrame has incorrect largest TF-IDF for 183.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_05": {
     "name": "q04_05",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = new_query_to_tfidf('yooo I am very very very interested in a practical machine learning course')\n>>> (out > 0).sum() == 7\nTrue",
         "failure_message": "Outputted Series has incorrect number of non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('yooo I am very very very interested in a practical machine learning course')\n>>> np.allclose(np.sort(out[out > 0]), np.array([0.03252745, 0.0507112 , 0.09000548, 0.10933736, 0.15238473, 0.17451412, 0.32801208]))\nTrue",
         "failure_message": "Outputted Series has incorrect number values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('yooo I am very very very interested in a practical machine learning course')\n>>> set(out[out > 0].index) == {'am', 'i', 'interested', 'learning', 'machine', 'practical', 'very'}\nTrue",
         "failure_message": "Outputted Series has incorrect non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('sEIG;H I  seigh;o ')\n>>> set(out[out > 0].index) == {'h', 'i', 'o'} and np.allclose(np.sort(out[out > 0]), np.array([0.08457137, 0.35157158, 0.45373671]))\nTrue",
         "failure_message": "Outputted Series has incorrect non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('sEIG;H I  seigh;o ')\n>>> np.allclose(np.sort(out[out > 0]), np.array([0.08457137, 0.35157158, 0.45373671]))\nTrue",
         "failure_message": "Outputted Series has incorrect non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('logical programming Fundamentals C++ compiler operator linear FUNCtional computer science 60 exam')\n>>> set(out[out > 0].index) == {'60', 'c', 'compiler', 'computer', 'exam', 'functional', 'fundamentals', 'linear', 'operator', 'programming', 'science'}\nTrue",
         "failure_message": "Outputted Series has incorrect non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('logical programming Fundamentals C++ compiler operator linear FUNCtional computer science 60 exam')\n>>> np.allclose(np.sort(out[out > 0]), np.array([0.01236833, 0.02302111, 0.04955893, 0.06068654, 0.08078338, 0.09750594, 0.10732119, 0.14648816, 0.14648816, 0.14648816, 0.28060799]))\nTrue",
         "failure_message": "Outputted Series has incorrect non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('logical programming Fundamentals C++ compiler operator linear FUNCtional computer science 60 exam')\n>>> out.shape[0] == 4306\nTrue",
         "failure_message": "Outputted Series has incorrect shape.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_06": {
     "name": "q04_06",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = top_n_similar_documents('yooo I am very very very interested in a practical machine learning course', 3)\n>>> set(out) == {'445.txt', '453.txt', '467.txt'}\nTrue",
         "failure_message": "Incorrect documents for input 'yooo I am very very very interested in a practical machine learning course', n = 3.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = top_n_similar_documents('yooo I am very very very interested in a practical machine learning course', 3)\n>>> out == ['467.txt', '445.txt', '453.txt']\nTrue",
         "failure_message": "Incorrect document order for 'yooo I am very very very interested in a practical machine learning course', n = 3.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = top_n_similar_documents('C++ programming and systems design', 4)\n>>> out == ['482.txt', '473.txt', '370.txt', '281.txt']\nTrue",
         "failure_message": "Incorrect documents for 'C++ programming and systems design', n = 4.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = top_n_similar_documents('C++ programming and systems design', 6)\n>>> out == ['482.txt', '473.txt', '370.txt', '281.txt', '280.txt', '470.txt']\nTrue",
         "failure_message": "Incorrect documents for 'C++ programming and systems design', n = 6.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = top_n_similar_documents('mathematical foundations of computing', 3)\n>>> out == ['475.txt', '376.txt', '490.txt']\nTrue",
         "failure_message": "Incorrect documents for 'mathematical foundations of computing', n = 3.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = top_n_similar_documents('probability theory and randomness', 7)\n>>> out == ['376.txt', '475.txt', '492.txt', '203.txt', '453.txt', '487.txt', '445.txt']\nTrue",
         "failure_message": "Incorrect documents for 'probability theory and randomness', n = 7.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_07": {
     "name": "q04_07",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> outs = [ask_gpteecs('yooo I am very very very interested in a practical machine learning course') for _ in range(3)]\n>>> any([\"445\" in out for out in outs]) and len(set(outs)) >= 2\nTrue",
         "failure_message": "445 not found in response for the query \"yooo I am very very very interested in a practical machine learning course\", or queries were all the same when called repeatedly (but should not be).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> outs = [ask_gpteecs('programming') for _ in range(3)]\n>>> any([\"390\" in out or \"490\" in out for out in outs]) and len(set(outs)) >= 2\nTrue",
         "failure_message": "Neither 390 nor 490 found in response for the query \"programming\", or queries were all the same when called repeatedly (but should not be).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> outs = [ask_gpteecs('what professors are teaching eecs 280', n=1) for _ in range(3)]\n>>> any(['Juett' in out or 'Kamil' in out or 'Razak' in out for out in outs]) and len(set(outs)) >= 2\nTrue",
         "failure_message": "Neither Juett nor Kamil nor Razak found in response for the query below, or queries were all the same when called repeatedly (but should not be).",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
